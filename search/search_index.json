{
    "docs": [
        {
            "location": "/",
            "text": "libigl - A simple C++ geometry processing library\n\u00b6\n\n\n\n\n\n\n\n\nhttps://github.com/libigl/libigl/\n\n\n\n\nGet started with:\n\n\ngit clone --recursive https://github.com/libigl/libigl.git\n\n\n\n\n\n\nlibigl is a simple C++ geometry processing library. We have a wide\nfunctionality including construction of sparse discrete differential geometry\noperators and finite-elements matrices such as the cotangent Laplacian and\ndiagonalized mass matrix, simple facet and edge-based topology data structures,\nmesh-viewing utilities for OpenGL and GLSL, and many core functions for matrix\nmanipulation which make \nEigen\n feel a lot more\nlike MATLAB.\n\n\nIt is \na header-only library\n. You do not need to compile anything to use,\njust include igl headers (e.g. \n#include\n \n<igl/cotmatrix.h>\n) and run.  Each\nheader file contains a single function (e.g. \nigl/cotmatrix.h\n contains\n\nigl::cotmatrix()\n). Most are tailored to operate on a generic triangle mesh\nstored in an n-by-3 matrix of vertex positions \nV\n and an m-by-3 matrix of\ntriangle indices \nF\n.\n\n\nOptionally\n the library may also be \npre-compiled\n into a statically\nlinked library, for faster compile times with your projects. This only effects\ncompile time (run-time performance and behavior is identical). If in doubt, use\nthe header-only default mode: (i.e. just include the headers you want to use).\n\n\nWe use the \nEigen\n library heavily in our code. Our\ngroup prototypes a lot in MATLAB, and we have a useful \nMATLAB to libigl+Eigen\nconversion table\n.\n\n\nWe regularly test compiling our library on Mac OS X with clang, Linux with gcc\nand Windows with Visual Studio 2015 Community Edition.\n\n\nTutorial\n\u00b6\n\n\nAs of version 1.0, libigl includes an introductory\n\ntutorial\n that covers many functionalities.\n\n\nlibigl Example Project\n\u00b6\n\n\nWe provide a \nblank project example\n showing how to use libigl and cmake. Feel free and encouraged to copy or fork this project as a way of starting a new personal project using libigl.\n\n\nCoding Guidelines and Tips\n\u00b6\n\n\nlibigl follows strict coding guidelines, please take a look \nhere\n before submitting your pull requests. We also have a set of \ngeneral coding tips\n on how to code a geometry processing research project.\n\n\nInstallation\n\u00b6\n\n\nLibigl is a \nheader-only\n library. You do \nnot\n need to build anything to\ninstall.  Simply add \nlibigl/include\n to your include path and include relevant\nheaders.  Here is a small \"Hello, World\" program:\n\n\n#include\n \n<igl/cotmatrix.h>\n\n\n#include\n \n<Eigen/Dense>\n\n\n#include\n \n<Eigen/Sparse>\n\n\n#include\n \n<iostream>\n\n\nint\n \nmain\n()\n\n\n{\n\n  \nEigen\n::\nMatrixXd\n \nV\n(\n4\n,\n2\n);\n\n  \nV\n<<\n0\n,\n0\n,\n\n     \n1\n,\n0\n,\n\n     \n1\n,\n1\n,\n\n     \n0\n,\n1\n;\n\n  \nEigen\n::\nMatrixXi\n \nF\n(\n2\n,\n3\n);\n\n  \nF\n<<\n0\n,\n1\n,\n2\n,\n\n     \n0\n,\n2\n,\n3\n;\n\n  \nEigen\n::\nSparseMatrix\n<\ndouble\n>\n \nL\n;\n\n  \nigl\n::\ncotmatrix\n(\nV\n,\nF\n,\nL\n);\n\n  \nstd\n::\ncout\n<<\n\"Hello, mesh: \"\n<<\nstd\n::\nendl\n<<\nL\n*\nV\n<<\nstd\n::\nendl\n;\n\n  \nreturn\n \n0\n;\n\n\n}\n\n\n\n\n\nIf you save this in \nhello.cpp\n, then you could compile this with (assuming\nEigen is installed in \n/usr/local/include/eigen3\n):\n\n\ng++ -std\n=\nc++11 -I/usr/local/include/eigen3 -I./libigl/include/ hello.cpp -o hello\n\n\n\n\nRunning \n./hello\n would then produce\n\n\nHello, mesh:\n 0.5  0.5\n-0.5  0.5\n-0.5 -0.5\n 0.5 -0.5\n\n\n\n\nDependencies\n\u00b6\n\n\nDependencies are on a per-include basis and the majority of the functions in\nlibigl depends only on the \nEigen\n library.\n\n\nFor more information see our \ntutorial\n.\n\n\nOptional Dependencies\n\u00b6\n\n\nLibigl compartmentalizes its \noptional\n dependences via its directory\norganization in the \ninclude/\n folder. All header files located \ndirectly\n in\nthe \ninclude/igl/\n folder have only stl and Eigen as dependencies. For example,\nall of the headers that depend on CGAL are located in \ninclude/igl/copyleft/cgal\n.\nFor a full list of \noptional\n dependencies check \noptional/CMakeLists.txt\n.\n\n\nGCC and the Optional CGAL Dependency\n\u00b6\n\n\nThe \ninclude/igl/copyleft/cgal/*.h\n headers depend on CGAL. It has come to\nour attention that CGAL does not work properly with GCC 4.8. To the best of\nour knowledge, GCC 4.7 and clang will work correctly.\n\n\nOpenMP and Windows\n\u00b6\n\n\nSome of our functions will take advantage of OpenMP if available. However, it\nhas come to our attention that Visual Studio + Eigen + OpenMP does not work\nproperly. Since we use OpenMP only to improve performance, we recommend\navoiding OpenMP on Windows or proceeding with caution.\n\n\nDownload\n\u00b6\n\n\nYou can keep up to date by cloning a read-only copy of our GitHub\n\nrepository\n.\n\n\nKnown Issues\n\u00b6\n\n\nWe rely heavily on Eigen. Nearly all inputs and outputs are Eigen matrices of\nsome kind. However, we currently \nonly\n officially support Eigen's default\ncolumn-major ordering. That means, we \ndo not\n expect our code to work for\nmatrices using the \nEigen::RowMajor\n flag. If you can, change definitions like:\n\n\nEigen\n::\nMatrix\n<\ndouble\n,\n \nEigen\n::\nDynamic\n,\n \n3\n,\n \nEigen\n::\nRowMajor\n>\n \nA\n;\n\n\n\n\n\nto\n\n\nEigen\n::\nMatrix\n<\ndouble\n,\n \nEigen\n::\nDynamic\n,\n \n3\n,\n \nEigen\n::\nColMajor\n>\n \nA\n;\n\n\n// or simply\n\n\nEigen\n::\nMatrix\n<\ndouble\n,\n \nEigen\n::\nDynamic\n,\n \n3\n>\n \nA\n;\n\n\n\n\n\nWe hope to fix this, or at least identify which functions are safe (many of\nthem probably work just fine). This requires setting up unit testing, which is\na major \ntodo\n for our development.\n\n\nGit Submodules\n\u00b6\n\n\nLibigl uses git submodules for its \noptional\n dependencies,\nin particular, those needed by the OpenGL viewer to run the examples in the\n\ntutorial\n. Git submodules allow use to treat clones of\nother libraries as sub-directories within ours while separating our commits.\nRead the \ndocumentation\n for a detailed\nexplanation, but essentially our libigl repo stores a hash for each of its\nsubrepos containing which version to update to. When a change is introduced in\na dependencies repo we can incorporate that change by pulling in our sub-repo\nand updating (i.e.  committing) that change to the hash.\n\n\nWhen pulling new changes to libigl it's also a good idea to update changes to\nsubrepos:\n\n\ngit pull\ngit submodule update --recursive\n\n\n\n\nUnit Testing\n\u00b6\n\n\nLibigl maintains \nseparate\nrepository\n for unit testing.\n\n\nHow to Contribute\n\u00b6\n\n\nIf you are interested in joining development, please fork the repository and\nsubmit a \npull request\n\nwith your changes. libigl follows strict coding guidelines, please take a look at our  \nstyle guidelines\n before submitting your pull requests.\n\n\nLicense\n\u00b6\n\n\nlibigl is primarily \nMPL2\n licensed\n(\nFAQ\n). Some files contain\nthird-party code under other licenses. We're currently in the processes of\nidentifying these and marking appropriately.\n\n\nAttribution\n\u00b6\n\n\nIf you use libigl in your academic projects, please cite the papers we\nimplement as appropriate. To cite the library in general, you could use this\nBibTeX entry:\n\n\n@misc\n{\nlibigl\n,\n\n  \ntitle\n \n=\n \n{{libigl}: A simple {C++} geometry processing library}\n,\n\n  \nauthor\n \n=\n \n{Alec Jacobson and Daniele Panozzo and others}\n,\n\n  \nnote\n \n=\n \n{http://libigl.github.io/libigl/}\n,\n\n  \nyear\n \n=\n \n{2017}\n,\n\n\n}\n\n\n\n\n\nProjects/Universities using libigl\n\u00b6\n\n\nLibigl is used by many research groups around the world. In 2015, it won the\nEurographics/ACM Symposium on Geometry Processing software award. Here are a\nfew labs/companies/institutions using libigl:\n\n\n\n\nActivision\n\n\nAdobe Research\n  \n\n\nElectronic Arts, Inc\n\n\nEpic Games\n\n\nGoogle Research\n\n\nIndustrial Light and Magic\n\n\nMesh consultants\n, Canada\n\n\nMicrosoft Research\n\n\nPixar\n\n\nSpine by Esoteric Software\n is an animation tool dedicated to 2D characters.\n\n\nvvvv toolkit\n a multipurpose tookit\n\n\nColumbia University, \nColumbia Computer Graphics Group\n, USA\n\n\nCornell University\n, USA\n\n\nCzech Technical University in Prague\n, Czech\n\n\nEPF Lausanne, \nComputer Graphics and Geometry Laboratory\n, Switzerland\n\n\nETH Zurich, \nInteractive Geometry Lab\n and \nAdvanced Technologies Lab\n, Swizterland\n\n\nGeorge Mason University, \nCraGL\n, USA\n\n\nHong Kong University of Science and Technology\n, Hong Kong\n\n\nInria, Universit\u00e9 Grenoble Alpes\n, France\n\n\nJiangnan university\n, China\n\n\nNational Institute of Informatics\n, Japan\n\n\nNew York University, \nMedia Research Lab\n, USA\n\n\nNYUPoly, \nGame Innovation Lab\n, USA\n\n\nTU Berlin\n, Germany\n\n\nTU Delft\n, Netherlands\n\n\nTU Wien\n, Austria\n\n\nTelecom ParisTech\n, Paris, France\n\n\nUtrecht University\n, The Netherlands\n\n\nUniversidade Federal de Santa Catarina\n, Brazil\n\n\nUniversity College London\n, England\n\n\nUniversity of California Berkeley\n, USA\n\n\nUniversity of Cambridge\n, England\n\n\nUniversity of Pennsylvania\n, USA\n\n\nUniversity of Texas at Austin\n, USA\n\n\nUniversity of Toronto\n, Canada\n\n\nUniversity of Victoria\n, Canada\n\n\nUniversity of Wisconsin-Eau Claire\n, USA\n\n\nUniversit\u00e0 della Svizzera Italiana\n, Switzerland\n\n\nUniversit\u00e9 Toulouse III Paul Sabatier\n, France\n\n\nZhejiang University\n, China\n\n\n\n\nContact\n\u00b6\n\n\nLibigl is a group endeavor led by \nAlec\nJacobson\n and \nDaniele\nPanozzo\n. Please \ncontact\nus\n if you have\nquestions or comments. For troubleshooting, please post an\n\nissue\n on github.\n\n\nIf you're using libigl in your projects, quickly \ndrop us a\nnote\n. Tell us who you\nare and what you're using it for. This helps us apply for funding and justify\nspending time maintaining this.\n\n\nIf you find bugs or have problems please use our \ngithub issue tracking\npage\n.\n\n\nCopyright\n\u00b6\n\n\n2017 Alec Jacobson, Daniele Panozzo, Christian Sch\u00fcller, Olga Diamanti, Qingnan Zhou, Sebastian Koch, Jeremie Dumas, Amir Vaxman, Nico Pietroni, Stefan Brugger, Kenshi Takayama, Wenzel Jakob, Nikolas De Giorgis, Luigi Rocca, Leonardo Sacht, Kevin Walliman, Olga Sorkine-Hornung, and others.\n\n\nPlease see individual files for appropriate copyright notices.",
            "title": "Home"
        },
        {
            "location": "/#libigl-a-simple-c-geometry-processing-library",
            "text": "https://github.com/libigl/libigl/   Get started with:  git clone --recursive https://github.com/libigl/libigl.git   libigl is a simple C++ geometry processing library. We have a wide\nfunctionality including construction of sparse discrete differential geometry\noperators and finite-elements matrices such as the cotangent Laplacian and\ndiagonalized mass matrix, simple facet and edge-based topology data structures,\nmesh-viewing utilities for OpenGL and GLSL, and many core functions for matrix\nmanipulation which make  Eigen  feel a lot more\nlike MATLAB.  It is  a header-only library . You do not need to compile anything to use,\njust include igl headers (e.g.  #include   <igl/cotmatrix.h> ) and run.  Each\nheader file contains a single function (e.g.  igl/cotmatrix.h  contains igl::cotmatrix() ). Most are tailored to operate on a generic triangle mesh\nstored in an n-by-3 matrix of vertex positions  V  and an m-by-3 matrix of\ntriangle indices  F .  Optionally  the library may also be  pre-compiled  into a statically\nlinked library, for faster compile times with your projects. This only effects\ncompile time (run-time performance and behavior is identical). If in doubt, use\nthe header-only default mode: (i.e. just include the headers you want to use).  We use the  Eigen  library heavily in our code. Our\ngroup prototypes a lot in MATLAB, and we have a useful  MATLAB to libigl+Eigen\nconversion table .  We regularly test compiling our library on Mac OS X with clang, Linux with gcc\nand Windows with Visual Studio 2015 Community Edition.",
            "title": "libigl - A simple C++ geometry processing library"
        },
        {
            "location": "/#tutorial",
            "text": "As of version 1.0, libigl includes an introductory tutorial  that covers many functionalities.",
            "title": "Tutorial"
        },
        {
            "location": "/#libigl-example-project",
            "text": "We provide a  blank project example  showing how to use libigl and cmake. Feel free and encouraged to copy or fork this project as a way of starting a new personal project using libigl.",
            "title": "libigl Example Project"
        },
        {
            "location": "/#coding-guidelines-and-tips",
            "text": "libigl follows strict coding guidelines, please take a look  here  before submitting your pull requests. We also have a set of  general coding tips  on how to code a geometry processing research project.",
            "title": "Coding Guidelines and Tips"
        },
        {
            "location": "/#installation",
            "text": "Libigl is a  header-only  library. You do  not  need to build anything to\ninstall.  Simply add  libigl/include  to your include path and include relevant\nheaders.  Here is a small \"Hello, World\" program:  #include   <igl/cotmatrix.h>  #include   <Eigen/Dense>  #include   <Eigen/Sparse>  #include   <iostream>  int   main ()  { \n   Eigen :: MatrixXd   V ( 4 , 2 ); \n   V << 0 , 0 , \n      1 , 0 , \n      1 , 1 , \n      0 , 1 ; \n   Eigen :: MatrixXi   F ( 2 , 3 ); \n   F << 0 , 1 , 2 , \n      0 , 2 , 3 ; \n   Eigen :: SparseMatrix < double >   L ; \n   igl :: cotmatrix ( V , F , L ); \n   std :: cout << \"Hello, mesh: \" << std :: endl << L * V << std :: endl ; \n   return   0 ;  }   If you save this in  hello.cpp , then you could compile this with (assuming\nEigen is installed in  /usr/local/include/eigen3 ):  g++ -std = c++11 -I/usr/local/include/eigen3 -I./libigl/include/ hello.cpp -o hello  Running  ./hello  would then produce  Hello, mesh:\n 0.5  0.5\n-0.5  0.5\n-0.5 -0.5\n 0.5 -0.5",
            "title": "Installation"
        },
        {
            "location": "/#dependencies",
            "text": "Dependencies are on a per-include basis and the majority of the functions in\nlibigl depends only on the  Eigen  library.  For more information see our  tutorial .",
            "title": "Dependencies"
        },
        {
            "location": "/#optional-dependencies",
            "text": "Libigl compartmentalizes its  optional  dependences via its directory\norganization in the  include/  folder. All header files located  directly  in\nthe  include/igl/  folder have only stl and Eigen as dependencies. For example,\nall of the headers that depend on CGAL are located in  include/igl/copyleft/cgal .\nFor a full list of  optional  dependencies check  optional/CMakeLists.txt .",
            "title": "Optional Dependencies"
        },
        {
            "location": "/#gcc-and-the-optional-cgal-dependency",
            "text": "The  include/igl/copyleft/cgal/*.h  headers depend on CGAL. It has come to\nour attention that CGAL does not work properly with GCC 4.8. To the best of\nour knowledge, GCC 4.7 and clang will work correctly.",
            "title": "GCC and the Optional CGAL Dependency"
        },
        {
            "location": "/#openmp-and-windows",
            "text": "Some of our functions will take advantage of OpenMP if available. However, it\nhas come to our attention that Visual Studio + Eigen + OpenMP does not work\nproperly. Since we use OpenMP only to improve performance, we recommend\navoiding OpenMP on Windows or proceeding with caution.",
            "title": "OpenMP and Windows"
        },
        {
            "location": "/#download",
            "text": "You can keep up to date by cloning a read-only copy of our GitHub repository .",
            "title": "Download"
        },
        {
            "location": "/#known-issues",
            "text": "We rely heavily on Eigen. Nearly all inputs and outputs are Eigen matrices of\nsome kind. However, we currently  only  officially support Eigen's default\ncolumn-major ordering. That means, we  do not  expect our code to work for\nmatrices using the  Eigen::RowMajor  flag. If you can, change definitions like:  Eigen :: Matrix < double ,   Eigen :: Dynamic ,   3 ,   Eigen :: RowMajor >   A ;   to  Eigen :: Matrix < double ,   Eigen :: Dynamic ,   3 ,   Eigen :: ColMajor >   A ;  // or simply  Eigen :: Matrix < double ,   Eigen :: Dynamic ,   3 >   A ;   We hope to fix this, or at least identify which functions are safe (many of\nthem probably work just fine). This requires setting up unit testing, which is\na major  todo  for our development.",
            "title": "Known Issues"
        },
        {
            "location": "/#git-submodules",
            "text": "Libigl uses git submodules for its  optional  dependencies,\nin particular, those needed by the OpenGL viewer to run the examples in the tutorial . Git submodules allow use to treat clones of\nother libraries as sub-directories within ours while separating our commits.\nRead the  documentation  for a detailed\nexplanation, but essentially our libigl repo stores a hash for each of its\nsubrepos containing which version to update to. When a change is introduced in\na dependencies repo we can incorporate that change by pulling in our sub-repo\nand updating (i.e.  committing) that change to the hash.  When pulling new changes to libigl it's also a good idea to update changes to\nsubrepos:  git pull\ngit submodule update --recursive",
            "title": "Git Submodules"
        },
        {
            "location": "/#unit-testing",
            "text": "Libigl maintains  separate\nrepository  for unit testing.",
            "title": "Unit Testing"
        },
        {
            "location": "/#how-to-contribute",
            "text": "If you are interested in joining development, please fork the repository and\nsubmit a  pull request \nwith your changes. libigl follows strict coding guidelines, please take a look at our   style guidelines  before submitting your pull requests.",
            "title": "How to Contribute"
        },
        {
            "location": "/#license",
            "text": "libigl is primarily  MPL2  licensed\n( FAQ ). Some files contain\nthird-party code under other licenses. We're currently in the processes of\nidentifying these and marking appropriately.",
            "title": "License"
        },
        {
            "location": "/#attribution",
            "text": "If you use libigl in your academic projects, please cite the papers we\nimplement as appropriate. To cite the library in general, you could use this\nBibTeX entry:  @misc { libigl , \n   title   =   {{libigl}: A simple {C++} geometry processing library} , \n   author   =   {Alec Jacobson and Daniele Panozzo and others} , \n   note   =   {http://libigl.github.io/libigl/} , \n   year   =   {2017} ,  }",
            "title": "Attribution"
        },
        {
            "location": "/#projectsuniversities-using-libigl",
            "text": "Libigl is used by many research groups around the world. In 2015, it won the\nEurographics/ACM Symposium on Geometry Processing software award. Here are a\nfew labs/companies/institutions using libigl:   Activision  Adobe Research     Electronic Arts, Inc  Epic Games  Google Research  Industrial Light and Magic  Mesh consultants , Canada  Microsoft Research  Pixar  Spine by Esoteric Software  is an animation tool dedicated to 2D characters.  vvvv toolkit  a multipurpose tookit  Columbia University,  Columbia Computer Graphics Group , USA  Cornell University , USA  Czech Technical University in Prague , Czech  EPF Lausanne,  Computer Graphics and Geometry Laboratory , Switzerland  ETH Zurich,  Interactive Geometry Lab  and  Advanced Technologies Lab , Swizterland  George Mason University,  CraGL , USA  Hong Kong University of Science and Technology , Hong Kong  Inria, Universit\u00e9 Grenoble Alpes , France  Jiangnan university , China  National Institute of Informatics , Japan  New York University,  Media Research Lab , USA  NYUPoly,  Game Innovation Lab , USA  TU Berlin , Germany  TU Delft , Netherlands  TU Wien , Austria  Telecom ParisTech , Paris, France  Utrecht University , The Netherlands  Universidade Federal de Santa Catarina , Brazil  University College London , England  University of California Berkeley , USA  University of Cambridge , England  University of Pennsylvania , USA  University of Texas at Austin , USA  University of Toronto , Canada  University of Victoria , Canada  University of Wisconsin-Eau Claire , USA  Universit\u00e0 della Svizzera Italiana , Switzerland  Universit\u00e9 Toulouse III Paul Sabatier , France  Zhejiang University , China",
            "title": "Projects/Universities using libigl"
        },
        {
            "location": "/#contact",
            "text": "Libigl is a group endeavor led by  Alec\nJacobson  and  Daniele\nPanozzo . Please  contact\nus  if you have\nquestions or comments. For troubleshooting, please post an issue  on github.  If you're using libigl in your projects, quickly  drop us a\nnote . Tell us who you\nare and what you're using it for. This helps us apply for funding and justify\nspending time maintaining this.  If you find bugs or have problems please use our  github issue tracking\npage .",
            "title": "Contact"
        },
        {
            "location": "/#copyright",
            "text": "2017 Alec Jacobson, Daniele Panozzo, Christian Sch\u00fcller, Olga Diamanti, Qingnan Zhou, Sebastian Koch, Jeremie Dumas, Amir Vaxman, Nico Pietroni, Stefan Brugger, Kenshi Takayama, Wenzel Jakob, Nikolas De Giorgis, Luigi Rocca, Leonardo Sacht, Kevin Walliman, Olga Sorkine-Hornung, and others.  Please see individual files for appropriate copyright notices.",
            "title": "Copyright"
        },
        {
            "location": "/tutorial/chapter-1/",
            "text": "html header:   \n\n\n\n\n\n\nhljs.initHighlightingOnLoad();\n\n\nlibigl tutorial notes\n\u00b6\n\n\noriginally presented by Daniele Panozzo and Alec Jacobson at SGP Graduate School 2014\n\u00b6\n\n\n\n\nLibigl is an open source C++ library for geometry processing research and development.  Dropping the heavy data structures of tradition geometry libraries, libigl is a simple header-only library of encapsulated functions. This combines the rapid prototyping familiar to Matlab or Python programmers with the performance and versatility of C++.  The tutorial is a self-contained, hands-on introduction to libigl.  Via interactive, step-by-step examples, we demonstrate how to accomplish common geometry processing tasks such as computation of differential quantities and operators, real-time deformation, parametrization, numerical optimization and remeshing. Each section of the lecture notes links to a cross-platform example application.\n\n\nChapter 1 [chapter1:introductiontolibigl]\n\u00b6\n\n\nWe introduce libigl with a series of self-contained examples. The purpose of\neach example is to showcase a feature of libigl while applying to a practical\nproblem in geometry processing. In this chapter, we will present the basic\nconcepts of libigl and introduce a simple mesh viewer that allows to\nvisualize a surface mesh and its attributes. All the tutorial examples are\ncross-platform and can be compiled on MacOSX, Linux and Windows.\n\n\nlibigl design principles\n [libigldesignprinciples]\n\u00b6\n\n\nBefore getting into the examples, we summarize the main design principles in\nlibigl:\n\n\n\n\n\n\nNo complex data types.\n We mostly use matrices and vectors. This greatly\n  favors code reusability and forces the function authors to expose all the\n  parameters used by the algorithm.  \n\n\n\n\n\n\nMinimal dependencies.\n We use external libraries only when necessary and\n  we wrap them in a small set of functions.\n\n\n\n\n\n\nHeader-only.\n It is straight forward to use our library since it is only\n  one additional include directory in your project. (if you are worried about\n  compilation speed, it is also possible to build the library as a \nstatic\n  library\n)\n\n\n\n\n\n\nFunction encapsulation.\n Every function (including its full\n  implementation) is contained in a pair of .h/.cpp files with the same name of\n  the function.\n\n\n\n\n\n\nDownloading libigl\n\u00b6\n\n\nlibigl can be downloaded from our \ngithub\nrepository\n or cloned with git:\n\n\ngit clone --recursive https://github.com/libigl/libigl.git\n\n\n\n\nThe core libigl functionality only depends on the C++ Standard Library and\nEigen.\n\n\nTo build all the examples in the tutorial, you can use the CMakeLists.txt in\nthe tutorial folder:\n\n\ncd\n tutorial\nmkdir build\n\ncd\n build\ncmake -DCMAKE_BUILD_TYPE\n=\nRelease ../\nmake\n\n\n\n\nThe examples can also be built independently using the CMakeLists.txt\ninside each example folder.\n\n\nNote for linux users\n: Many linux distributions do not include gcc and the basic development tools\nin their default installation. On Ubuntu, you need to install the following packages:\n\n\nsudo apt-get install git\nsudo apt-get install build-essential\nsudo apt-get install cmake\nsudo apt-get install libx11-dev\nsudo apt-get install mesa-common-dev libgl1-mesa-dev libglu1-mesa-dev\nsudo apt-get install libxrandr-dev\nsudo apt-get install libxi-dev\nsudo apt-get install libxmu-dev\nsudo apt-get install libblas-dev\nsudo apt-get install libxinerama-dev\nsudo apt-get install libxcursor-dev\n\n\n\nNote for windows users\n: libigl only supports the Microsoft Visual Studio 2015 compiler in 64bit mode. It will not work with a 32bit build and it will not work\nwith older versions of visual studio.\n\n\nA few examples in Chapter 5 requires the \nCoMiSo\nsolver\n. We provide a\nmirror of CoMISo that works out of the box with libigl. To install it:\n\n\ncd\n libigl/external\ngit clone --recursive https://github.com/libigl/CoMISo.git\n\n\n\n\nYou can then build the tutorials again and it libigl will automatically find and\ncompile CoMISo.\n\n\nNote 1\n: CoMISo is distributed under the GPL3 license, it does impose restrictions on commercial usage.\n\n\nNote 2\n: CoMISo requires a blas implementation. We use the built-in blas in macosx and linux, and we bundle a precompiled binary for VS2015 64 bit. Do NOT compile the tutorials\nin 32 bit on windows.\n\n\nlibigl example project\n\u00b6\n\n\nWe provide a \nblank project example\n showing how to use libigl and cmake. Feel free and encouraged to copy or fork this project as a way of starting a new personal project using libigl.\n\n\nMesh representation\n [meshrepresentation]\n\u00b6\n\n\nlibigl uses the \nEigen\n library to encode vector\nand matrices. We suggest that you keep the\n\ndense\n and\n\nsparse\n quick\nreference guides at hand while you read the examples in this tutorial.\n\n\nA triangular mesh is encoded as a pair of matrices:\n\n\nEigen\n::\nMatrixXd\n \nV\n;\n\n\nEigen\n::\nMatrixXi\n \nF\n;\n\n\n\n\n\nV\n is a #N by 3 matrix which stores the coordinates of the vertices. Each\nrow stores the coordinate of a vertex, with its x,y and z coordinates in the first,\nsecond and third column, respectively. The matrix \nF\n stores the triangle\nconnectivity: each line of \nF\n denotes a triangle whose 3 vertices are\nrepresented as indices pointing to rows of \nV\n.\n\n\n\n\nNote that the order of the vertex indices in \nF\n determines the orientation of\nthe triangles and it should thus be consistent for the entire surface.\nThis simple representation has many advantages:\n\n\n\n\nit is memory efficient and cache friendly\n\n\nthe use of indices instead of pointers greatly simplifies debugging\n\n\nthe data can be trivially copied and serialized\n\n\n\n\nlibigl provides input [output] functions to read [write] many common mesh formats.\nThe IO functions are contained in the files read*.h and write*.h. As a general\nrule each libigl function is contained in a pair of .h/.cpp files with the same name.\nBy default, the .h files include the corresponding cpp files, making the library header-only.\n\n\nReading a mesh from a file requires a single libigl function call:\n\n\nigl\n::\nreadOFF\n(\nTUTORIAL_SHARED_PATH\n \n\"/cube.off\"\n,\n \nV\n,\n \nF\n);\n\n\n\n\n\nThe function reads the mesh cube.off and it fills the provided \nV\n and \nF\n matrices.\nSimilarly, a mesh can be written in an OBJ file using:\n\n\nigl\n::\nwriteOBJ\n(\n\"cube.obj\"\n,\nV\n,\nF\n);\n\n\n\n\n\nExample 101\n contains a simple mesh\nconverter from OFF to OBJ format.\n\n\nVisualizing surfaces\n [visualizingsurfaces]\n\u00b6\n\n\nLibigl provides an glfw-based OpenGL 3.2 viewer to visualize surfaces, their\nproperties and additional debugging information.\n\n\nThe following code (\nExample 102\n) is a basic skeleton\nfor all the examples that will be used in the tutorial.\nIt is a standalone application that loads a mesh and uses the viewer to\nrender it.\n\n\n#include\n \n<igl/readOFF.h>\n\n\n#include\n \n<igl/opengl/glfw/Viewer.h>\n\n\n\nEigen\n::\nMatrixXd\n \nV\n;\n\n\nEigen\n::\nMatrixXi\n \nF\n;\n\n\n\nint\n \nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n  \n// Load a mesh in OFF format\n\n  \nigl\n::\nreadOFF\n(\nTUTORIAL_SHARED_PATH\n \n\"/bunny.off\"\n,\n \nV\n,\n \nF\n);\n\n\n  \n// Plot the mesh\n\n  \nigl\n::\nopengl\n::\nglfw\n::\nViewer\n \nviewer\n;\n\n  \nviewer\n.\ndata\n().\nset_mesh\n(\nV\n,\n \nF\n);\n\n  \nviewer\n.\nlaunch\n();\n\n\n}\n\n\n\n\n\nThe function \nset_mesh\n copies the mesh into the viewer.\n\nViewer.launch()\n  creates a window, an OpenGL context and it starts the draw loop.\nAdditional properties can be plotted on the mesh (as we will see later),\nand it is possible to extend the viewer with standard OpenGL code.\nPlease see the documentation in\n\nViewer.h\n for more details.\n\n\n\n\nInteraction with keyboard and mouse\n [interactionwithkeyboardandmouse]\n\u00b6\n\n\nKeyboard and mouse events triggers callbacks that can be registered in the\nviewer. The viewer supports the following callbacks:\n\n\nbool\n \n(\n*\ncallback_pre_draw\n)(\nViewer\n&\n \nviewer\n);\n\n\nbool\n \n(\n*\ncallback_post_draw\n)(\nViewer\n&\n \nviewer\n);\n\n\nbool\n \n(\n*\ncallback_mouse_down\n)(\nViewer\n&\n \nviewer\n,\n \nint\n \nbutton\n,\n \nint\n \nmodifier\n);\n\n\nbool\n \n(\n*\ncallback_mouse_up\n)(\nViewer\n&\n \nviewer\n,\n \nint\n \nbutton\n,\n \nint\n \nmodifier\n);\n\n\nbool\n \n(\n*\ncallback_mouse_move\n)(\nViewer\n&\n \nviewer\n,\n \nint\n \nmouse_x\n,\n \nint\n \nmouse_y\n);\n\n\nbool\n \n(\n*\ncallback_mouse_scroll\n)(\nViewer\n&\n \nviewer\n,\n \nfloat\n \ndelta_y\n);\n\n\nbool\n \n(\n*\ncallback_key_down\n)(\nViewer\n&\n \nviewer\n,\n \nunsigned\n \nchar\n \nkey\n,\n \nint\n \nmodifiers\n);\n\n\nbool\n \n(\n*\ncallback_key_up\n)(\nViewer\n&\n \nviewer\n,\n \nunsigned\n \nchar\n \nkey\n,\n \nint\n \nmodifiers\n);\n\n\n\n\n\nA keyboard callback can be used to visualize multiple meshes or different\nstages of an algorithm, as demonstrated in \nExample 103\n, where\nthe keyboard callback changes the visualized mesh depending on the key pressed:\n\n\nbool\n \nkey_down\n(\nigl\n::\nopengl\n::\nglfw\n::\nViewer\n&\n \nviewer\n,\n \nunsigned\n \nchar\n \nkey\n,\n \nint\n \nmodifier\n)\n\n\n{\n\n  \nif\n \n(\nkey\n \n==\n \n'1'\n)\n\n  \n{\n\n    \nviewer\n.\ndata\n().\nclear\n();\n\n    \nviewer\n.\ndata\n().\nset_mesh\n(\nV1\n,\n \nF1\n);\n\n    \nviewer\n.\ncore\n.\nalign_camera_center\n(\nV1\n,\nF1\n);\n\n  \n}\n\n  \nelse\n \nif\n \n(\nkey\n \n==\n \n'2'\n)\n\n  \n{\n\n    \nviewer\n.\ndata\n().\nclear\n();\n\n    \nviewer\n.\ndata\n().\nset_mesh\n(\nV2\n,\n \nF2\n);\n\n    \nviewer\n.\ncore\n.\nalign_camera_center\n(\nV2\n,\nF2\n);\n\n  \n}\n\n  \nreturn\n \nfalse\n;\n\n\n}\n\n\n\n\n\nThe callback is registered in the viewer as follows:\n\n\nviewer\n.\ncallback_key_down\n \n=\n \n&\nkey_down\n;\n\n\n\n\n\nNote that the mesh is cleared before using set_mesh. This has to be called\nevery time the number of vertices or faces of the plotted mesh changes. Every\ncallback returns a boolean value that tells the viewer if the event has been\nhandled by the plugin, or if the viewer should process it normally. This is\nuseful, for example, to disable the default mouse event handling if you want to\ncontrol the camera directly in your code.\n\n\nThe viewer can be extended using plugins, which are classes that implements all\nthe viewer's callbacks. See the\n\nViewer_plugin\n for more details.\n\n\nScalar field visualization\n [scalarfieldvisualization]\n\u00b6\n\n\nColors and normals can be associated to faces or vertices using the\nset_colors function:\n\n\nviewer\n.\ndata\n().\nset_colors\n(\nC\n);\n\n\n\n\n\nC\n is a #C by 3 matrix with one RGB color per row. \nC\n must have as many\nrows as the number of faces \nor\n the number of vertices of the mesh.\nDepending on the size of \nC\n, the viewer applies the color to the faces or to\nthe vertices.\n\n\nColors can be used to visualize a scalar function defined on a surface.  The\nscalar function is converted to colors using a color transfer function, which\nmaps a scalar value between 0 and 1 to a color. A simple example of a scalar\nfield defined on a surface is the z coordinate of each point, which can be\nextract from our mesh representation by taking the last column of \nV\n\n(\nExample 104\n). The function \nigl::jet\n can be used to\nconvert it to colors:\n\n\nEigen\n::\nVectorXd\n \nZ\n \n=\n \nV\n.\ncol\n(\n2\n);\n\n\nigl\n::\njet\n(\nZ\n,\ntrue\n,\nC\n);\n\n\n\n\n\nThe first row extracts the third column from \nV\n (the z coordinate of each\nvertex) and the second calls a libigl functions that converts a scalar field to colors. The second parameter of jet normalizes the scalar field to lie between 0 and 1 before applying the transfer function.\n\n\n\n\nigl::jet\n is an example of a standard function in libigl: it takes simple\ntypes and can be easily reused for many different tasks.  Not committing to\nheavy data structures types favors simplicity, ease of use and reusability.\n\n\nOverlays\n [overlays]\n\u00b6\n\n\nIn addition to plotting the surface, the viewer supports the visualization of points, lines and text labels: these overlays can be very helpful while developing geometric processing algorithms to plot debug information.\n\n\nviewer\n.\ndata\n().\nadd_points\n(\nP\n,\nEigen\n::\nRowVector3d\n(\nr\n,\ng\n,\nb\n));\n\n\n\n\n\nDraws a point of color r,g,b for each row of P. The point is placed at the coordinates specified in each row of P, which is a #P by 3 matrix.\n\n\nviewer\n.\ndata\n().\nadd_edges\n(\nP1\n,\nP2\n,\nEigen\n::\nRowVector3d\n(\nr\n,\ng\n,\nb\n);\n\n\n\n\n\nDraws a line of color r,g,b for each row of P1 and P2, which connects the 3D point in to the point in P2. Both P1 and P2 are of size #P by 3.\n\n\nviewer\n.\ndata\n().\nadd_label\n(\np\n,\nstr\n);\n\n\n\n\n\nDraws a label containing the string str at the position p, which is a vector of length 3.\n\n\nThese functions are demonstrate in \nExample 105\n where\nthe bounding box of a mesh is plotted using lines and points.\nUsing matrices to encode the mesh and its attributes allows to write short and\nefficient code for many operations, avoiding to write for loops. For example,\nthe bounding box of a mesh can be found by taking the colwise maximum and minimum of \nV\n:\n\n\nEigen\n::\nVector3d\n \nm\n \n=\n \nV\n.\ncolwise\n().\nminCoeff\n();\n\n\nEigen\n::\nVector3d\n \nM\n \n=\n \nV\n.\ncolwise\n().\nmaxCoeff\n();\n\n\n\n\n\n\n\nViewer Menu\n [viewermenu]\n\u00b6\n\n\nAs of latest version, the viewer uses a new menu and completely replaces\n\nAntTweakBar\n and\n\nnanogui\n with \nDear ImGui\n. To extend the default menu of the\nviewer and to expose more user defined variables you have to implement a custom interface, as in \nExample 106\n:\n\n// Add content to the default menu window\n\n\nmenu\n.\ncallback_draw_viewer_menu\n \n=\n \n[\n&\n]()\n\n\n{\n\n  \n// Draw parent menu content\n\n  \nmenu\n.\ndraw_viewer_menu\n();\n\n\n  \n// Add new group\n\n  \nif\n \n(\nImGui\n::\nCollapsingHeader\n(\n\"New Group\"\n,\n \nImGuiTreeNodeFlags_DefaultOpen\n))\n\n  \n{\n\n    \n// Expose variable directly ...\n\n    \nImGui\n::\nInputFloat\n(\n\"float\"\n,\n \n&\nfloatVariable\n,\n \n0\n,\n \n0\n,\n \n3\n);\n\n\n    \n// ... or using a custom callback\n\n    \nstatic\n \nbool\n \nboolVariable\n \n=\n \ntrue\n;\n\n    \nif\n \n(\nImGui\n::\nCheckbox\n(\n\"bool\"\n,\n \n&\nboolVariable\n))\n\n    \n{\n\n      \n// do something\n\n      \nstd\n::\ncout\n \n<<\n \n\"boolVariable: \"\n \n<<\n \nstd\n::\nboolalpha\n \n<<\n \nboolVariable\n \n<<\n \nstd\n::\nendl\n;\n\n    \n}\n\n\n    \n// Expose an enumeration type\n\n    \nenum\n \nOrientation\n \n{\n \nUp\n=\n0\n,\n \nDown\n,\n \nLeft\n,\n \nRight\n \n};\n\n    \nstatic\n \nOrientation\n \ndir\n \n=\n \nUp\n;\n\n    \nImGui\n::\nCombo\n(\n\"Direction\"\n,\n \n(\nint\n \n*\n)(\n&\ndir\n),\n \n\"Up\n\\0\nDown\n\\0\nLeft\n\\0\nRight\n\\0\\0\n\"\n);\n\n\n    \n// We can also use a std::vector<std::string> defined dynamically\n\n    \nstatic\n \nint\n \nnum_choices\n \n=\n \n3\n;\n\n    \nstatic\n \nstd\n::\nvector\n<\nstd\n::\nstring\n>\n \nchoices\n;\n\n    \nstatic\n \nint\n \nidx_choice\n \n=\n \n0\n;\n\n    \nif\n \n(\nImGui\n::\nInputInt\n(\n\"Num letters\"\n,\n \n&\nnum_choices\n))\n\n    \n{\n\n      \nnum_choices\n \n=\n \nstd\n::\nmax\n(\n1\n,\n \nstd\n::\nmin\n(\n26\n,\n \nnum_choices\n));\n\n    \n}\n\n    \nif\n \n(\nnum_choices\n \n!=\n \n(\nint\n)\n \nchoices\n.\nsize\n())\n\n    \n{\n\n      \nchoices\n.\nresize\n(\nnum_choices\n);\n\n      \nfor\n \n(\nint\n \ni\n \n=\n \n0\n;\n \ni\n \n<\n \nnum_choices\n;\n \n++\ni\n)\n\n        \nchoices\n[\ni\n]\n \n=\n \nstd\n::\nstring\n(\n1\n,\n \n'A'\n \n+\n \ni\n);\n\n      \nif\n \n(\nidx_choice\n \n>=\n \nnum_choices\n)\n\n        \nidx_choice\n \n=\n \nnum_choices\n \n-\n \n1\n;\n\n    \n}\n\n    \nImGui\n::\nCombo\n(\n\"Letter\"\n,\n \n&\nidx_choice\n,\n \nchoices\n);\n\n\n    \n// Add a button\n\n    \nif\n \n(\nImGui\n::\nButton\n(\n\"Print Hello\"\n,\n \nImVec2\n(\n-\n1\n,\n0\n)))\n\n    \n{\n\n      \nstd\n::\ncout\n \n<<\n \n\"Hello\n\\n\n\"\n;\n\n    \n}\n\n  \n}\n\n\n};\n\n\n\n\nIf you need a separate new menu window implement:\n\n\n// Draw additional windows\n\n\nmenu\n.\ncallback_draw_custom_window\n \n=\n \n[\n&\n]()\n\n\n{\n\n  \n// Define next window position + size\n\n  \nImGui\n::\nSetNextWindowPos\n(\nImVec2\n(\n180.f\n \n*\n \nmenu\n.\nmenu_scaling\n(),\n \n10\n),\n \nImGuiSetCond_FirstUseEver\n);\n\n  \nImGui\n::\nSetNextWindowSize\n(\nImVec2\n(\n200\n,\n \n160\n),\n \nImGuiSetCond_FirstUseEver\n);\n\n  \nImGui\n::\nBegin\n(\n\n      \n\"New Window\"\n,\n \nnullptr\n,\n\n      \nImGuiWindowFlags_NoSavedSettings\n\n  \n);\n\n\n  \n// Expose the same variable directly ...\n\n  \nImGui\n::\nPushItemWidth\n(\n-\n80\n);\n\n  \nImGui\n::\nDragFloat\n(\n\"float\"\n,\n \n&\nfloatVariable\n,\n \n0.0\n,\n \n0.0\n,\n \n3.0\n);\n\n  \nImGui\n::\nPopItemWidth\n();\n\n\n  \nstatic\n \nstd\n::\nstring\n \nstr\n \n=\n \n\"bunny\"\n;\n\n  \nImGui\n::\nInputText\n(\n\"Name\"\n,\n \nstr\n);\n\n\n  \nImGui\n::\nEnd\n();\n\n\n};\n\n\n\n\n\n\n\nMultiple Meshes\n [multiplemeshes]\n\u00b6\n\n\nLibigl's \nigl::opengl::glfw::Viewer\n provides basic support for rendering\nmultiple meshes.\n\n\nWhich mesh is \nselected\n is controlled via the \nviewer.selected_data_index\n\nfield. By default it his is set to \n0\n, so in the typical case of a single mesh\n\nviewer.data()\n returns the \nigl::ViewerData\n corresponding to the one\nand only mesh.",
            "title": "Chapter 1: Introduction to libigl"
        },
        {
            "location": "/tutorial/chapter-1/#libigl-tutorial-notes",
            "text": "",
            "title": "libigl tutorial notes"
        },
        {
            "location": "/tutorial/chapter-1/#originally-presented-by-daniele-panozzo-and-alec-jacobson-at-sgp-graduate-school-2014",
            "text": "Libigl is an open source C++ library for geometry processing research and development.  Dropping the heavy data structures of tradition geometry libraries, libigl is a simple header-only library of encapsulated functions. This combines the rapid prototyping familiar to Matlab or Python programmers with the performance and versatility of C++.  The tutorial is a self-contained, hands-on introduction to libigl.  Via interactive, step-by-step examples, we demonstrate how to accomplish common geometry processing tasks such as computation of differential quantities and operators, real-time deformation, parametrization, numerical optimization and remeshing. Each section of the lecture notes links to a cross-platform example application.",
            "title": "originally presented by Daniele Panozzo and Alec Jacobson at SGP Graduate School 2014"
        },
        {
            "location": "/tutorial/chapter-1/#chapter-1-chapter1introductiontolibigl",
            "text": "We introduce libigl with a series of self-contained examples. The purpose of\neach example is to showcase a feature of libigl while applying to a practical\nproblem in geometry processing. In this chapter, we will present the basic\nconcepts of libigl and introduce a simple mesh viewer that allows to\nvisualize a surface mesh and its attributes. All the tutorial examples are\ncross-platform and can be compiled on MacOSX, Linux and Windows.",
            "title": "Chapter 1 [chapter1:introductiontolibigl]"
        },
        {
            "location": "/tutorial/chapter-1/#libigl-design-principles-libigldesignprinciples",
            "text": "Before getting into the examples, we summarize the main design principles in\nlibigl:    No complex data types.  We mostly use matrices and vectors. This greatly\n  favors code reusability and forces the function authors to expose all the\n  parameters used by the algorithm.      Minimal dependencies.  We use external libraries only when necessary and\n  we wrap them in a small set of functions.    Header-only.  It is straight forward to use our library since it is only\n  one additional include directory in your project. (if you are worried about\n  compilation speed, it is also possible to build the library as a  static\n  library )    Function encapsulation.  Every function (including its full\n  implementation) is contained in a pair of .h/.cpp files with the same name of\n  the function.",
            "title": "libigl design principles [libigldesignprinciples]"
        },
        {
            "location": "/tutorial/chapter-1/#downloading-libigl",
            "text": "libigl can be downloaded from our  github\nrepository  or cloned with git:  git clone --recursive https://github.com/libigl/libigl.git  The core libigl functionality only depends on the C++ Standard Library and\nEigen.  To build all the examples in the tutorial, you can use the CMakeLists.txt in\nthe tutorial folder:  cd  tutorial\nmkdir build cd  build\ncmake -DCMAKE_BUILD_TYPE = Release ../\nmake  The examples can also be built independently using the CMakeLists.txt\ninside each example folder.  Note for linux users : Many linux distributions do not include gcc and the basic development tools\nin their default installation. On Ubuntu, you need to install the following packages:  sudo apt-get install git\nsudo apt-get install build-essential\nsudo apt-get install cmake\nsudo apt-get install libx11-dev\nsudo apt-get install mesa-common-dev libgl1-mesa-dev libglu1-mesa-dev\nsudo apt-get install libxrandr-dev\nsudo apt-get install libxi-dev\nsudo apt-get install libxmu-dev\nsudo apt-get install libblas-dev\nsudo apt-get install libxinerama-dev\nsudo apt-get install libxcursor-dev  Note for windows users : libigl only supports the Microsoft Visual Studio 2015 compiler in 64bit mode. It will not work with a 32bit build and it will not work\nwith older versions of visual studio.  A few examples in Chapter 5 requires the  CoMiSo\nsolver . We provide a\nmirror of CoMISo that works out of the box with libigl. To install it:  cd  libigl/external\ngit clone --recursive https://github.com/libigl/CoMISo.git  You can then build the tutorials again and it libigl will automatically find and\ncompile CoMISo.  Note 1 : CoMISo is distributed under the GPL3 license, it does impose restrictions on commercial usage.  Note 2 : CoMISo requires a blas implementation. We use the built-in blas in macosx and linux, and we bundle a precompiled binary for VS2015 64 bit. Do NOT compile the tutorials\nin 32 bit on windows.",
            "title": "Downloading libigl"
        },
        {
            "location": "/tutorial/chapter-1/#libigl-example-project",
            "text": "We provide a  blank project example  showing how to use libigl and cmake. Feel free and encouraged to copy or fork this project as a way of starting a new personal project using libigl.",
            "title": "libigl example project"
        },
        {
            "location": "/tutorial/chapter-1/#mesh-representation-meshrepresentation",
            "text": "libigl uses the  Eigen  library to encode vector\nand matrices. We suggest that you keep the dense  and sparse  quick\nreference guides at hand while you read the examples in this tutorial.  A triangular mesh is encoded as a pair of matrices:  Eigen :: MatrixXd   V ;  Eigen :: MatrixXi   F ;   V  is a #N by 3 matrix which stores the coordinates of the vertices. Each\nrow stores the coordinate of a vertex, with its x,y and z coordinates in the first,\nsecond and third column, respectively. The matrix  F  stores the triangle\nconnectivity: each line of  F  denotes a triangle whose 3 vertices are\nrepresented as indices pointing to rows of  V .   Note that the order of the vertex indices in  F  determines the orientation of\nthe triangles and it should thus be consistent for the entire surface.\nThis simple representation has many advantages:   it is memory efficient and cache friendly  the use of indices instead of pointers greatly simplifies debugging  the data can be trivially copied and serialized   libigl provides input [output] functions to read [write] many common mesh formats.\nThe IO functions are contained in the files read*.h and write*.h. As a general\nrule each libigl function is contained in a pair of .h/.cpp files with the same name.\nBy default, the .h files include the corresponding cpp files, making the library header-only.  Reading a mesh from a file requires a single libigl function call:  igl :: readOFF ( TUTORIAL_SHARED_PATH   \"/cube.off\" ,   V ,   F );   The function reads the mesh cube.off and it fills the provided  V  and  F  matrices.\nSimilarly, a mesh can be written in an OBJ file using:  igl :: writeOBJ ( \"cube.obj\" , V , F );   Example 101  contains a simple mesh\nconverter from OFF to OBJ format.",
            "title": "Mesh representation [meshrepresentation]"
        },
        {
            "location": "/tutorial/chapter-1/#visualizing-surfaces-visualizingsurfaces",
            "text": "Libigl provides an glfw-based OpenGL 3.2 viewer to visualize surfaces, their\nproperties and additional debugging information.  The following code ( Example 102 ) is a basic skeleton\nfor all the examples that will be used in the tutorial.\nIt is a standalone application that loads a mesh and uses the viewer to\nrender it.  #include   <igl/readOFF.h>  #include   <igl/opengl/glfw/Viewer.h>  Eigen :: MatrixXd   V ;  Eigen :: MatrixXi   F ;  int   main ( int   argc ,   char   * argv [])  { \n   // Load a mesh in OFF format \n   igl :: readOFF ( TUTORIAL_SHARED_PATH   \"/bunny.off\" ,   V ,   F ); \n\n   // Plot the mesh \n   igl :: opengl :: glfw :: Viewer   viewer ; \n   viewer . data (). set_mesh ( V ,   F ); \n   viewer . launch ();  }   The function  set_mesh  copies the mesh into the viewer. Viewer.launch()   creates a window, an OpenGL context and it starts the draw loop.\nAdditional properties can be plotted on the mesh (as we will see later),\nand it is possible to extend the viewer with standard OpenGL code.\nPlease see the documentation in Viewer.h  for more details.",
            "title": "Visualizing surfaces [visualizingsurfaces]"
        },
        {
            "location": "/tutorial/chapter-1/#interaction-with-keyboard-and-mouse-interactionwithkeyboardandmouse",
            "text": "Keyboard and mouse events triggers callbacks that can be registered in the\nviewer. The viewer supports the following callbacks:  bool   ( * callback_pre_draw )( Viewer &   viewer );  bool   ( * callback_post_draw )( Viewer &   viewer );  bool   ( * callback_mouse_down )( Viewer &   viewer ,   int   button ,   int   modifier );  bool   ( * callback_mouse_up )( Viewer &   viewer ,   int   button ,   int   modifier );  bool   ( * callback_mouse_move )( Viewer &   viewer ,   int   mouse_x ,   int   mouse_y );  bool   ( * callback_mouse_scroll )( Viewer &   viewer ,   float   delta_y );  bool   ( * callback_key_down )( Viewer &   viewer ,   unsigned   char   key ,   int   modifiers );  bool   ( * callback_key_up )( Viewer &   viewer ,   unsigned   char   key ,   int   modifiers );   A keyboard callback can be used to visualize multiple meshes or different\nstages of an algorithm, as demonstrated in  Example 103 , where\nthe keyboard callback changes the visualized mesh depending on the key pressed:  bool   key_down ( igl :: opengl :: glfw :: Viewer &   viewer ,   unsigned   char   key ,   int   modifier )  { \n   if   ( key   ==   '1' ) \n   { \n     viewer . data (). clear (); \n     viewer . data (). set_mesh ( V1 ,   F1 ); \n     viewer . core . align_camera_center ( V1 , F1 ); \n   } \n   else   if   ( key   ==   '2' ) \n   { \n     viewer . data (). clear (); \n     viewer . data (). set_mesh ( V2 ,   F2 ); \n     viewer . core . align_camera_center ( V2 , F2 ); \n   } \n   return   false ;  }   The callback is registered in the viewer as follows:  viewer . callback_key_down   =   & key_down ;   Note that the mesh is cleared before using set_mesh. This has to be called\nevery time the number of vertices or faces of the plotted mesh changes. Every\ncallback returns a boolean value that tells the viewer if the event has been\nhandled by the plugin, or if the viewer should process it normally. This is\nuseful, for example, to disable the default mouse event handling if you want to\ncontrol the camera directly in your code.  The viewer can be extended using plugins, which are classes that implements all\nthe viewer's callbacks. See the Viewer_plugin  for more details.",
            "title": "Interaction with keyboard and mouse [interactionwithkeyboardandmouse]"
        },
        {
            "location": "/tutorial/chapter-1/#scalar-field-visualization-scalarfieldvisualization",
            "text": "Colors and normals can be associated to faces or vertices using the\nset_colors function:  viewer . data (). set_colors ( C );   C  is a #C by 3 matrix with one RGB color per row.  C  must have as many\nrows as the number of faces  or  the number of vertices of the mesh.\nDepending on the size of  C , the viewer applies the color to the faces or to\nthe vertices.  Colors can be used to visualize a scalar function defined on a surface.  The\nscalar function is converted to colors using a color transfer function, which\nmaps a scalar value between 0 and 1 to a color. A simple example of a scalar\nfield defined on a surface is the z coordinate of each point, which can be\nextract from our mesh representation by taking the last column of  V \n( Example 104 ). The function  igl::jet  can be used to\nconvert it to colors:  Eigen :: VectorXd   Z   =   V . col ( 2 );  igl :: jet ( Z , true , C );   The first row extracts the third column from  V  (the z coordinate of each\nvertex) and the second calls a libigl functions that converts a scalar field to colors. The second parameter of jet normalizes the scalar field to lie between 0 and 1 before applying the transfer function.   igl::jet  is an example of a standard function in libigl: it takes simple\ntypes and can be easily reused for many different tasks.  Not committing to\nheavy data structures types favors simplicity, ease of use and reusability.",
            "title": "Scalar field visualization [scalarfieldvisualization]"
        },
        {
            "location": "/tutorial/chapter-1/#overlays-overlays",
            "text": "In addition to plotting the surface, the viewer supports the visualization of points, lines and text labels: these overlays can be very helpful while developing geometric processing algorithms to plot debug information.  viewer . data (). add_points ( P , Eigen :: RowVector3d ( r , g , b ));   Draws a point of color r,g,b for each row of P. The point is placed at the coordinates specified in each row of P, which is a #P by 3 matrix.  viewer . data (). add_edges ( P1 , P2 , Eigen :: RowVector3d ( r , g , b );   Draws a line of color r,g,b for each row of P1 and P2, which connects the 3D point in to the point in P2. Both P1 and P2 are of size #P by 3.  viewer . data (). add_label ( p , str );   Draws a label containing the string str at the position p, which is a vector of length 3.  These functions are demonstrate in  Example 105  where\nthe bounding box of a mesh is plotted using lines and points.\nUsing matrices to encode the mesh and its attributes allows to write short and\nefficient code for many operations, avoiding to write for loops. For example,\nthe bounding box of a mesh can be found by taking the colwise maximum and minimum of  V :  Eigen :: Vector3d   m   =   V . colwise (). minCoeff ();  Eigen :: Vector3d   M   =   V . colwise (). maxCoeff ();",
            "title": "Overlays [overlays]"
        },
        {
            "location": "/tutorial/chapter-1/#viewer-menu-viewermenu",
            "text": "As of latest version, the viewer uses a new menu and completely replaces AntTweakBar  and nanogui  with  Dear ImGui . To extend the default menu of the\nviewer and to expose more user defined variables you have to implement a custom interface, as in  Example 106 : // Add content to the default menu window  menu . callback_draw_viewer_menu   =   [ & ]()  { \n   // Draw parent menu content \n   menu . draw_viewer_menu (); \n\n   // Add new group \n   if   ( ImGui :: CollapsingHeader ( \"New Group\" ,   ImGuiTreeNodeFlags_DefaultOpen )) \n   { \n     // Expose variable directly ... \n     ImGui :: InputFloat ( \"float\" ,   & floatVariable ,   0 ,   0 ,   3 ); \n\n     // ... or using a custom callback \n     static   bool   boolVariable   =   true ; \n     if   ( ImGui :: Checkbox ( \"bool\" ,   & boolVariable )) \n     { \n       // do something \n       std :: cout   <<   \"boolVariable: \"   <<   std :: boolalpha   <<   boolVariable   <<   std :: endl ; \n     } \n\n     // Expose an enumeration type \n     enum   Orientation   {   Up = 0 ,   Down ,   Left ,   Right   }; \n     static   Orientation   dir   =   Up ; \n     ImGui :: Combo ( \"Direction\" ,   ( int   * )( & dir ),   \"Up \\0 Down \\0 Left \\0 Right \\0\\0 \" ); \n\n     // We can also use a std::vector<std::string> defined dynamically \n     static   int   num_choices   =   3 ; \n     static   std :: vector < std :: string >   choices ; \n     static   int   idx_choice   =   0 ; \n     if   ( ImGui :: InputInt ( \"Num letters\" ,   & num_choices )) \n     { \n       num_choices   =   std :: max ( 1 ,   std :: min ( 26 ,   num_choices )); \n     } \n     if   ( num_choices   !=   ( int )   choices . size ()) \n     { \n       choices . resize ( num_choices ); \n       for   ( int   i   =   0 ;   i   <   num_choices ;   ++ i ) \n         choices [ i ]   =   std :: string ( 1 ,   'A'   +   i ); \n       if   ( idx_choice   >=   num_choices ) \n         idx_choice   =   num_choices   -   1 ; \n     } \n     ImGui :: Combo ( \"Letter\" ,   & idx_choice ,   choices ); \n\n     // Add a button \n     if   ( ImGui :: Button ( \"Print Hello\" ,   ImVec2 ( - 1 , 0 ))) \n     { \n       std :: cout   <<   \"Hello \\n \" ; \n     } \n   }  };   If you need a separate new menu window implement:  // Draw additional windows  menu . callback_draw_custom_window   =   [ & ]()  { \n   // Define next window position + size \n   ImGui :: SetNextWindowPos ( ImVec2 ( 180.f   *   menu . menu_scaling (),   10 ),   ImGuiSetCond_FirstUseEver ); \n   ImGui :: SetNextWindowSize ( ImVec2 ( 200 ,   160 ),   ImGuiSetCond_FirstUseEver ); \n   ImGui :: Begin ( \n       \"New Window\" ,   nullptr , \n       ImGuiWindowFlags_NoSavedSettings \n   ); \n\n   // Expose the same variable directly ... \n   ImGui :: PushItemWidth ( - 80 ); \n   ImGui :: DragFloat ( \"float\" ,   & floatVariable ,   0.0 ,   0.0 ,   3.0 ); \n   ImGui :: PopItemWidth (); \n\n   static   std :: string   str   =   \"bunny\" ; \n   ImGui :: InputText ( \"Name\" ,   str ); \n\n   ImGui :: End ();  };",
            "title": "Viewer Menu [viewermenu]"
        },
        {
            "location": "/tutorial/chapter-1/#multiple-meshes-multiplemeshes",
            "text": "Libigl's  igl::opengl::glfw::Viewer  provides basic support for rendering\nmultiple meshes.  Which mesh is  selected  is controlled via the  viewer.selected_data_index \nfield. By default it his is set to  0 , so in the typical case of a single mesh viewer.data()  returns the  igl::ViewerData  corresponding to the one\nand only mesh.",
            "title": "Multiple Meshes [multiplemeshes]"
        },
        {
            "location": "/tutorial/chapter-2/",
            "text": "Chapter 2: Discrete Geometric Quantities and Operators\n\u00b6\n\n\nThis chapter illustrates a few discrete quantities that libigl can compute on a\nmesh and the libigl functions that construct popular discrete differential\ngeometry operators. It also provides an introduction to basic drawing and\ncoloring routines of our viewer.\n\n\nNormals\n\u00b6\n\n\nSurface normals are a basic quantity necessary for rendering a surface. There\nare a variety of ways to compute and store normals on a triangle mesh. \nExample\n201\n demonstrates how to compute and visualize normals\nwith libigl.\n\n\nPer-face\n\u00b6\n\n\nNormals are well defined on each triangle of a mesh as the vector orthogonal to\ntriangle's plane. These piecewise-constant normals produce piecewise-flat\nrenderings: the surface appears non-smooth and reveals its underlying\ndiscretization.\n\n\nPer-vertex\n\u00b6\n\n\nNormals can be computed and stored on vertices, and interpolated in the interior of the triangles to produce smooth renderings (\nPhong shading\n).\nMost techniques for computing per-vertex normals take an average of incident face normals. The main difference between these techniques is their weighting scheme: Uniform\nweighting is heavily biased by the discretization choice, whereas area-based\nor angle-based weighting is more forgiving.\n\n\nThe typical half-edge style computation of area-based weights has this structure:\n\n\nN\n.\nsetZero\n(\nV\n.\nrows\n(),\n3\n);\n\n\nfor\n(\nint\n \ni\n \n:\n \nvertices\n)\n\n\n{\n\n  \nfor\n(\nface\n \n:\n \nincident_faces\n(\ni\n))\n\n  \n{\n\n    \nN\n.\nrow\n(\ni\n)\n \n+=\n \nface\n.\narea\n \n*\n \nface\n.\nnormal\n;\n\n  \n}\n\n\n}\n\n\nN\n.\nrowwise\n().\nnormalize\n();\n\n\n\n\n\nAt first glance, it might seem inefficient to loop over incident faces---and thus constructing the per-vertex normals--- without using an half-edge data structure. However, per-vertex normals may be \nthrowing\n each face normal to\nrunning sums on its corner vertices:\n\n\nN\n.\nsetZero\n(\nV\n.\nrows\n(),\n3\n);\n\n\nfor\n(\nint\n \nf\n \n=\n \n0\n;\n \nf\n \n<\n \nF\n.\nrows\n();\nf\n++\n)\n\n\n{\n\n  \nfor\n(\nint\n \nc\n \n=\n \n0\n;\n \nc\n \n<\n \n3\n;\nc\n++\n)\n\n  \n{\n\n    \nN\n.\nrow\n(\nF\n(\nf\n,\nc\n))\n \n+=\n \narea\n(\nf\n)\n \n*\n \nface_normal\n.\nrow\n(\nf\n);\n\n  \n}\n\n\n}\n\n\nN\n.\nrowwise\n().\nnormalize\n();\n\n\n\n\n\nPer-corner\n\u00b6\n\n\nStoring normals per-corner is an efficient and convenient way of supporting both\nsmooth and sharp (e.g. creases and corners) rendering. This format is common to\nOpenGL and the .obj mesh file format. Often such normals are tuned by the mesh\ndesigner, but creases and corners can also be computed automatically. Libigl\nimplements a simple scheme which computes corner normals as averages of\nnormals of faces incident on the corresponding vertex which do not deviate by more than a specified dihedral angle (e.g. 20\u00b0).\n\n\n\n\nGaussian curvature\n\u00b6\n\n\nGaussian curvature on a continuous surface is defined as the product of the\nprincipal curvatures:\n\n\nk_G = k_1 k_2.\nk_G = k_1 k_2.\n\n\nAs an \nintrinsic\n measure, it depends on the metric and\nnot the surface's embedding.\n\n\nIntuitively, Gaussian curvature tells how locally spherical or \nelliptic\n the\nsurface is ( \nk_G>0\nk_G>0\n ), how locally saddle-shaped or \nhyperbolic\n the surface\nis ( \nk_G<0\nk_G<0\n ), or how locally cylindrical or \nparabolic\n ( \nk_G=0\nk_G=0\n ) the\nsurface is.\n\n\nIn the discrete setting, one definition for a \"discrete Gaussian curvature\"\non a triangle mesh is via a vertex's \nangular deficit\n:\n\n\nk_G(v_i) = 2\u03c0 - \\sum\\limits_{j\\in N(i)}\u03b8_{ij},\nk_G(v_i) = 2\u03c0 - \\sum\\limits_{j\\in N(i)}\u03b8_{ij},\n\n\nwhere \nN(i)\nN(i)\n are the triangles incident on vertex \ni\ni\n and \n\u03b8_{ij}\n\u03b8_{ij}\n is the angle\nat vertex \ni\ni\n in triangle \nj\nj\n [][#meyer_2003].\n\n\nJust like the continuous analog, our discrete Gaussian curvature reveals\nelliptic, hyperbolic and parabolic vertices on the domain, as demonstrated in \nExample 202\n.\n\n\n\n\nCurvature directions\n\u00b6\n\n\nThe two principal curvatures \n(k_1,k_2)\n(k_1,k_2)\n at a point on a surface measure how\nmuch the surface bends in different directions. The directions of maximum and\nminimum (signed) bending are called principal directions and are always\northogonal.\n\n\nMean curvature is defined as the average of principal curvatures:\n\n\nH = \\frac{1}{2}(k_1 + k_2).\nH = \\frac{1}{2}(k_1 + k_2).\n\n\nOne way to extract mean curvature is by examining the Laplace-Beltrami operator\napplied to the surface positions. The result is a so-called mean-curvature\nnormal:\n\n\n-\\Delta \\mathbf{x} = H \\mathbf{n}.\n-\\Delta \\mathbf{x} = H \\mathbf{n}.\n\n\nIt is easy to compute this on a discrete triangle mesh in libigl using the\ncotangent Laplace-Beltrami operator [][#meyer_2003].\n\n\n#include\n \n<igl/cotmatrix.h>\n\n\n#include\n \n<igl/massmatrix.h>\n\n\n#include\n \n<igl/invert_diag.h>\n\n\n...\n\n\nMatrixXd\n \nHN\n;\n\n\nSparseMatrix\n<\ndouble\n>\n \nL\n,\nM\n,\nMinv\n;\n\n\nigl\n::\ncotmatrix\n(\nV\n,\nF\n,\nL\n);\n\n\nigl\n::\nmassmatrix\n(\nV\n,\nF\n,\nigl\n::\nMASSMATRIX_TYPE_VORONOI\n,\nM\n);\n\n\nigl\n::\ninvert_diag\n(\nM\n,\nMinv\n);\n\n\nHN\n \n=\n \n-\nMinv\n*\n(\nL\n*\nV\n);\n\n\nH\n \n=\n \nHN\n.\nrowwise\n().\nnorm\n();\n \n//up to sign\n\n\n\n\n\nCombined with the angle defect definition of discrete Gaussian curvature, one\ncan define principal curvatures and use least squares fitting to find\ndirections [][#meyer_2003].\n\n\nAlternatively, a robust method for determining principal curvatures is via\nquadric fitting [][#panozzo_2010]. In the neighborhood around every vertex, a\nbest-fit quadric is found and principal curvature values and directions are\nanalytically computed on this quadric (\nExample\n203\n).\n\n\n\n\nGradient\n\u00b6\n\n\nScalar functions on a surface can be discretized as a piecewise linear function\nwith values defined at each mesh vertex:\n\n\nf(\\mathbf{x}) \\approx \\sum\\limits_{i=1}^n \\phi_i(\\mathbf{x})\\, f_i,\nf(\\mathbf{x}) \\approx \\sum\\limits_{i=1}^n \\phi_i(\\mathbf{x})\\, f_i,\n\n\nwhere \n\\phi_i\n\\phi_i\n is a piecewise linear hat function defined by the mesh so that\nfor each triangle \n\\phi_i\n\\phi_i\n is \nthe\n linear function which is one only at\nvertex \ni\ni\n and zero at the other corners.\n\n\n\n\nThus gradients of such piecewise linear functions are simply sums of gradients\nof the hat functions:\n\n\n\\nabla f(\\mathbf{x}) \\approx\n \\nabla \\sum\\limits_{i=1}^n \\phi_i(\\mathbf{x})\\, f_i =\n \\sum\\limits_{i=1}^n \\nabla \\phi_i(\\mathbf{x})\\, f_i.\n\\nabla f(\\mathbf{x}) \\approx\n \\nabla \\sum\\limits_{i=1}^n \\phi_i(\\mathbf{x})\\, f_i =\n \\sum\\limits_{i=1}^n \\nabla \\phi_i(\\mathbf{x})\\, f_i.\n\n\nThis reveals that the gradient is a linear function of the vector of \nf_i\nf_i\n\nvalues. Because the \n\\phi_i\n\\phi_i\n are linear in each triangle, their gradients are\n\nconstant\n in each triangle. Thus our discrete gradient operator can be written\nas a matrix multiplication taking vertex values to triangle values:\n\n\n\\nabla f \\approx \\mathbf{G}\\,\\mathbf{f},\n\\nabla f \\approx \\mathbf{G}\\,\\mathbf{f},\n\n\nwhere \n\\mathbf{f}\n\\mathbf{f}\n is \nn\\times 1\nn\\times 1\n and \n\\mathbf{G}\n\\mathbf{G}\n is an \nmd\\times n\nmd\\times n\n sparse\nmatrix. This matrix \n\\mathbf{G}\n\\mathbf{G}\n can be derived geometrically, e.g.\nch. 2\n1\n.\nLibigl's \ngrad\n function computes \n\\mathbf{G}\n\\mathbf{G}\n for\ntriangle and tetrahedral meshes (\nExample 204\n):\n\n\n\n\nLaplacian\n\u00b6\n\n\nThe discrete Laplacian is an essential geometry processing tool. Many\ninterpretations and flavors of the Laplace and Laplace-Beltrami operator exist.\n\n\nIn open Euclidean space, the \nLaplace\n operator is the usual divergence of\ngradient (or equivalently the Laplacian of a function is the trace of its\nHessian):\n\n\n\\Delta f =\n \\frac{\\partial^2 f}{\\partial x^2} +\n \\frac{\\partial^2 f}{\\partial y^2} +\n \\frac{\\partial^2 f}{\\partial z^2}.\n\\Delta f =\n \\frac{\\partial^2 f}{\\partial x^2} +\n \\frac{\\partial^2 f}{\\partial y^2} +\n \\frac{\\partial^2 f}{\\partial z^2}.\n\n\nThe \nLaplace-Beltrami\n operator generalizes this to surfaces.\n\n\nWhen considering piecewise-linear functions on a triangle mesh, a discrete\nLaplacian may be derived in a variety of ways. The most popular in geometry\nprocessing is the so-called ``cotangent Laplacian'' \n\\mathbf{L}\n\\mathbf{L}\n, arising\nsimultaneously from FEM, DEC and applying divergence theorem to vertex\none-rings. As a linear operator taking vertex values to vertex values, the\nLaplacian \n\\mathbf{L}\n\\mathbf{L}\n is a \nn\\times n\nn\\times n\n matrix with elements:\n\n\nL_{ij} = \\begin{cases}j \\in N(i) &\\cot \\alpha_{ij} + \\cot \\beta_{ij},\\\\\nj \\notin N(i) & 0,\\\\\ni = j & -\\sum\\limits_{k\\neq i} L_{ik},\n\\end{cases}\nL_{ij} = \\begin{cases}j \\in N(i) &\\cot \\alpha_{ij} + \\cot \\beta_{ij},\\\\\nj \\notin N(i) & 0,\\\\\ni = j & -\\sum\\limits_{k\\neq i} L_{ik},\n\\end{cases}\n\n\nwhere \nN(i)\nN(i)\n are the vertices adjacent to (neighboring) vertex \ni\ni\n, and\n\n\\alpha_{ij},\\beta_{ij}\n\\alpha_{ij},\\beta_{ij}\n are the angles opposite to edge \n{ij}\n{ij}\n.\nThis formula leads to a typical half-edge style implementation for\nconstructing \n\\mathbf{L}\n\\mathbf{L}\n:\n\n\nfor\n(\nint\n \ni\n \n:\n \nvertices\n)\n\n\n{\n\n  \nfor\n(\nint\n \nj\n \n:\n \none_ring\n(\ni\n))\n\n  \n{\n\n    \nfor\n(\nint\n \nk\n \n:\n \ntriangle_on_edge\n(\ni\n,\nj\n))\n\n    \n{\n\n      \nL\n(\ni\n,\nj\n)\n \n=\n \ncot\n(\nangle\n(\ni\n,\nj\n,\nk\n));\n\n      \nL\n(\ni\n,\ni\n)\n \n-=\n \ncot\n(\nangle\n(\ni\n,\nj\n,\nk\n));\n\n    \n}\n\n  \n}\n\n\n}\n\n\n\n\n\nSimilarly as before, it may seem to loop over one-rings without having an half-edge data structure. However, this is not the case, since the Laplacian may be built by summing together contributions for each triangle, much in spirit with its FEM discretization\nof the Dirichlet energy (sum of squared gradients):\n\n\nfor\n(\ntriangle\n \nt\n \n:\n \ntriangles\n)\n\n\n{\n\n  \nfor\n(\nedge\n \ni\n,\nj\n \n:\n \nt\n)\n\n  \n{\n\n    \nL\n(\ni\n,\nj\n)\n \n+=\n \ncot\n(\nangle\n(\ni\n,\nj\n,\nk\n));\n\n    \nL\n(\nj\n,\ni\n)\n \n+=\n \ncot\n(\nangle\n(\ni\n,\nj\n,\nk\n));\n\n    \nL\n(\ni\n,\ni\n)\n \n-=\n \ncot\n(\nangle\n(\ni\n,\nj\n,\nk\n));\n\n    \nL\n(\nj\n,\nj\n)\n \n-=\n \ncot\n(\nangle\n(\ni\n,\nj\n,\nk\n));\n\n  \n}\n\n\n}\n\n\n\n\n\nLibigl implements discrete \"cotangent\" Laplacians for triangles meshes and\ntetrahedral meshes, building both with fast geometric rules rather than \"by the\nbook\" FEM construction which involves many (small) matrix inversions, cf.\n[#sharf_2007][].\n\n\nThe operator applied to mesh vertex positions amounts to smoothing by \nflowing\n\nthe surface along the mean curvature normal direction (\nExample 205\n). Note that this is equivalent to minimizing surface area.\n\n\n\n\nMass matrix\n\u00b6\n\n\nThe mass matrix \n\\mathbf{M}\n\\mathbf{M}\n is another \nn \\times n\nn \\times n\n matrix which takes vertex\nvalues to vertex values. From an FEM point of view, it is a discretization of\nthe inner-product: it accounts for the area around each vertex. Consequently,\n\n\\mathbf{M}\n\\mathbf{M}\n is often a diagonal matrix, such that \nM_{ii}\nM_{ii}\n is the barycentric\nor voronoi area around vertex \ni\ni\n in the mesh [#meyer_2003][]. The inverse of\nthis matrix is also very useful as it transforms integrated quantities into\npoint-wise quantities, e.g.:\n\n\n\\Delta f \\approx \\mathbf{M}^{-1} \\mathbf{L} \\mathbf{f}.\n\\Delta f \\approx \\mathbf{M}^{-1} \\mathbf{L} \\mathbf{f}.\n\n\nIn general, when encountering squared quantities integrated over the surface,\nthe mass matrix will be used as the discretization of the inner product when\nsampling function values at vertices:\n\n\n\\int_S x\\, y\\ dA \\approx \\mathbf{x}^T\\mathbf{M}\\,\\mathbf{y}.\n\\int_S x\\, y\\ dA \\approx \\mathbf{x}^T\\mathbf{M}\\,\\mathbf{y}.\n\n\nAn alternative mass matrix \n\\mathbf{T}\n\\mathbf{T}\n is a \nmd \\times md\nmd \\times md\n matrix which takes\ntriangle vector values to triangle vector values. This matrix represents an\ninner-product accounting for the area associated with each triangle (i.e. the\ntriangles true area).\n\n\nAlternative construction of Laplacian\n\u00b6\n\n\nAn alternative construction of the discrete cotangent Laplacian is by\n\"squaring\" the discrete gradient operator. This may be derived by applying\nGreen's identity (ignoring boundary conditions for the moment):\n\n\n\\int_S \\|\\nabla f\\|^2 dA = \\int_S f \\Delta f dA\n\\int_S \\|\\nabla f\\|^2 dA = \\int_S f \\Delta f dA\n\n\nOr in matrix form which is immediately translatable to code:\n\n\n\\mathbf{f}^T \\mathbf{G}^T \\mathbf{T} \\mathbf{G} \\mathbf{f} =\n  \\mathbf{f}^T \\mathbf{M} \\mathbf{M}^{-1} \\mathbf{L} \\mathbf{f} =\n  \\mathbf{f}^T \\mathbf{L} \\mathbf{f}.\n\\mathbf{f}^T \\mathbf{G}^T \\mathbf{T} \\mathbf{G} \\mathbf{f} =\n  \\mathbf{f}^T \\mathbf{M} \\mathbf{M}^{-1} \\mathbf{L} \\mathbf{f} =\n  \\mathbf{f}^T \\mathbf{L} \\mathbf{f}.\n\n\nSo we have that \n\\mathbf{L} = \\mathbf{G}^T \\mathbf{T} \\mathbf{G}\n\\mathbf{L} = \\mathbf{G}^T \\mathbf{T} \\mathbf{G}\n. This also\nhints that we may consider \n\\mathbf{G}^T\n\\mathbf{G}^T\n as a discrete \ndivergence\n operator,\nsince the Laplacian is the divergence of the gradient. Naturally, \n\\mathbf{G}^T\n\\mathbf{G}^T\n is\na \nn \\times md\nn \\times md\n sparse matrix which takes vector values stored at triangle faces\nto scalar divergence values at vertices.\n\n\nGeodesic\n\u00b6\n\n\nThe discrete geodesic distance between two points is the length of the shortest path between then restricted to the surface. For triangle meshes, such a path is made of a set of segments which can be either edges of the mesh or crossing a triangle.\n\n\nLibigl includes a wrapper for the exact geodesic algorithm [#mitchell_1987] developed by Danil Kirsanov (\nhttps://code.google.com/archive/p/geodesic/\n), exposing it through an Eigen-based API. The function \n\nigl\n::\nexact_geodesic\n(\nV\n,\nF\n,\nVS\n,\nFS\n,\nVT\n,\nFT\n,\nd\n);\n\n\n\ncomputes the closest geodesic distances of each vertex in VT or face in FT, from the source vertices VS or faces FS of the input mesh V,F. The output is writted in the vector d, which lists first the distances for the vertices in VT, and then for the faces in FT. For example, if you want to compute the distance from the vertex with id \nvid\n, to all vertices of F you can use:\n\nEigen\n::\nVectorXi\n \nVS\n,\nFS\n,\nVT\n,\nFT\n;\n\n\n// The selected vertex is the source\n\n\nVS\n.\nresize\n(\n1\n);\n\n\nVS\n \n<<\n \nvid\n;\n\n\n// All vertices are the targets\n\n\nVT\n.\nsetLinSpaced\n(\nV\n.\nrows\n(),\n0\n,\nV\n.\nrows\n()\n-\n1\n);\n\n\nEigen\n::\nVectorXd\n \nd\n;\n\n\nigl\n::\nexact_geodesic\n(\nV\n,\nF\n,\nVS\n,\nFS\n,\nVT\n,\nFT\n,\nd\n);\n\n\n\n\n\n\nReferences\n\u00b6\n\n\n\n\n\n\n\n\n\n\nAlec Jacobson,\n\nAlgorithms and Interfaces for Real-Time Deformation of 2D and 3D Shapes\n,\n2013.\u00a0\n\u21a9",
            "title": "Chapter 2: Discrete Geometric Quantities and Operators"
        },
        {
            "location": "/tutorial/chapter-2/#chapter-2-discrete-geometric-quantities-and-operators",
            "text": "This chapter illustrates a few discrete quantities that libigl can compute on a\nmesh and the libigl functions that construct popular discrete differential\ngeometry operators. It also provides an introduction to basic drawing and\ncoloring routines of our viewer.",
            "title": "Chapter 2: Discrete Geometric Quantities and Operators"
        },
        {
            "location": "/tutorial/chapter-2/#normals",
            "text": "Surface normals are a basic quantity necessary for rendering a surface. There\nare a variety of ways to compute and store normals on a triangle mesh.  Example\n201  demonstrates how to compute and visualize normals\nwith libigl.",
            "title": "Normals"
        },
        {
            "location": "/tutorial/chapter-2/#per-face",
            "text": "Normals are well defined on each triangle of a mesh as the vector orthogonal to\ntriangle's plane. These piecewise-constant normals produce piecewise-flat\nrenderings: the surface appears non-smooth and reveals its underlying\ndiscretization.",
            "title": "Per-face"
        },
        {
            "location": "/tutorial/chapter-2/#per-vertex",
            "text": "Normals can be computed and stored on vertices, and interpolated in the interior of the triangles to produce smooth renderings ( Phong shading ).\nMost techniques for computing per-vertex normals take an average of incident face normals. The main difference between these techniques is their weighting scheme: Uniform\nweighting is heavily biased by the discretization choice, whereas area-based\nor angle-based weighting is more forgiving.  The typical half-edge style computation of area-based weights has this structure:  N . setZero ( V . rows (), 3 );  for ( int   i   :   vertices )  { \n   for ( face   :   incident_faces ( i )) \n   { \n     N . row ( i )   +=   face . area   *   face . normal ; \n   }  }  N . rowwise (). normalize ();   At first glance, it might seem inefficient to loop over incident faces---and thus constructing the per-vertex normals--- without using an half-edge data structure. However, per-vertex normals may be  throwing  each face normal to\nrunning sums on its corner vertices:  N . setZero ( V . rows (), 3 );  for ( int   f   =   0 ;   f   <   F . rows (); f ++ )  { \n   for ( int   c   =   0 ;   c   <   3 ; c ++ ) \n   { \n     N . row ( F ( f , c ))   +=   area ( f )   *   face_normal . row ( f ); \n   }  }  N . rowwise (). normalize ();",
            "title": "Per-vertex"
        },
        {
            "location": "/tutorial/chapter-2/#per-corner",
            "text": "Storing normals per-corner is an efficient and convenient way of supporting both\nsmooth and sharp (e.g. creases and corners) rendering. This format is common to\nOpenGL and the .obj mesh file format. Often such normals are tuned by the mesh\ndesigner, but creases and corners can also be computed automatically. Libigl\nimplements a simple scheme which computes corner normals as averages of\nnormals of faces incident on the corresponding vertex which do not deviate by more than a specified dihedral angle (e.g. 20\u00b0).",
            "title": "Per-corner"
        },
        {
            "location": "/tutorial/chapter-2/#gaussian-curvature",
            "text": "Gaussian curvature on a continuous surface is defined as the product of the\nprincipal curvatures:  k_G = k_1 k_2. k_G = k_1 k_2.  As an  intrinsic  measure, it depends on the metric and\nnot the surface's embedding.  Intuitively, Gaussian curvature tells how locally spherical or  elliptic  the\nsurface is (  k_G>0 k_G>0  ), how locally saddle-shaped or  hyperbolic  the surface\nis (  k_G<0 k_G<0  ), or how locally cylindrical or  parabolic  (  k_G=0 k_G=0  ) the\nsurface is.  In the discrete setting, one definition for a \"discrete Gaussian curvature\"\non a triangle mesh is via a vertex's  angular deficit :  k_G(v_i) = 2\u03c0 - \\sum\\limits_{j\\in N(i)}\u03b8_{ij}, k_G(v_i) = 2\u03c0 - \\sum\\limits_{j\\in N(i)}\u03b8_{ij},  where  N(i) N(i)  are the triangles incident on vertex  i i  and  \u03b8_{ij} \u03b8_{ij}  is the angle\nat vertex  i i  in triangle  j j  [][#meyer_2003].  Just like the continuous analog, our discrete Gaussian curvature reveals\nelliptic, hyperbolic and parabolic vertices on the domain, as demonstrated in  Example 202 .",
            "title": "Gaussian curvature"
        },
        {
            "location": "/tutorial/chapter-2/#curvature-directions",
            "text": "The two principal curvatures  (k_1,k_2) (k_1,k_2)  at a point on a surface measure how\nmuch the surface bends in different directions. The directions of maximum and\nminimum (signed) bending are called principal directions and are always\northogonal.  Mean curvature is defined as the average of principal curvatures:  H = \\frac{1}{2}(k_1 + k_2). H = \\frac{1}{2}(k_1 + k_2).  One way to extract mean curvature is by examining the Laplace-Beltrami operator\napplied to the surface positions. The result is a so-called mean-curvature\nnormal:  -\\Delta \\mathbf{x} = H \\mathbf{n}. -\\Delta \\mathbf{x} = H \\mathbf{n}.  It is easy to compute this on a discrete triangle mesh in libigl using the\ncotangent Laplace-Beltrami operator [][#meyer_2003].  #include   <igl/cotmatrix.h>  #include   <igl/massmatrix.h>  #include   <igl/invert_diag.h>  ...  MatrixXd   HN ;  SparseMatrix < double >   L , M , Minv ;  igl :: cotmatrix ( V , F , L );  igl :: massmatrix ( V , F , igl :: MASSMATRIX_TYPE_VORONOI , M );  igl :: invert_diag ( M , Minv );  HN   =   - Minv * ( L * V );  H   =   HN . rowwise (). norm ();   //up to sign   Combined with the angle defect definition of discrete Gaussian curvature, one\ncan define principal curvatures and use least squares fitting to find\ndirections [][#meyer_2003].  Alternatively, a robust method for determining principal curvatures is via\nquadric fitting [][#panozzo_2010]. In the neighborhood around every vertex, a\nbest-fit quadric is found and principal curvature values and directions are\nanalytically computed on this quadric ( Example\n203 ).",
            "title": "Curvature directions"
        },
        {
            "location": "/tutorial/chapter-2/#gradient",
            "text": "Scalar functions on a surface can be discretized as a piecewise linear function\nwith values defined at each mesh vertex:  f(\\mathbf{x}) \\approx \\sum\\limits_{i=1}^n \\phi_i(\\mathbf{x})\\, f_i, f(\\mathbf{x}) \\approx \\sum\\limits_{i=1}^n \\phi_i(\\mathbf{x})\\, f_i,  where  \\phi_i \\phi_i  is a piecewise linear hat function defined by the mesh so that\nfor each triangle  \\phi_i \\phi_i  is  the  linear function which is one only at\nvertex  i i  and zero at the other corners.   Thus gradients of such piecewise linear functions are simply sums of gradients\nof the hat functions:  \\nabla f(\\mathbf{x}) \\approx\n \\nabla \\sum\\limits_{i=1}^n \\phi_i(\\mathbf{x})\\, f_i =\n \\sum\\limits_{i=1}^n \\nabla \\phi_i(\\mathbf{x})\\, f_i. \\nabla f(\\mathbf{x}) \\approx\n \\nabla \\sum\\limits_{i=1}^n \\phi_i(\\mathbf{x})\\, f_i =\n \\sum\\limits_{i=1}^n \\nabla \\phi_i(\\mathbf{x})\\, f_i.  This reveals that the gradient is a linear function of the vector of  f_i f_i \nvalues. Because the  \\phi_i \\phi_i  are linear in each triangle, their gradients are constant  in each triangle. Thus our discrete gradient operator can be written\nas a matrix multiplication taking vertex values to triangle values:  \\nabla f \\approx \\mathbf{G}\\,\\mathbf{f}, \\nabla f \\approx \\mathbf{G}\\,\\mathbf{f},  where  \\mathbf{f} \\mathbf{f}  is  n\\times 1 n\\times 1  and  \\mathbf{G} \\mathbf{G}  is an  md\\times n md\\times n  sparse\nmatrix. This matrix  \\mathbf{G} \\mathbf{G}  can be derived geometrically, e.g.\nch. 2 1 .\nLibigl's  grad  function computes  \\mathbf{G} \\mathbf{G}  for\ntriangle and tetrahedral meshes ( Example 204 ):",
            "title": "Gradient"
        },
        {
            "location": "/tutorial/chapter-2/#laplacian",
            "text": "The discrete Laplacian is an essential geometry processing tool. Many\ninterpretations and flavors of the Laplace and Laplace-Beltrami operator exist.  In open Euclidean space, the  Laplace  operator is the usual divergence of\ngradient (or equivalently the Laplacian of a function is the trace of its\nHessian):  \\Delta f =\n \\frac{\\partial^2 f}{\\partial x^2} +\n \\frac{\\partial^2 f}{\\partial y^2} +\n \\frac{\\partial^2 f}{\\partial z^2}. \\Delta f =\n \\frac{\\partial^2 f}{\\partial x^2} +\n \\frac{\\partial^2 f}{\\partial y^2} +\n \\frac{\\partial^2 f}{\\partial z^2}.  The  Laplace-Beltrami  operator generalizes this to surfaces.  When considering piecewise-linear functions on a triangle mesh, a discrete\nLaplacian may be derived in a variety of ways. The most popular in geometry\nprocessing is the so-called ``cotangent Laplacian''  \\mathbf{L} \\mathbf{L} , arising\nsimultaneously from FEM, DEC and applying divergence theorem to vertex\none-rings. As a linear operator taking vertex values to vertex values, the\nLaplacian  \\mathbf{L} \\mathbf{L}  is a  n\\times n n\\times n  matrix with elements:  L_{ij} = \\begin{cases}j \\in N(i) &\\cot \\alpha_{ij} + \\cot \\beta_{ij},\\\\\nj \\notin N(i) & 0,\\\\\ni = j & -\\sum\\limits_{k\\neq i} L_{ik},\n\\end{cases} L_{ij} = \\begin{cases}j \\in N(i) &\\cot \\alpha_{ij} + \\cot \\beta_{ij},\\\\\nj \\notin N(i) & 0,\\\\\ni = j & -\\sum\\limits_{k\\neq i} L_{ik},\n\\end{cases}  where  N(i) N(i)  are the vertices adjacent to (neighboring) vertex  i i , and \\alpha_{ij},\\beta_{ij} \\alpha_{ij},\\beta_{ij}  are the angles opposite to edge  {ij} {ij} .\nThis formula leads to a typical half-edge style implementation for\nconstructing  \\mathbf{L} \\mathbf{L} :  for ( int   i   :   vertices )  { \n   for ( int   j   :   one_ring ( i )) \n   { \n     for ( int   k   :   triangle_on_edge ( i , j )) \n     { \n       L ( i , j )   =   cot ( angle ( i , j , k )); \n       L ( i , i )   -=   cot ( angle ( i , j , k )); \n     } \n   }  }   Similarly as before, it may seem to loop over one-rings without having an half-edge data structure. However, this is not the case, since the Laplacian may be built by summing together contributions for each triangle, much in spirit with its FEM discretization\nof the Dirichlet energy (sum of squared gradients):  for ( triangle   t   :   triangles )  { \n   for ( edge   i , j   :   t ) \n   { \n     L ( i , j )   +=   cot ( angle ( i , j , k )); \n     L ( j , i )   +=   cot ( angle ( i , j , k )); \n     L ( i , i )   -=   cot ( angle ( i , j , k )); \n     L ( j , j )   -=   cot ( angle ( i , j , k )); \n   }  }   Libigl implements discrete \"cotangent\" Laplacians for triangles meshes and\ntetrahedral meshes, building both with fast geometric rules rather than \"by the\nbook\" FEM construction which involves many (small) matrix inversions, cf.\n[#sharf_2007][].  The operator applied to mesh vertex positions amounts to smoothing by  flowing \nthe surface along the mean curvature normal direction ( Example 205 ). Note that this is equivalent to minimizing surface area.",
            "title": "Laplacian"
        },
        {
            "location": "/tutorial/chapter-2/#mass-matrix",
            "text": "The mass matrix  \\mathbf{M} \\mathbf{M}  is another  n \\times n n \\times n  matrix which takes vertex\nvalues to vertex values. From an FEM point of view, it is a discretization of\nthe inner-product: it accounts for the area around each vertex. Consequently, \\mathbf{M} \\mathbf{M}  is often a diagonal matrix, such that  M_{ii} M_{ii}  is the barycentric\nor voronoi area around vertex  i i  in the mesh [#meyer_2003][]. The inverse of\nthis matrix is also very useful as it transforms integrated quantities into\npoint-wise quantities, e.g.:  \\Delta f \\approx \\mathbf{M}^{-1} \\mathbf{L} \\mathbf{f}. \\Delta f \\approx \\mathbf{M}^{-1} \\mathbf{L} \\mathbf{f}.  In general, when encountering squared quantities integrated over the surface,\nthe mass matrix will be used as the discretization of the inner product when\nsampling function values at vertices:  \\int_S x\\, y\\ dA \\approx \\mathbf{x}^T\\mathbf{M}\\,\\mathbf{y}. \\int_S x\\, y\\ dA \\approx \\mathbf{x}^T\\mathbf{M}\\,\\mathbf{y}.  An alternative mass matrix  \\mathbf{T} \\mathbf{T}  is a  md \\times md md \\times md  matrix which takes\ntriangle vector values to triangle vector values. This matrix represents an\ninner-product accounting for the area associated with each triangle (i.e. the\ntriangles true area).",
            "title": "Mass matrix"
        },
        {
            "location": "/tutorial/chapter-2/#alternative-construction-of-laplacian",
            "text": "An alternative construction of the discrete cotangent Laplacian is by\n\"squaring\" the discrete gradient operator. This may be derived by applying\nGreen's identity (ignoring boundary conditions for the moment):  \\int_S \\|\\nabla f\\|^2 dA = \\int_S f \\Delta f dA \\int_S \\|\\nabla f\\|^2 dA = \\int_S f \\Delta f dA  Or in matrix form which is immediately translatable to code:  \\mathbf{f}^T \\mathbf{G}^T \\mathbf{T} \\mathbf{G} \\mathbf{f} =\n  \\mathbf{f}^T \\mathbf{M} \\mathbf{M}^{-1} \\mathbf{L} \\mathbf{f} =\n  \\mathbf{f}^T \\mathbf{L} \\mathbf{f}. \\mathbf{f}^T \\mathbf{G}^T \\mathbf{T} \\mathbf{G} \\mathbf{f} =\n  \\mathbf{f}^T \\mathbf{M} \\mathbf{M}^{-1} \\mathbf{L} \\mathbf{f} =\n  \\mathbf{f}^T \\mathbf{L} \\mathbf{f}.  So we have that  \\mathbf{L} = \\mathbf{G}^T \\mathbf{T} \\mathbf{G} \\mathbf{L} = \\mathbf{G}^T \\mathbf{T} \\mathbf{G} . This also\nhints that we may consider  \\mathbf{G}^T \\mathbf{G}^T  as a discrete  divergence  operator,\nsince the Laplacian is the divergence of the gradient. Naturally,  \\mathbf{G}^T \\mathbf{G}^T  is\na  n \\times md n \\times md  sparse matrix which takes vector values stored at triangle faces\nto scalar divergence values at vertices.",
            "title": "Alternative construction of Laplacian"
        },
        {
            "location": "/tutorial/chapter-2/#geodesic",
            "text": "The discrete geodesic distance between two points is the length of the shortest path between then restricted to the surface. For triangle meshes, such a path is made of a set of segments which can be either edges of the mesh or crossing a triangle.  Libigl includes a wrapper for the exact geodesic algorithm [#mitchell_1987] developed by Danil Kirsanov ( https://code.google.com/archive/p/geodesic/ ), exposing it through an Eigen-based API. The function  igl :: exact_geodesic ( V , F , VS , FS , VT , FT , d );  \ncomputes the closest geodesic distances of each vertex in VT or face in FT, from the source vertices VS or faces FS of the input mesh V,F. The output is writted in the vector d, which lists first the distances for the vertices in VT, and then for the faces in FT. For example, if you want to compute the distance from the vertex with id  vid , to all vertices of F you can use: Eigen :: VectorXi   VS , FS , VT , FT ;  // The selected vertex is the source  VS . resize ( 1 );  VS   <<   vid ;  // All vertices are the targets  VT . setLinSpaced ( V . rows (), 0 , V . rows () - 1 );  Eigen :: VectorXd   d ;  igl :: exact_geodesic ( V , F , VS , FS , VT , FT , d );",
            "title": "Geodesic"
        },
        {
            "location": "/tutorial/chapter-2/#references",
            "text": "Alec Jacobson, Algorithms and Interfaces for Real-Time Deformation of 2D and 3D Shapes ,\n2013.\u00a0 \u21a9",
            "title": "References"
        },
        {
            "location": "/tutorial/chapter-3/",
            "text": "Chapter 3: Matrices and linear algebra\n\u00b6\n\n\nLibigl relies heavily on the Eigen library for dense and sparse linear algebra\nroutines. Besides geometry processing routines, libigl has linear algebra\nroutines which bootstrap Eigen and make it feel even more similar to a high-level\nalgebra library such as Matlab.\n\n\nSlice\n\u00b6\n\n\nA very familiar and powerful routine in Matlab is array slicing. This allows\nreading from or writing to a possibly non-contiguous sub-matrix. Let's consider\nthe Matlab code:\n\n\nB\n \n=\n \nA\n(\nR\n,\nC\n);\n\n\n\n\n\nIf \nA\n is a \nm \\times n\nm \\times n\n matrix and \nR\n is a \nj\nj\n-long list of row-indices\n(between 1 and \nm\nm\n) and \nC\n is a \nk\nk\n-long list of column-indices, then as a\nresult \nB\n will be a \nj \\times k\nj \\times k\n matrix drawing elements from \nA\n according to\n\nR\n and \nC\n. In libigl, the same functionality is provided by the \nslice\n\nfunction (\nExample 301\n):\n\n\nVectorXi\n \nR\n,\nC\n;\n\n\nMatrixXd\n \nA\n,\nB\n;\n\n\n...\n\n\nigl\n::\nslice\n(\nA\n,\nR\n,\nC\n,\nB\n);\n\n\n\n\n\nNote that \nA\n and \nB\n could also be sparse matrices.\n\n\nSimilarly, consider the Matlab code:\n\n\nA\n(\nR\n,\nC\n)\n \n=\n \nB\n;\n\n\n\n\n\nNow, the selection is on the left-hand side so the \nj \\times k\nj \\times k\n matrix  \nB\n is\nbeing \nwritten into\n the submatrix of \nA\n determined by \nR\n and \nC\n. This\nfunctionality is provided in libigl using \nslice_into\n:\n\n\nigl\n::\nslice_into\n(\nB\n,\nR\n,\nC\n,\nA\n);\n\n\n\n\n\n\n\nSort\n\u00b6\n\n\nMatlab and other higher-level languages make it very easy to extract indices of\nsorting and comparison routines. For example in Matlab, one can write:\n\n\n[\nY\n,\nI\n]\n \n=\n \nsort\n(\nX\n,\n1\n,\n'ascend'\n);\n\n\n\n\n\nso if \nX\n is a \nm \\times n\nm \\times n\n matrix then \nY\n will also be an \nm \\times n\nm \\times n\n matrix\nwith entries sorted along dimension \n1\n in \n'ascend'\ning order. The second\noutput \nI\n is a \nm \\times n\nm \\times n\n matrix of indices such that \nY(i,j) =X(I(i,j),j);\n. That is, \nI\n reveals how \nX\n is sorted into \nY\n.\n\n\nThis same functionality is supported in libigl:\n\n\nigl\n::\nsort\n(\nX\n,\n1\n,\ntrue\n,\nY\n,\nI\n);\n\n\n\n\n\nSimilarly, sorting entire rows can be accomplished in Matlab using:\n\n\n[\nY\n,\nI\n]\n \n=\n \nsortrows\n(\nX\n,\n'ascend'\n);\n\n\n\n\n\nwhere now \nI\n is a \nm\nm\n vector of indices such that \nY = X(I,:)\n.\n\n\nIn libigl, this is supported with\n\n\nigl\n::\nsortrows\n(\nX\n,\ntrue\n,\nY\n,\nI\n);\n\n\n\nwhere again \nI\n reveals the index of sort so that it can be reproduced with\n\nigl::slice(X,I,1,Y)\n.\n\n\nAnalogous functions are available in libigl for: \nmax\n, \nmin\n, and \nunique\n.\n\n\n\n\nOther Matlab-style functions\n\u00b6\n\n\nLibigl implements a variety of other routines with the same api and\nfunctionality as common Matlab functions.\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nigl::all\n\n\nWhether all elements are non-zero (true)\n\n\n\n\n\n\nigl::any\n\n\nWhether any elements are non-zero (true)\n\n\n\n\n\n\nigl::cat\n\n\nConcatenate two matrices (especially useful for dealing with Eigen sparse matrices)\n\n\n\n\n\n\nigl::ceil\n\n\nRound entries up to nearest integer\n\n\n\n\n\n\nigl::cumsum\n\n\nCumulative sum of matrix elements\n\n\n\n\n\n\nigl::colon\n\n\nAct like Matlab's \n:\n, similar to Eigen's \nLinSpaced\n\n\n\n\n\n\nigl::components\n\n\nConnected components of graph (cf. Matlab's \ngraphconncomp\n)\n\n\n\n\n\n\nigl::count\n\n\nCount non-zeros in rows or columns\n\n\n\n\n\n\nigl::cross\n\n\nCross product per-row\n\n\n\n\n\n\nigl::cumsum\n\n\nCumulative summation\n\n\n\n\n\n\nigl::dot\n\n\ndot product per-row\n\n\n\n\n\n\nigl::eigs\n\n\nSolve sparse eigen value problem\n\n\n\n\n\n\nigl::find\n\n\nFind subscripts of non-zero entries\n\n\n\n\n\n\nigl::floor\n\n\nRound entries down to nearest integer\n\n\n\n\n\n\nigl::histc\n\n\nCounting occurrences for building a histogram\n\n\n\n\n\n\nigl::hsv_to_rgb\n\n\nConvert HSV colors to RGB (cf. Matlab's \nhsv2rgb\n)\n\n\n\n\n\n\nigl::intersect\n\n\nSet intersection of matrix elements.\n\n\n\n\n\n\nigl::isdiag\n\n\nDetermine whether matrix is diagonal\n\n\n\n\n\n\nigl::ismember\n\n\nDetermine whether elements in A occur in B\n\n\n\n\n\n\nigl::jet\n\n\nQuantized colors along the rainbow.\n\n\n\n\n\n\nigl::max\n\n\nCompute maximum entry per row or column\n\n\n\n\n\n\nigl::median\n\n\nCompute the median per column\n\n\n\n\n\n\nigl::min\n\n\nCompute minimum entry per row or column\n\n\n\n\n\n\nigl::mod\n\n\nCompute per element modulo\n\n\n\n\n\n\nigl::mode\n\n\nCompute the mode per column\n\n\n\n\n\n\nigl::null\n\n\nCompute the null space basis of a matrix\n\n\n\n\n\n\nigl::nchoosek\n\n\nCompute all k-size combinations of n-long vector\n\n\n\n\n\n\nigl::orth\n\n\nOrthogonalization of a basis\n\n\n\n\n\n\nigl::parula\n\n\nGenerate a quantized colormap from blue to yellow\n\n\n\n\n\n\nigl::pinv\n\n\nCompute Moore-Penrose pseudoinverse\n\n\n\n\n\n\nigl::randperm\n\n\nGenerate a random permutation of [0,...,n-1]\n\n\n\n\n\n\nigl::rgb_to_hsv\n\n\nConvert RGB colors to HSV (cf. Matlab's \nrgb2hsv\n)\n\n\n\n\n\n\nigl::repmat\n\n\nRepeat a matrix along columns and rows\n\n\n\n\n\n\nigl::round\n\n\nPer-element round to whole number\n\n\n\n\n\n\nigl::setdiff\n\n\nSet difference of matrix elements\n\n\n\n\n\n\nigl::setunion\n\n\nSet union of matrix elements\n\n\n\n\n\n\nigl::setxor\n\n\nSet exclusive \"or\" of matrix elements\n\n\n\n\n\n\nigl::slice\n\n\nSlice parts of matrix using index lists: (cf. Matlab's \nB = A(I,J)\n)\n\n\n\n\n\n\nigl::slice_mask\n\n\nSlice parts of matrix using boolean masks: (cf. Matlab's \nB = A(M,N)\n)\n\n\n\n\n\n\nigl::slice_into\n\n\nSlice left-hand side of matrix assignment using index lists (cf. Matlab's \nB(I,J) = A\n)\n\n\n\n\n\n\nigl::sort\n\n\nSort elements or rows of matrix\n\n\n\n\n\n\nigl::speye\n\n\nIdentity as sparse matrix\n\n\n\n\n\n\nigl::sum\n\n\nSum along columns or rows (of sparse matrix)\n\n\n\n\n\n\nigl::unique\n\n\nExtract unique elements or rows of matrix\n\n\n\n\n\n\n\n\nLaplace equation\n\u00b6\n\n\nA common linear system in geometry processing is the Laplace equation:\n\n\n\u2206z = 0\n\u2206z = 0\n\n\nsubject to some boundary conditions, for example Dirichlet boundary conditions\n(fixed value):\n\n\n\\left.z\\right|_{\\partial{S}} = z_{bc}\n\\left.z\\right|_{\\partial{S}} = z_{bc}\n\n\nIn the discrete setting, the linear system can be written as:\n\n\n\\mathbf{L} \\mathbf{z} = \\mathbf{0}\n\\mathbf{L} \\mathbf{z} = \\mathbf{0}\n\n\nwhere \n\\mathbf{L}\n\\mathbf{L}\n is the \nn \\times n\nn \\times n\n discrete Laplacian and \n\\mathbf{z}\n\\mathbf{z}\n is a\nvector of per-vertex values. Most of \n\\mathbf{z}\n\\mathbf{z}\n correspond to interior\nvertices and are unknown, but some of \n\\mathbf{z}\n\\mathbf{z}\n represent values at boundary\nvertices. Their values are known so we may move their corresponding terms to\nthe right-hand side.\n\n\nConceptually, this is very easy if we have sorted \n\\mathbf{z}\n\\mathbf{z}\n so that interior\nvertices come first and then boundary vertices:\n\n\n\\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} & \\mathbf{L}_{in,b}\\\\\n \\mathbf{L}_{b,in} & \\mathbf{L}_{b,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\left(\\begin{array}{c}\n \\mathbf{0}_{in}\\\\\n \\mathbf{z}_{bc}\\end{array}\\right)\n\\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} & \\mathbf{L}_{in,b}\\\\\n \\mathbf{L}_{b,in} & \\mathbf{L}_{b,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\left(\\begin{array}{c}\n \\mathbf{0}_{in}\\\\\n \\mathbf{z}_{bc}\\end{array}\\right)\n<span><span class=\"MathJax_Preview\">\\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} &amp; \\mathbf{L}_{in,b}\\\\\n \\mathbf{L}_{b,in} &amp; \\mathbf{L}_{b,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\left(\\begin{array}{c}\n \\mathbf{0}_{in}\\\\\n \\mathbf{z}_{bc}\\end{array}\\right)</span><script type=\"math/tex\">\\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} & \\mathbf{L}_{in,b}\\\\\n \\mathbf{L}_{b,in} & \\mathbf{L}_{b,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\left(\\begin{array}{c}\n \\mathbf{0}_{in}\\\\\n \\mathbf{z}_{bc}\\end{array}\\right)\n\n\nThe bottom block of equations is no longer meaningful so we'll only consider\nthe top block:\n\n\n\\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} & \\mathbf{L}_{in,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\mathbf{0}_{in}\n\\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} & \\mathbf{L}_{in,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\mathbf{0}_{in}\n<span><span class=\"MathJax_Preview\">\\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} &amp; \\mathbf{L}_{in,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\mathbf{0}_{in}</span><script type=\"math/tex\">\\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} & \\mathbf{L}_{in,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\mathbf{0}_{in}\n\n\nWe can move the known values to the right-hand side:\n\n\n\\mathbf{L}_{in,in}\n \\mathbf{z}_{in} = -\n \\mathbf{L}_{in,b}\n \\mathbf{z}_{b}\n\\mathbf{L}_{in,in}\n \\mathbf{z}_{in} = -\n \\mathbf{L}_{in,b}\n \\mathbf{z}_{b}\n<span><span class=\"MathJax_Preview\">\\mathbf{L}_{in,in}\n \\mathbf{z}_{in} = -\n \\mathbf{L}_{in,b}\n \\mathbf{z}_{b}</span><script type=\"math/tex\">\\mathbf{L}_{in,in}\n \\mathbf{z}_{in} = -\n \\mathbf{L}_{in,b}\n \\mathbf{z}_{b}\n\n\nFinally we can solve this equation for the unknown values at interior vertices\n\n\\mathbf{z}_{in}\n\\mathbf{z}_{in}\n.\n\n\nHowever, our vertices will often not be sorted in this way. One option would be to sort \nV\n,\nthen proceed as above and then \nunsort\n the solution \nZ\n to match \nV\n. However,\nthis solution is not very general.\n\n\nWith array slicing no explicit sort is needed. Instead we can \nslice-out\n\nsubmatrix blocks (\n\\mathbf{L}_{in,in}\n\\mathbf{L}_{in,in}\n, \n\\mathbf{L}_{in,b}\n\\mathbf{L}_{in,b}\n, etc.) and follow\nthe linear algebra above directly. Then we can slice the solution \ninto\n the\nrows of \nZ\n corresponding to the interior vertices (\nExample 303\n).\n\n\n\n\nQuadratic energy minimization\n\u00b6\n\n\nThe same Laplace equation may be equivalently derived by minimizing Dirichlet\nenergy subject to the same boundary conditions:\n\n\n\\mathop{\\text{minimize }}_z \\frac{1}{2}\\int\\limits_S \\|\\nabla z\\|^2 dA\n\\mathop{\\text{minimize }}_z \\frac{1}{2}\\int\\limits_S \\|\\nabla z\\|^2 dA\n\n\nOn our discrete mesh, recall that this becomes\n\n\n\\mathop{\\text{minimize }}_\\mathbf{z}  \\frac{1}{2}\\mathbf{z}^T \\mathbf{G}^T \\mathbf{D}\n \\mathbf{G} \\mathbf{z} \\rightarrow \\mathop{\\text{minimize }}_\\mathbf{z} \\mathbf{z}^T \\mathbf{L} \\mathbf{z}\n\\mathop{\\text{minimize }}_\\mathbf{z}  \\frac{1}{2}\\mathbf{z}^T \\mathbf{G}^T \\mathbf{D}\n \\mathbf{G} \\mathbf{z} \\rightarrow \\mathop{\\text{minimize }}_\\mathbf{z} \\mathbf{z}^T \\mathbf{L} \\mathbf{z}\n\n\nThe general problem of minimizing some energy over a mesh subject to fixed\nvalue boundary conditions is so wide spread that libigl has a dedicated api for\nsolving such systems.\n\n\nLet us consider a general quadratic minimization problem subject to different\ncommon constraints:\n\n\n\\mathop{\\text{minimize }}_\\mathbf{z}  \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n \\mathbf{z}^T \\mathbf{B} + \\text{constant},\n\\mathop{\\text{minimize }}_\\mathbf{z}  \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n \\mathbf{z}^T \\mathbf{B} + \\text{constant},\n<span><span class=\"MathJax_Preview\">\\mathop{\\text{minimize }}_\\mathbf{z}  \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n \\mathbf{z}^T \\mathbf{B} + \\text{constant},</span><script type=\"math/tex\">\\mathop{\\text{minimize }}_\\mathbf{z}  \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n \\mathbf{z}^T \\mathbf{B} + \\text{constant},\n\n\nsubject to\n\n\n\\mathbf{z}_b = \\mathbf{z}_{bc} \\text{ and } \\mathbf{A}_{eq} \\mathbf{z} =\n \\mathbf{B}_{eq},\n\\mathbf{z}_b = \\mathbf{z}_{bc} \\text{ and } \\mathbf{A}_{eq} \\mathbf{z} =\n \\mathbf{B}_{eq},\n<span><span class=\"MathJax_Preview\">\\mathbf{z}_b = \\mathbf{z}_{bc} \\text{ and } \\mathbf{A}_{eq} \\mathbf{z} =\n \\mathbf{B}_{eq},</span><script type=\"math/tex\">\\mathbf{z}_b = \\mathbf{z}_{bc} \\text{ and } \\mathbf{A}_{eq} \\mathbf{z} =\n \\mathbf{B}_{eq},\n\n\nwhere\n\n\n\n\n\\mathbf{Q}\n\\mathbf{Q}\n is a (usually sparse) \nn \\times n\nn \\times n\n positive semi-definite\n    matrix of quadratic coefficients (Hessian),\n\n\n\\mathbf{B}\n\\mathbf{B}\n is a \nn \\times 1\nn \\times 1\n vector of linear coefficients,\n\n\n\\mathbf{z}_b\n\\mathbf{z}_b\n is a \n|b| \\times 1\n|b| \\times 1\n portion of\n\n\\mathbf{z}\n\\mathbf{z}\n corresponding to boundary or \nfixed\n vertices,\n\n\n\\mathbf{z}_{bc}\n\\mathbf{z}_{bc}\n is a \n|b| \\times 1\n|b| \\times 1\n vector of known values corresponding to\n    \n\\mathbf{z}_b\n\\mathbf{z}_b\n,\n\n\n\\mathbf{A}_{eq}\n\\mathbf{A}_{eq}\n is a (usually sparse) \nm \\times n\nm \\times n\n matrix of linear\n    equality constraint coefficients (one row per constraint), and\n\n\n\\mathbf{B}_{eq}\n\\mathbf{B}_{eq}\n is a \nm \\times 1\nm \\times 1\n vector of linear equality constraint\n    right-hand side values.\n\n\n\n\nThis specification is overly general as we could write \n\\mathbf{z}_b =\n\\mathbf{z}_{bc}\n\\mathbf{z}_b =\n\\mathbf{z}_{bc}\n as rows of \n\\mathbf{A}_{eq} \\mathbf{z} =\n\\mathbf{B}_{eq}\n\\mathbf{A}_{eq} \\mathbf{z} =\n\\mathbf{B}_{eq}\n, but these fixed value constraints appear so often that they\nmerit a dedicated place in the API.\n\n\nIn libigl, solving such quadratic optimization problems is split into two\nroutines: precomputation and solve. Precomputation only depends on the\nquadratic coefficients, known value indices and linear constraint coefficients:\n\n\nigl\n::\nmin_quad_with_fixed_data\n \nmqwf\n;\n\n\nigl\n::\nmin_quad_with_fixed_precompute\n(\nQ\n,\nb\n,\nAeq\n,\ntrue\n,\nmqwf\n);\n\n\n\n\n\nThe output is a struct \nmqwf\n which contains the system matrix factorization\nand is used during solving with arbitrary linear terms, known values, and\nconstraint in the right-hand sides:\n\n\nigl\n::\nmin_quad_with_fixed_solve\n(\nmqwf\n,\nB\n,\nbc\n,\nBeq\n,\nZ\n);\n\n\n\n\n\nThe output \nZ\n is a \nn \\times 1\nn \\times 1\n vector of solutions with fixed values\ncorrectly placed to match the mesh vertices \nV\n.\n\n\nLinear equality constraints\n\u00b6\n\n\nWe saw above that \nmin_quad_with_fixed_*\n in libigl provides a compact way to\nsolve general quadratic programs. Let's consider another example, this time\nwith active linear equality constraints. Specifically let's solve the\n\nbi-Laplace equation\n or equivalently minimize the Laplace energy:\n\n\n\\Delta^2 z = 0 \\leftrightarrow \\mathop{\\text{minimize }}\\limits_z \\frac{1}{2}\n \\int\\limits_S (\\Delta z)^2 dA\n\\Delta^2 z = 0 \\leftrightarrow \\mathop{\\text{minimize }}\\limits_z \\frac{1}{2}\n \\int\\limits_S (\\Delta z)^2 dA\n<span><span class=\"MathJax_Preview\">\\Delta^2 z = 0 \\leftrightarrow \\mathop{\\text{minimize }}\\limits_z \\frac{1}{2}\n \\int\\limits_S (\\Delta z)^2 dA</span><script type=\"math/tex\">\\Delta^2 z = 0 \\leftrightarrow \\mathop{\\text{minimize }}\\limits_z \\frac{1}{2}\n \\int\\limits_S (\\Delta z)^2 dA\n\n\nsubject to fixed value constraints and a linear equality constraint:\n\n\nz_{a} = 1, z_{b} = -1\nz_{a} = 1, z_{b} = -1\n and \nz_{c} = z_{d}\nz_{c} = z_{d}\n.\n\n\nNotice that we can rewrite the last constraint in the familiar form from above:\n\n\nz_{c} - z_{d} = 0.\nz_{c} - z_{d} = 0.\n\n\nNow we can assembly \nAeq\n as a \n1 \\times n\n1 \\times n\n sparse matrix with a coefficient\n\n1\n1\n in the column corresponding to vertex \nc\nc\n and a \n-1\n-1\n at \nd\nd\n. The right-hand\nside \nBeq\n is simply zero.\n\n\nInternally, \nmin_quad_with_fixed_*\n solves using the Lagrange Multiplier\nmethod. This method adds additional variables for each linear constraint (in\ngeneral a \nm \\times 1\nm \\times 1\n vector of variables \n\\lambda\n\\lambda\n) and then solves the\nsaddle problem:\n\n\n\\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\, \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n  \\mathbf{z}^T \\mathbf{B} + \\text{constant} + \\lambda^T\\left(\\mathbf{A}_{eq}\n \\mathbf{z} - \\mathbf{B}_{eq}\\right)\n\\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\, \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n  \\mathbf{z}^T \\mathbf{B} + \\text{constant} + \\lambda^T\\left(\\mathbf{A}_{eq}\n \\mathbf{z} - \\mathbf{B}_{eq}\\right)\n<span><span class=\"MathJax_Preview\">\\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\, \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n  \\mathbf{z}^T \\mathbf{B} + \\text{constant} + \\lambda^T\\left(\\mathbf{A}_{eq}\n \\mathbf{z} - \\mathbf{B}_{eq}\\right)</span><script type=\"math/tex\">\\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\, \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n  \\mathbf{z}^T \\mathbf{B} + \\text{constant} + \\lambda^T\\left(\\mathbf{A}_{eq}\n \\mathbf{z} - \\mathbf{B}_{eq}\\right)\n\n\nThis can be rewritten in a more familiar form by stacking \n\\mathbf{z}\n\\mathbf{z}\n and\n\n\\lambda\n\\lambda\n into one \n(m+n) \\times 1\n(m+n) \\times 1\n vector of unknowns:\n\n\n\\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\,\n \\frac{1}{2}\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{cc}\n  \\mathbf{Q}      & \\mathbf{A}_{eq}^T\\\\\n  \\mathbf{A}_{eq} & 0\n  \\end{array}\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{z}\\\\\n  \\lambda\n  \\end{array}\n \\right) +\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{B}\\\\\n  -\\mathbf{B}_{eq}\n  \\end{array}\n  \\right)\n  + \\text{constant}\n\\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\,\n \\frac{1}{2}\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{cc}\n  \\mathbf{Q}      & \\mathbf{A}_{eq}^T\\\\\n  \\mathbf{A}_{eq} & 0\n  \\end{array}\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{z}\\\\\n  \\lambda\n  \\end{array}\n \\right) +\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{B}\\\\\n  -\\mathbf{B}_{eq}\n  \\end{array}\n  \\right)\n  + \\text{constant}\n<span><span class=\"MathJax_Preview\">\\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\,\n \\frac{1}{2}\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{cc}\n  \\mathbf{Q}      &amp; \\mathbf{A}_{eq}^T\\\\\n  \\mathbf{A}_{eq} &amp; 0\n  \\end{array}\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{z}\\\\\n  \\lambda\n  \\end{array}\n \\right) +\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{B}\\\\\n  -\\mathbf{B}_{eq}\n  \\end{array}\n  \\right)\n  + \\text{constant}</span><script type=\"math/tex\">\\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\,\n \\frac{1}{2}\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{cc}\n  \\mathbf{Q}      & \\mathbf{A}_{eq}^T\\\\\n  \\mathbf{A}_{eq} & 0\n  \\end{array}\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{z}\\\\\n  \\lambda\n  \\end{array}\n \\right) +\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{B}\\\\\n  -\\mathbf{B}_{eq}\n  \\end{array}\n  \\right)\n  + \\text{constant}\n\n\nDifferentiating with respect to \n\\left( \\mathbf{z}^T \\lambda^T \\right)\n\\left( \\mathbf{z}^T \\lambda^T \\right)\n reveals\na linear system and we can solve for \n\\mathbf{z}\n\\mathbf{z}\n and \n\\lambda\n\\lambda\n. The only\ndifference from the straight quadratic \nminimization\n system, is that this\nsaddle problem system will not be positive definite. Thus, we must use a\ndifferent factorization technique (LDLT rather than LLT): libigl's\n\nmin_quad_with_fixed_precompute\n automatically chooses the correct solver in\nthe presence of linear equality constraints (\nExample 304\n).\n\n\n\n\nQuadratic programming\n\u00b6\n\n\nWe can generalize the quadratic optimization in the previous section even more\nby allowing inequality constraints. Specifically box constraints (lower and\nupper bounds):\n\n\n\\mathbf{l} \\le \\mathbf{z} \\le \\mathbf{u},\n\\mathbf{l} \\le \\mathbf{z} \\le \\mathbf{u},\n\n\nwhere \n\\mathbf{l},\\mathbf{u}\n\\mathbf{l},\\mathbf{u}\n are \nn \\times 1\nn \\times 1\n vectors of lower and upper\nbounds\nand general linear inequality constraints:\n\n\n\\mathbf{A}_{ieq} \\mathbf{z} \\le \\mathbf{B}_{ieq},\n\\mathbf{A}_{ieq} \\mathbf{z} \\le \\mathbf{B}_{ieq},\n\n\nwhere \n\\mathbf{A}_{ieq}\n\\mathbf{A}_{ieq}\n is a \nk \\times n\nk \\times n\n matrix of linear coefficients and\n\n\\mathbf{B}_{ieq}\n\\mathbf{B}_{ieq}\n is a \nk \\times 1\nk \\times 1\n matrix of constraint right-hand sides.\n\n\nAgain, we are overly general as the box constraints could be written as\nrows of the linear inequality constraints, but bounds appear frequently enough\nto merit a dedicated api.\n\n\nLibigl implements its own active set routine for solving \nquadratric programs\n\n(QPs). This algorithm works by iteratively \"activating\" violated inequality\nconstraints by enforcing them as equalities and \"deactivating\" constraints\nwhich are no longer needed.\n\n\nAfter deciding which constraints are active at each iteration, the problem\nreduces to a quadratic minimization subject to linear \nequality\n constraints,\nand the method from the previous section is invoked. This is repeated until convergence.\n\n\nCurrently the implementation is efficient for box constraints and sparse\nnon-overlapping linear inequality constraints.\n\n\nUnlike alternative interior-point methods, the active set method benefits from\na warm-start (initial guess for the solution vector \n\\mathbf{z}\n\\mathbf{z}\n).\n\n\nigl\n::\nactive_set_params\n \nas\n;\n\n\n// Z is optional initial guess and output\n\n\nigl\n::\nactive_set\n(\nQ\n,\nB\n,\nb\n,\nbc\n,\nAeq\n,\nBeq\n,\nAieq\n,\nBieq\n,\nlx\n,\nux\n,\nas\n,\nZ\n);\n\n\n\n\n\n\n\nEigen Decomposition\n\u00b6\n\n\nLibigl has rudimentary support for extracting eigen pairs of a generalized\neigen value problem:\n\n\nAx = \\lambda B x\nAx = \\lambda B x\n\n\nwhere \nA\nA\n is a sparse symmetric matrix and \nB\nB\n is a sparse positive definite\nmatrix. Most commonly in geometry processing, we let \nA=L\nA=L\n the cotangent\nLaplacian and \nB=M\nB=M\n the per-vertex mass matrix (e.g. [#vallet_2008][]).\nTypically applications will make use of the \nlow frequency\n eigen modes.\nAnalogous to the Fourier decomposition, a function \nf\nf\n on a surface can be\nrepresented via its spectral decomposition of the eigen modes of the\nLaplace-Beltrami:\n\n\nf = \\sum\\limits_{i=1}^\\infty a_i \\phi_i\nf = \\sum\\limits_{i=1}^\\infty a_i \\phi_i\n\n\nwhere each \n\\phi_i\n\\phi_i\n is an eigen function satisfying: \n\\Delta \\phi_i = \\lambda_i\n\\phi_i\n\\Delta \\phi_i = \\lambda_i\n\\phi_i\n and \na_i\na_i\n are scalar coefficients. For a discrete triangle mesh, a\ncompletely analogous decomposition exists, albeit with finite sum:\n\n\n\\mathbf{f} = \\sum\\limits_{i=1}^n a_i \\phi_i\n\\mathbf{f} = \\sum\\limits_{i=1}^n a_i \\phi_i\n\n\nwhere now a column vector of values at vertices \n\\mathbf{f} \\in \\mathcal{R}^n\n\\mathbf{f} \\in \\mathcal{R}^n\n\nspecifies a piecewise linear function and \n\\phi_i \\in \\mathcal{R}^n\n\\phi_i \\in \\mathcal{R}^n\n is an\neigen vector satisfying:\n\n\n\\mathbf{L} \\phi_i = \\lambda_i \\mathbf{M} \\phi_i\n\\mathbf{L} \\phi_i = \\lambda_i \\mathbf{M} \\phi_i\n.\n\n\nNote that Vallet & Levy [#vallet_2008][] propose solving a symmetrized\n\nstandard\n eigen problem \n\\mathbf{M}^{-1/2}\\mathbf{L}\\mathbf{M}^{-1/2} \\phi_i\n= \\lambda_i \\phi_i\n\\mathbf{M}^{-1/2}\\mathbf{L}\\mathbf{M}^{-1/2} \\phi_i\n= \\lambda_i \\phi_i\n. Libigl implements a generalized eigen problem solver so\nthis unnecessary symmetrization can be avoided.\n\n\nOften the sum above is \ntruncated\n to the first \nk\nk\n eigen vectors. If the low\nfrequency modes are chosen, i.e. those corresponding to small \n\\lambda_i\n\\lambda_i\n\nvalues, then this truncation effectively \nregularizes\n \n\\mathbf{f}\n\\mathbf{f}\n to smooth,\nslowly changing functions over the mesh (e.g. [#hildebrandt_2011][]). Modal\nanalysis and model subspaces have been used frequently in real-time deformation\n(e.g. [#barbic_2005][]).\n\n\nIn \nExample 306\n), the first 5 eigen vectors\nof the discrete Laplace-Beltrami operator are computed and displayed in\npseudo-color atop the beetle. Eigen vectors are computed using \nigl::eigs\n\n(mirroring MATLAB's \neigs\n). The 5 eigen vectors are placed into the columns\nof \nU\n and the eigen values are placed into the entries of \nS\n:\n\n\nSparseMatrix\n<\ndouble\n>\n \nL\n,\nM\n;\n\n\nigl\n::\ncotmatrix\n(\nV\n,\nF\n,\nL\n);\n\n\nigl\n::\nmassmatrix\n(\nV\n,\nF\n,\nigl\n::\nMASSMATRIX_TYPE_DEFAULT\n,\nM\n);\n\n\nEigen\n::\nMatrixXd\n \nU\n;\n\n\nEigen\n::\nVectorXd\n \nS\n;\n\n\nigl\n::\neigs\n(\nL\n,\nM\n,\n5\n,\nigl\n::\nEIGS_TYPE_SM\n,\nU\n,\nS\n);",
            "title": "Chapter 3: Matrices and Linear Algebra"
        },
        {
            "location": "/tutorial/chapter-3/#chapter-3-matrices-and-linear-algebra",
            "text": "Libigl relies heavily on the Eigen library for dense and sparse linear algebra\nroutines. Besides geometry processing routines, libigl has linear algebra\nroutines which bootstrap Eigen and make it feel even more similar to a high-level\nalgebra library such as Matlab.",
            "title": "Chapter 3: Matrices and linear algebra"
        },
        {
            "location": "/tutorial/chapter-3/#slice",
            "text": "A very familiar and powerful routine in Matlab is array slicing. This allows\nreading from or writing to a possibly non-contiguous sub-matrix. Let's consider\nthe Matlab code:  B   =   A ( R , C );   If  A  is a  m \\times n m \\times n  matrix and  R  is a  j j -long list of row-indices\n(between 1 and  m m ) and  C  is a  k k -long list of column-indices, then as a\nresult  B  will be a  j \\times k j \\times k  matrix drawing elements from  A  according to R  and  C . In libigl, the same functionality is provided by the  slice \nfunction ( Example 301 ):  VectorXi   R , C ;  MatrixXd   A , B ;  ...  igl :: slice ( A , R , C , B );   Note that  A  and  B  could also be sparse matrices.  Similarly, consider the Matlab code:  A ( R , C )   =   B ;   Now, the selection is on the left-hand side so the  j \\times k j \\times k  matrix   B  is\nbeing  written into  the submatrix of  A  determined by  R  and  C . This\nfunctionality is provided in libigl using  slice_into :  igl :: slice_into ( B , R , C , A );",
            "title": "Slice"
        },
        {
            "location": "/tutorial/chapter-3/#sort",
            "text": "Matlab and other higher-level languages make it very easy to extract indices of\nsorting and comparison routines. For example in Matlab, one can write:  [ Y , I ]   =   sort ( X , 1 , 'ascend' );   so if  X  is a  m \\times n m \\times n  matrix then  Y  will also be an  m \\times n m \\times n  matrix\nwith entries sorted along dimension  1  in  'ascend' ing order. The second\noutput  I  is a  m \\times n m \\times n  matrix of indices such that  Y(i,j) =X(I(i,j),j); . That is,  I  reveals how  X  is sorted into  Y .  This same functionality is supported in libigl:  igl :: sort ( X , 1 , true , Y , I );   Similarly, sorting entire rows can be accomplished in Matlab using:  [ Y , I ]   =   sortrows ( X , 'ascend' );   where now  I  is a  m m  vector of indices such that  Y = X(I,:) .  In libigl, this is supported with  igl :: sortrows ( X , true , Y , I );  \nwhere again  I  reveals the index of sort so that it can be reproduced with igl::slice(X,I,1,Y) .  Analogous functions are available in libigl for:  max ,  min , and  unique .",
            "title": "Sort"
        },
        {
            "location": "/tutorial/chapter-3/#other-matlab-style-functions",
            "text": "Libigl implements a variety of other routines with the same api and\nfunctionality as common Matlab functions.     Name  Description      igl::all  Whether all elements are non-zero (true)    igl::any  Whether any elements are non-zero (true)    igl::cat  Concatenate two matrices (especially useful for dealing with Eigen sparse matrices)    igl::ceil  Round entries up to nearest integer    igl::cumsum  Cumulative sum of matrix elements    igl::colon  Act like Matlab's  : , similar to Eigen's  LinSpaced    igl::components  Connected components of graph (cf. Matlab's  graphconncomp )    igl::count  Count non-zeros in rows or columns    igl::cross  Cross product per-row    igl::cumsum  Cumulative summation    igl::dot  dot product per-row    igl::eigs  Solve sparse eigen value problem    igl::find  Find subscripts of non-zero entries    igl::floor  Round entries down to nearest integer    igl::histc  Counting occurrences for building a histogram    igl::hsv_to_rgb  Convert HSV colors to RGB (cf. Matlab's  hsv2rgb )    igl::intersect  Set intersection of matrix elements.    igl::isdiag  Determine whether matrix is diagonal    igl::ismember  Determine whether elements in A occur in B    igl::jet  Quantized colors along the rainbow.    igl::max  Compute maximum entry per row or column    igl::median  Compute the median per column    igl::min  Compute minimum entry per row or column    igl::mod  Compute per element modulo    igl::mode  Compute the mode per column    igl::null  Compute the null space basis of a matrix    igl::nchoosek  Compute all k-size combinations of n-long vector    igl::orth  Orthogonalization of a basis    igl::parula  Generate a quantized colormap from blue to yellow    igl::pinv  Compute Moore-Penrose pseudoinverse    igl::randperm  Generate a random permutation of [0,...,n-1]    igl::rgb_to_hsv  Convert RGB colors to HSV (cf. Matlab's  rgb2hsv )    igl::repmat  Repeat a matrix along columns and rows    igl::round  Per-element round to whole number    igl::setdiff  Set difference of matrix elements    igl::setunion  Set union of matrix elements    igl::setxor  Set exclusive \"or\" of matrix elements    igl::slice  Slice parts of matrix using index lists: (cf. Matlab's  B = A(I,J) )    igl::slice_mask  Slice parts of matrix using boolean masks: (cf. Matlab's  B = A(M,N) )    igl::slice_into  Slice left-hand side of matrix assignment using index lists (cf. Matlab's  B(I,J) = A )    igl::sort  Sort elements or rows of matrix    igl::speye  Identity as sparse matrix    igl::sum  Sum along columns or rows (of sparse matrix)    igl::unique  Extract unique elements or rows of matrix",
            "title": "Other Matlab-style functions"
        },
        {
            "location": "/tutorial/chapter-3/#laplace-equation",
            "text": "A common linear system in geometry processing is the Laplace equation:  \u2206z = 0 \u2206z = 0  subject to some boundary conditions, for example Dirichlet boundary conditions\n(fixed value):  \\left.z\\right|_{\\partial{S}} = z_{bc} \\left.z\\right|_{\\partial{S}} = z_{bc}  In the discrete setting, the linear system can be written as:  \\mathbf{L} \\mathbf{z} = \\mathbf{0} \\mathbf{L} \\mathbf{z} = \\mathbf{0}  where  \\mathbf{L} \\mathbf{L}  is the  n \\times n n \\times n  discrete Laplacian and  \\mathbf{z} \\mathbf{z}  is a\nvector of per-vertex values. Most of  \\mathbf{z} \\mathbf{z}  correspond to interior\nvertices and are unknown, but some of  \\mathbf{z} \\mathbf{z}  represent values at boundary\nvertices. Their values are known so we may move their corresponding terms to\nthe right-hand side.  Conceptually, this is very easy if we have sorted  \\mathbf{z} \\mathbf{z}  so that interior\nvertices come first and then boundary vertices:  \\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} & \\mathbf{L}_{in,b}\\\\\n \\mathbf{L}_{b,in} & \\mathbf{L}_{b,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\left(\\begin{array}{c}\n \\mathbf{0}_{in}\\\\\n \\mathbf{z}_{bc}\\end{array}\\right) \\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} & \\mathbf{L}_{in,b}\\\\\n \\mathbf{L}_{b,in} & \\mathbf{L}_{b,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\left(\\begin{array}{c}\n \\mathbf{0}_{in}\\\\\n \\mathbf{z}_{bc}\\end{array}\\right) <span><span class=\"MathJax_Preview\">\\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} &amp; \\mathbf{L}_{in,b}\\\\\n \\mathbf{L}_{b,in} &amp; \\mathbf{L}_{b,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\left(\\begin{array}{c}\n \\mathbf{0}_{in}\\\\\n \\mathbf{z}_{bc}\\end{array}\\right)</span><script type=\"math/tex\">\\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} & \\mathbf{L}_{in,b}\\\\\n \\mathbf{L}_{b,in} & \\mathbf{L}_{b,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\left(\\begin{array}{c}\n \\mathbf{0}_{in}\\\\\n \\mathbf{z}_{bc}\\end{array}\\right)  The bottom block of equations is no longer meaningful so we'll only consider\nthe top block:  \\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} & \\mathbf{L}_{in,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\mathbf{0}_{in} \\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} & \\mathbf{L}_{in,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\mathbf{0}_{in} <span><span class=\"MathJax_Preview\">\\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} &amp; \\mathbf{L}_{in,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\mathbf{0}_{in}</span><script type=\"math/tex\">\\left(\\begin{array}{cc}\n \\mathbf{L}_{in,in} & \\mathbf{L}_{in,b}\\end{array}\\right)\n \\left(\\begin{array}{c}\n \\mathbf{z}_{in}\\\\\n \\mathbf{z}_{b}\\end{array}\\right) =\n \\mathbf{0}_{in}  We can move the known values to the right-hand side:  \\mathbf{L}_{in,in}\n \\mathbf{z}_{in} = -\n \\mathbf{L}_{in,b}\n \\mathbf{z}_{b} \\mathbf{L}_{in,in}\n \\mathbf{z}_{in} = -\n \\mathbf{L}_{in,b}\n \\mathbf{z}_{b} <span><span class=\"MathJax_Preview\">\\mathbf{L}_{in,in}\n \\mathbf{z}_{in} = -\n \\mathbf{L}_{in,b}\n \\mathbf{z}_{b}</span><script type=\"math/tex\">\\mathbf{L}_{in,in}\n \\mathbf{z}_{in} = -\n \\mathbf{L}_{in,b}\n \\mathbf{z}_{b}  Finally we can solve this equation for the unknown values at interior vertices \\mathbf{z}_{in} \\mathbf{z}_{in} .  However, our vertices will often not be sorted in this way. One option would be to sort  V ,\nthen proceed as above and then  unsort  the solution  Z  to match  V . However,\nthis solution is not very general.  With array slicing no explicit sort is needed. Instead we can  slice-out \nsubmatrix blocks ( \\mathbf{L}_{in,in} \\mathbf{L}_{in,in} ,  \\mathbf{L}_{in,b} \\mathbf{L}_{in,b} , etc.) and follow\nthe linear algebra above directly. Then we can slice the solution  into  the\nrows of  Z  corresponding to the interior vertices ( Example 303 ).",
            "title": "Laplace equation"
        },
        {
            "location": "/tutorial/chapter-3/#quadratic-energy-minimization",
            "text": "The same Laplace equation may be equivalently derived by minimizing Dirichlet\nenergy subject to the same boundary conditions:  \\mathop{\\text{minimize }}_z \\frac{1}{2}\\int\\limits_S \\|\\nabla z\\|^2 dA \\mathop{\\text{minimize }}_z \\frac{1}{2}\\int\\limits_S \\|\\nabla z\\|^2 dA  On our discrete mesh, recall that this becomes  \\mathop{\\text{minimize }}_\\mathbf{z}  \\frac{1}{2}\\mathbf{z}^T \\mathbf{G}^T \\mathbf{D}\n \\mathbf{G} \\mathbf{z} \\rightarrow \\mathop{\\text{minimize }}_\\mathbf{z} \\mathbf{z}^T \\mathbf{L} \\mathbf{z} \\mathop{\\text{minimize }}_\\mathbf{z}  \\frac{1}{2}\\mathbf{z}^T \\mathbf{G}^T \\mathbf{D}\n \\mathbf{G} \\mathbf{z} \\rightarrow \\mathop{\\text{minimize }}_\\mathbf{z} \\mathbf{z}^T \\mathbf{L} \\mathbf{z}  The general problem of minimizing some energy over a mesh subject to fixed\nvalue boundary conditions is so wide spread that libigl has a dedicated api for\nsolving such systems.  Let us consider a general quadratic minimization problem subject to different\ncommon constraints:  \\mathop{\\text{minimize }}_\\mathbf{z}  \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n \\mathbf{z}^T \\mathbf{B} + \\text{constant}, \\mathop{\\text{minimize }}_\\mathbf{z}  \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n \\mathbf{z}^T \\mathbf{B} + \\text{constant}, <span><span class=\"MathJax_Preview\">\\mathop{\\text{minimize }}_\\mathbf{z}  \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n \\mathbf{z}^T \\mathbf{B} + \\text{constant},</span><script type=\"math/tex\">\\mathop{\\text{minimize }}_\\mathbf{z}  \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n \\mathbf{z}^T \\mathbf{B} + \\text{constant},  subject to  \\mathbf{z}_b = \\mathbf{z}_{bc} \\text{ and } \\mathbf{A}_{eq} \\mathbf{z} =\n \\mathbf{B}_{eq}, \\mathbf{z}_b = \\mathbf{z}_{bc} \\text{ and } \\mathbf{A}_{eq} \\mathbf{z} =\n \\mathbf{B}_{eq}, <span><span class=\"MathJax_Preview\">\\mathbf{z}_b = \\mathbf{z}_{bc} \\text{ and } \\mathbf{A}_{eq} \\mathbf{z} =\n \\mathbf{B}_{eq},</span><script type=\"math/tex\">\\mathbf{z}_b = \\mathbf{z}_{bc} \\text{ and } \\mathbf{A}_{eq} \\mathbf{z} =\n \\mathbf{B}_{eq},  where   \\mathbf{Q} \\mathbf{Q}  is a (usually sparse)  n \\times n n \\times n  positive semi-definite\n    matrix of quadratic coefficients (Hessian),  \\mathbf{B} \\mathbf{B}  is a  n \\times 1 n \\times 1  vector of linear coefficients,  \\mathbf{z}_b \\mathbf{z}_b  is a  |b| \\times 1 |b| \\times 1  portion of \\mathbf{z} \\mathbf{z}  corresponding to boundary or  fixed  vertices,  \\mathbf{z}_{bc} \\mathbf{z}_{bc}  is a  |b| \\times 1 |b| \\times 1  vector of known values corresponding to\n     \\mathbf{z}_b \\mathbf{z}_b ,  \\mathbf{A}_{eq} \\mathbf{A}_{eq}  is a (usually sparse)  m \\times n m \\times n  matrix of linear\n    equality constraint coefficients (one row per constraint), and  \\mathbf{B}_{eq} \\mathbf{B}_{eq}  is a  m \\times 1 m \\times 1  vector of linear equality constraint\n    right-hand side values.   This specification is overly general as we could write  \\mathbf{z}_b =\n\\mathbf{z}_{bc} \\mathbf{z}_b =\n\\mathbf{z}_{bc}  as rows of  \\mathbf{A}_{eq} \\mathbf{z} =\n\\mathbf{B}_{eq} \\mathbf{A}_{eq} \\mathbf{z} =\n\\mathbf{B}_{eq} , but these fixed value constraints appear so often that they\nmerit a dedicated place in the API.  In libigl, solving such quadratic optimization problems is split into two\nroutines: precomputation and solve. Precomputation only depends on the\nquadratic coefficients, known value indices and linear constraint coefficients:  igl :: min_quad_with_fixed_data   mqwf ;  igl :: min_quad_with_fixed_precompute ( Q , b , Aeq , true , mqwf );   The output is a struct  mqwf  which contains the system matrix factorization\nand is used during solving with arbitrary linear terms, known values, and\nconstraint in the right-hand sides:  igl :: min_quad_with_fixed_solve ( mqwf , B , bc , Beq , Z );   The output  Z  is a  n \\times 1 n \\times 1  vector of solutions with fixed values\ncorrectly placed to match the mesh vertices  V .",
            "title": "Quadratic energy minimization"
        },
        {
            "location": "/tutorial/chapter-3/#linear-equality-constraints",
            "text": "We saw above that  min_quad_with_fixed_*  in libigl provides a compact way to\nsolve general quadratic programs. Let's consider another example, this time\nwith active linear equality constraints. Specifically let's solve the bi-Laplace equation  or equivalently minimize the Laplace energy:  \\Delta^2 z = 0 \\leftrightarrow \\mathop{\\text{minimize }}\\limits_z \\frac{1}{2}\n \\int\\limits_S (\\Delta z)^2 dA \\Delta^2 z = 0 \\leftrightarrow \\mathop{\\text{minimize }}\\limits_z \\frac{1}{2}\n \\int\\limits_S (\\Delta z)^2 dA <span><span class=\"MathJax_Preview\">\\Delta^2 z = 0 \\leftrightarrow \\mathop{\\text{minimize }}\\limits_z \\frac{1}{2}\n \\int\\limits_S (\\Delta z)^2 dA</span><script type=\"math/tex\">\\Delta^2 z = 0 \\leftrightarrow \\mathop{\\text{minimize }}\\limits_z \\frac{1}{2}\n \\int\\limits_S (\\Delta z)^2 dA  subject to fixed value constraints and a linear equality constraint:  z_{a} = 1, z_{b} = -1 z_{a} = 1, z_{b} = -1  and  z_{c} = z_{d} z_{c} = z_{d} .  Notice that we can rewrite the last constraint in the familiar form from above:  z_{c} - z_{d} = 0. z_{c} - z_{d} = 0.  Now we can assembly  Aeq  as a  1 \\times n 1 \\times n  sparse matrix with a coefficient 1 1  in the column corresponding to vertex  c c  and a  -1 -1  at  d d . The right-hand\nside  Beq  is simply zero.  Internally,  min_quad_with_fixed_*  solves using the Lagrange Multiplier\nmethod. This method adds additional variables for each linear constraint (in\ngeneral a  m \\times 1 m \\times 1  vector of variables  \\lambda \\lambda ) and then solves the\nsaddle problem:  \\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\, \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n  \\mathbf{z}^T \\mathbf{B} + \\text{constant} + \\lambda^T\\left(\\mathbf{A}_{eq}\n \\mathbf{z} - \\mathbf{B}_{eq}\\right) \\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\, \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n  \\mathbf{z}^T \\mathbf{B} + \\text{constant} + \\lambda^T\\left(\\mathbf{A}_{eq}\n \\mathbf{z} - \\mathbf{B}_{eq}\\right) <span><span class=\"MathJax_Preview\">\\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\, \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n  \\mathbf{z}^T \\mathbf{B} + \\text{constant} + \\lambda^T\\left(\\mathbf{A}_{eq}\n \\mathbf{z} - \\mathbf{B}_{eq}\\right)</span><script type=\"math/tex\">\\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\, \\frac{1}{2}\\mathbf{z}^T \\mathbf{Q} \\mathbf{z} +\n  \\mathbf{z}^T \\mathbf{B} + \\text{constant} + \\lambda^T\\left(\\mathbf{A}_{eq}\n \\mathbf{z} - \\mathbf{B}_{eq}\\right)  This can be rewritten in a more familiar form by stacking  \\mathbf{z} \\mathbf{z}  and \\lambda \\lambda  into one  (m+n) \\times 1 (m+n) \\times 1  vector of unknowns:  \\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\,\n \\frac{1}{2}\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{cc}\n  \\mathbf{Q}      & \\mathbf{A}_{eq}^T\\\\\n  \\mathbf{A}_{eq} & 0\n  \\end{array}\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{z}\\\\\n  \\lambda\n  \\end{array}\n \\right) +\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{B}\\\\\n  -\\mathbf{B}_{eq}\n  \\end{array}\n  \\right)\n  + \\text{constant} \\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\,\n \\frac{1}{2}\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{cc}\n  \\mathbf{Q}      & \\mathbf{A}_{eq}^T\\\\\n  \\mathbf{A}_{eq} & 0\n  \\end{array}\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{z}\\\\\n  \\lambda\n  \\end{array}\n \\right) +\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{B}\\\\\n  -\\mathbf{B}_{eq}\n  \\end{array}\n  \\right)\n  + \\text{constant} <span><span class=\"MathJax_Preview\">\\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\,\n \\frac{1}{2}\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{cc}\n  \\mathbf{Q}      &amp; \\mathbf{A}_{eq}^T\\\\\n  \\mathbf{A}_{eq} &amp; 0\n  \\end{array}\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{z}\\\\\n  \\lambda\n  \\end{array}\n \\right) +\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{B}\\\\\n  -\\mathbf{B}_{eq}\n  \\end{array}\n  \\right)\n  + \\text{constant}</span><script type=\"math/tex\">\\mathop{\\text{find saddle }}_{\\mathbf{z},\\lambda}\\,\n \\frac{1}{2}\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{cc}\n  \\mathbf{Q}      & \\mathbf{A}_{eq}^T\\\\\n  \\mathbf{A}_{eq} & 0\n  \\end{array}\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{z}\\\\\n  \\lambda\n  \\end{array}\n \\right) +\n \\left(\n  \\mathbf{z}^T\n  \\lambda^T\n \\right)\n \\left(\n  \\begin{array}{c}\n  \\mathbf{B}\\\\\n  -\\mathbf{B}_{eq}\n  \\end{array}\n  \\right)\n  + \\text{constant}  Differentiating with respect to  \\left( \\mathbf{z}^T \\lambda^T \\right) \\left( \\mathbf{z}^T \\lambda^T \\right)  reveals\na linear system and we can solve for  \\mathbf{z} \\mathbf{z}  and  \\lambda \\lambda . The only\ndifference from the straight quadratic  minimization  system, is that this\nsaddle problem system will not be positive definite. Thus, we must use a\ndifferent factorization technique (LDLT rather than LLT): libigl's min_quad_with_fixed_precompute  automatically chooses the correct solver in\nthe presence of linear equality constraints ( Example 304 ).",
            "title": "Linear equality constraints"
        },
        {
            "location": "/tutorial/chapter-3/#quadratic-programming",
            "text": "We can generalize the quadratic optimization in the previous section even more\nby allowing inequality constraints. Specifically box constraints (lower and\nupper bounds):  \\mathbf{l} \\le \\mathbf{z} \\le \\mathbf{u}, \\mathbf{l} \\le \\mathbf{z} \\le \\mathbf{u},  where  \\mathbf{l},\\mathbf{u} \\mathbf{l},\\mathbf{u}  are  n \\times 1 n \\times 1  vectors of lower and upper\nbounds\nand general linear inequality constraints:  \\mathbf{A}_{ieq} \\mathbf{z} \\le \\mathbf{B}_{ieq}, \\mathbf{A}_{ieq} \\mathbf{z} \\le \\mathbf{B}_{ieq},  where  \\mathbf{A}_{ieq} \\mathbf{A}_{ieq}  is a  k \\times n k \\times n  matrix of linear coefficients and \\mathbf{B}_{ieq} \\mathbf{B}_{ieq}  is a  k \\times 1 k \\times 1  matrix of constraint right-hand sides.  Again, we are overly general as the box constraints could be written as\nrows of the linear inequality constraints, but bounds appear frequently enough\nto merit a dedicated api.  Libigl implements its own active set routine for solving  quadratric programs \n(QPs). This algorithm works by iteratively \"activating\" violated inequality\nconstraints by enforcing them as equalities and \"deactivating\" constraints\nwhich are no longer needed.  After deciding which constraints are active at each iteration, the problem\nreduces to a quadratic minimization subject to linear  equality  constraints,\nand the method from the previous section is invoked. This is repeated until convergence.  Currently the implementation is efficient for box constraints and sparse\nnon-overlapping linear inequality constraints.  Unlike alternative interior-point methods, the active set method benefits from\na warm-start (initial guess for the solution vector  \\mathbf{z} \\mathbf{z} ).  igl :: active_set_params   as ;  // Z is optional initial guess and output  igl :: active_set ( Q , B , b , bc , Aeq , Beq , Aieq , Bieq , lx , ux , as , Z );",
            "title": "Quadratic programming"
        },
        {
            "location": "/tutorial/chapter-3/#eigen-decomposition",
            "text": "Libigl has rudimentary support for extracting eigen pairs of a generalized\neigen value problem:  Ax = \\lambda B x Ax = \\lambda B x  where  A A  is a sparse symmetric matrix and  B B  is a sparse positive definite\nmatrix. Most commonly in geometry processing, we let  A=L A=L  the cotangent\nLaplacian and  B=M B=M  the per-vertex mass matrix (e.g. [#vallet_2008][]).\nTypically applications will make use of the  low frequency  eigen modes.\nAnalogous to the Fourier decomposition, a function  f f  on a surface can be\nrepresented via its spectral decomposition of the eigen modes of the\nLaplace-Beltrami:  f = \\sum\\limits_{i=1}^\\infty a_i \\phi_i f = \\sum\\limits_{i=1}^\\infty a_i \\phi_i  where each  \\phi_i \\phi_i  is an eigen function satisfying:  \\Delta \\phi_i = \\lambda_i\n\\phi_i \\Delta \\phi_i = \\lambda_i\n\\phi_i  and  a_i a_i  are scalar coefficients. For a discrete triangle mesh, a\ncompletely analogous decomposition exists, albeit with finite sum:  \\mathbf{f} = \\sum\\limits_{i=1}^n a_i \\phi_i \\mathbf{f} = \\sum\\limits_{i=1}^n a_i \\phi_i  where now a column vector of values at vertices  \\mathbf{f} \\in \\mathcal{R}^n \\mathbf{f} \\in \\mathcal{R}^n \nspecifies a piecewise linear function and  \\phi_i \\in \\mathcal{R}^n \\phi_i \\in \\mathcal{R}^n  is an\neigen vector satisfying:  \\mathbf{L} \\phi_i = \\lambda_i \\mathbf{M} \\phi_i \\mathbf{L} \\phi_i = \\lambda_i \\mathbf{M} \\phi_i .  Note that Vallet & Levy [#vallet_2008][] propose solving a symmetrized standard  eigen problem  \\mathbf{M}^{-1/2}\\mathbf{L}\\mathbf{M}^{-1/2} \\phi_i\n= \\lambda_i \\phi_i \\mathbf{M}^{-1/2}\\mathbf{L}\\mathbf{M}^{-1/2} \\phi_i\n= \\lambda_i \\phi_i . Libigl implements a generalized eigen problem solver so\nthis unnecessary symmetrization can be avoided.  Often the sum above is  truncated  to the first  k k  eigen vectors. If the low\nfrequency modes are chosen, i.e. those corresponding to small  \\lambda_i \\lambda_i \nvalues, then this truncation effectively  regularizes   \\mathbf{f} \\mathbf{f}  to smooth,\nslowly changing functions over the mesh (e.g. [#hildebrandt_2011][]). Modal\nanalysis and model subspaces have been used frequently in real-time deformation\n(e.g. [#barbic_2005][]).  In  Example 306 ), the first 5 eigen vectors\nof the discrete Laplace-Beltrami operator are computed and displayed in\npseudo-color atop the beetle. Eigen vectors are computed using  igl::eigs \n(mirroring MATLAB's  eigs ). The 5 eigen vectors are placed into the columns\nof  U  and the eigen values are placed into the entries of  S :  SparseMatrix < double >   L , M ;  igl :: cotmatrix ( V , F , L );  igl :: massmatrix ( V , F , igl :: MASSMATRIX_TYPE_DEFAULT , M );  Eigen :: MatrixXd   U ;  Eigen :: VectorXd   S ;  igl :: eigs ( L , M , 5 , igl :: EIGS_TYPE_SM , U , S );",
            "title": "Eigen Decomposition"
        },
        {
            "location": "/tutorial/chapter-4/",
            "text": "Chapter 4: Shape deformation\n\u00b6\n\n\nModern mesh-based shape deformation methods satisfy user deformation\nconstraints at handles (selected vertices or regions on the mesh) and propagate\nthese handle deformations to the rest of shape \nsmoothly\n and \nwithout removing\nor distorting details\n. Libigl provides implementations of a variety of\nstate-of-the-art deformation techniques, ranging from quadratic mesh-based\nenergy minimizers, to skinning methods, to non-linear elasticity-inspired\ntechniques.\n\n\nBiharmonic deformation\n\u00b6\n\n\nThe period of research between 2000 and 2010 produced a collection of\ntechniques that cast the problem of handle-based shape deformation as a\nquadratic energy minimization problem or equivalently the solution to a linear\npartial differential equation.\n\n\nThere are many flavors of these techniques, but a prototypical subset are those\nthat consider solutions to the bi-Laplace equation, that is a biharmonic\nfunction [#botsch_2004][]. This fourth-order PDE provides sufficient\nflexibility in boundary conditions to ensure \nC^1\nC^1\n continuity at handle\nconstraints (in the limit under refinement) [#jacobson_mixed_2010][].\n\n\nBiharmonic surfaces\n\u00b6\n\n\nLet us first begin our discussion of biharmonic \ndeformation\n, by considering\nbiharmonic \nsurfaces\n. We will casually define biharmonic surfaces as surface\nwhose \nposition functions\n are biharmonic with respect to some initial\nparameterization:\n\n\n\\Delta^2 \\mathbf{x}' = 0\n\\Delta^2 \\mathbf{x}' = 0\n\n\nand subject to some handle constraints, conceptualized as \"boundary\nconditions\":\n\n\n\\mathbf{x}'_{b} = \\mathbf{x}_{bc}.\n\\mathbf{x}'_{b} = \\mathbf{x}_{bc}.\n\n\nwhere \n\\mathbf{x}'\n\\mathbf{x}'\n is the unknown 3D position of a point on the surface. So we\nare asking that the bi-Laplacian of each of spatial coordinate function to be\nzero.\n\n\nIn libigl, one can solve a biharmonic problem with \nigl::harmonic\n\nand setting \nk=2\nk=2\n (\nbi\n-harmonic):\n\n\n// U_bc contains deformation of boundary vertices b\n\n\nigl\n::\nharmonic\n(\nV\n,\nF\n,\nb\n,\nU_bc\n,\n2\n,\nU\n);\n\n\n\n\n\nThis produces a smooth surface that interpolates the handle constraints, but all\noriginal details on the surface will be \nsmoothed away\n. Most obviously, if the\noriginal surface is not already biharmonic, then giving all handles the\nidentity deformation (keeping them at their rest positions) will \nnot\n\nreproduce the original surface. Rather, the result will be the biharmonic\nsurface that does interpolate those handle positions.\n\n\nThus, we may conclude that this is not an intuitive technique for shape\ndeformation.\n\n\nBiharmonic deformation fields\n\u00b6\n\n\nNow we know that one useful property for a deformation technique is \"rest pose\nreproduction\": applying no deformation to the handles should apply no\ndeformation to the shape.\n\n\nTo guarantee this by construction we can work with \ndeformation fields\n (ie.\ndisplacements)\n\n\\mathbf{d}\n\\mathbf{d}\n rather\nthan directly with positions \n\\mathbf{x}\n\\mathbf{x}\n. Then the deformed positions can be\nrecovered as\n\n\n\\mathbf{x}' = \\mathbf{x}+\\mathbf{d}.\n\\mathbf{x}' = \\mathbf{x}+\\mathbf{d}.\n\n\nA smooth deformation field \n\\mathbf{d}\n\\mathbf{d}\n which interpolates the deformation\nfields of the handle constraints will impose a smooth deformed shape\n\n\\mathbf{x}'\n\\mathbf{x}'\n. Naturally, we consider \nbiharmonic deformation fields\n:\n\n\n\\Delta^2 \\mathbf{d} = 0\n\\Delta^2 \\mathbf{d} = 0\n\n\nsubject to the same handle constraints, but rewritten in terms of their implied\ndeformation field at the boundary (handles):\n\n\n\\mathbf{d}_b = \\mathbf{x}_{bc} - \\mathbf{x}_b.\n\\mathbf{d}_b = \\mathbf{x}_{bc} - \\mathbf{x}_b.\n\n\nAgain we can use \nigl::harmonic\n with \nk=2\nk=2\n, but this time solve for the\ndeformation field and then recover the deformed positions:\n\n\n// U_bc contains deformation of boundary vertices b\n\n\nD_bc\n \n=\n \nU_bc\n \n-\n \nigl\n::\nslice\n(\nV\n,\nb\n,\n1\n);\n\n\nigl\n::\nharmonic\n(\nV\n,\nF\n,\nb\n,\nD_bc\n,\n2\n,\nD\n);\n\n\nU\n \n=\n \nV\n+\nD\n;\n\n\n\n\n\n\n\nRelationship to \"differential coordinates\" and Laplacian surface editing\n\u00b6\n\n\nBiharmonic functions (whether positions or displacements) are solutions to the\nbi-Laplace equation, but also minimizers of the \"Laplacian energy\". For\nexample, for displacements \n\\mathbf{d}\n\\mathbf{d}\n, the energy reads\n\n\n\\int\\limits_S \\|\\Delta \\mathbf{d}\\|^2 dA,\n\\int\\limits_S \\|\\Delta \\mathbf{d}\\|^2 dA,\n\n\nwhere we define \n\\Delta \\mathbf{d}\n\\Delta \\mathbf{d}\n to simply apply the Laplacian\ncoordinate-wise.\n\n\nBy linearity of the Laplace(-Beltrami) operator we can reexpress this energy in\nterms of the original positions \n\\mathbf{x}\n\\mathbf{x}\n and the unknown positions\n\n\\mathbf{x}' = \\mathbf{x} - \\mathbf{d}\n\\mathbf{x}' = \\mathbf{x} - \\mathbf{d}\n:\n\n\n\\int\\limits_S \\|\\Delta (\\mathbf{x}' - \\mathbf{x})\\|^2 dA = \\int\\limits_S\n \\|\\Delta \\mathbf{x}' - \\Delta \\mathbf{x})\\|^2 dA.\n\\int\\limits_S \\|\\Delta (\\mathbf{x}' - \\mathbf{x})\\|^2 dA = \\int\\limits_S\n \\|\\Delta \\mathbf{x}' - \\Delta \\mathbf{x})\\|^2 dA.\n\n\nIn the early work of Sorkine et al., the quantities \n\\Delta \\mathbf{x}'\n\\Delta \\mathbf{x}'\n and\n\n\\Delta \\mathbf{x}\n\\Delta \\mathbf{x}\n were dubbed \"differential coordinates\" [#sorkine_2004][].\nTheir deformations (without linearized rotations) is thus equivalent to\nbiharmonic deformation fields.\n\n\nPolyharmonic deformation\n\u00b6\n\n\nWe can generalize biharmonic deformation by considering different powers of\nthe Laplacian, resulting in a series of PDEs of the form:\n\n\n\\Delta^k \\mathbf{d} = 0.\n\\Delta^k \\mathbf{d} = 0.\n\n\nwith \nk\\in{1,2,3,\\dots}\nk\\in{1,2,3,\\dots}\n. The choice of \nk\nk\n determines the level of continuity\nat the handles. In particular, \nk=1\nk=1\n implies \nC^0\nC^0\n at the boundary, \nk=2\nk=2\n\nimplies \nC^1\nC^1\n, \nk=3\nk=3\n implies \nC^2\nC^2\n and in general \nk\nk\n implies \nC^{k-1}\nC^{k-1}\n.\n\n\nint\n \nk\n \n=\n \n2\n;\n// or 1,3,4,...\n\n\nigl\n::\nharmonic\n(\nV\n,\nF\n,\nb\n,\nbc\n,\nk\n,\nZ\n);\n\n\n\n\n\n\n\nBounded biharmonic weights\n\u00b6\n\n\nIn computer animation, shape deformation is often referred to as \"skinning\".\nConstraints are posed as relative rotations of internal rigid \"bones\" inside a\ncharacter. The deformation method, or skinning method, determines how the\nsurface of the character (i.e. its skin) should move as a function of the bone\nrotations.\n\n\nThe most popular technique is linear blend skinning. Each point on the shape\ncomputes its new location as a linear combination of bone transformations:\n\n\n\\mathbf{x}' = \\sum\\limits_{i = 1}^m w_i(\\mathbf{x}) \\mathbf{T}_i\n \\left(\\begin{array}{c}\\mathbf{x}_i\\\\1\\end{array}\\right),\n\\mathbf{x}' = \\sum\\limits_{i = 1}^m w_i(\\mathbf{x}) \\mathbf{T}_i\n \\left(\\begin{array}{c}\\mathbf{x}_i\\\\1\\end{array}\\right),\n\n\nwhere \nw_i(\\mathbf{x})\nw_i(\\mathbf{x})\n is the scalar \nweight function\n of the ith bone evaluated at\n\n\\mathbf{x}\n\\mathbf{x}\n and \n\\mathbf{T}_i\n\\mathbf{T}_i\n is the bone transformation as a \n4 \\times 3\n4 \\times 3\n\nmatrix.\n\n\nThis formula is embarassingly parallel (computation at one point does not\ndepend on shared data need by computation at another point). It is often\nimplemented as a vertex shader. The weights and rest positions for each vertex\nare sent as vertex shader \nattributes\n and bone transformations are sent as\n\nuniforms\n. Then vertices are transformed within the vertex shader, just in\ntime for rendering.\n\n\nAs the skinning formula is linear (hence its name), we can write it as matrix\nmultiplication:\n\n\n\\mathbf{X}' = \\mathbf{M} \\mathbf{T},\n\\mathbf{X}' = \\mathbf{M} \\mathbf{T},\n\n\nwhere \n\\mathbf{X}'\n\\mathbf{X}'\n is \nn \\times 3\nn \\times 3\n stack of deformed positions as row\nvectors, \n\\mathbf{M}\n\\mathbf{M}\n is a \nn \\times m\\cdot dim\nn \\times m\\cdot dim\n matrix containing weights and\nrest positions and \n\\mathbf{T}\n\\mathbf{T}\n is a \nm\\cdot (dim+1) \\times dim\nm\\cdot (dim+1) \\times dim\n stack of\ntransposed bone transformations.\n\n\nTraditionally, the weight functions \nw_j\nw_j\n are painted manually by skilled\nrigging professionals. Modern techniques now exist to compute weight functions\nautomatically given the shape and a description of the skeleton (or in general\nany handle structure such as a cage, collection of points, selected regions,\netc.).\n\n\nBounded biharmonic weights are one such technique that casts weight computation\nas a constrained optimization problem [#jacobson_2011][]. The weights enforce\nsmoothness by minimizing the familiar Laplacian energy:\n\n\n\\sum\\limits_{i = 1}^m \\int_S (\\Delta w_i)^2 dA\n\\sum\\limits_{i = 1}^m \\int_S (\\Delta w_i)^2 dA\n\n\nsubject to constraints which enforce interpolation of handle constraints:\n\n\nw_i(\\mathbf{x}) = \\begin{cases} 1 & \\text{ if } \\mathbf{x} \\in H_i\\\\ 0 &\n \\text{ otherwise } \\end{cases},\nw_i(\\mathbf{x}) = \\begin{cases} 1 & \\text{ if } \\mathbf{x} \\in H_i\\\\ 0 &\n \\text{ otherwise } \\end{cases},\n\n\nwhere \nH_i\nH_i\n is the ith handle, and constraints which enforce non-negativity,\nparition of unity and encourage sparsity:\n\n\n0\\le w_i \\le 1\n0\\le w_i \\le 1\n and \n\\sum\\limits_{i=1}^m w_i = 1.\n\\sum\\limits_{i=1}^m w_i = 1.\n\n\nThis is a quadratic programming problem and libigl solves it using its active\nset solver or by calling out to \nMosek\n.\n\n\n\n\nDual quaternion skinning\n\u00b6\n\n\nEven with high quality weights, linear blend skinning is limited. In\nparticular, it suffers from known artifacts stemming from blending rotations as\nas matrices: a weight combination of rotation matrices is not necessarily a\nrotation. Consider an equal blend between rotating by \n-\\pi/2\n-\\pi/2\n and by \n\\pi/2\n\\pi/2\n\nabout the \nz\nz\n-axis. Intuitively one might expect to get the identity matrix,\nbut instead the blend is a degenerate matrix scaling the \nx\nx\n and \ny\ny\n\ncoordinates by zero:\n\n\n0.5\\left(\\begin{array}{ccc}0&-1&0\\\\1&0&0\\\\0&0&1\\end{array}\\right)+\n 0.5\\left(\\begin{array}{ccc}0&1&0\\\\-1&0&0\\\\0&0&1\\end{array}\\right)=\n \\left(\\begin{array}{ccc}0&0&0\\\\0&0&0\\\\0&0&1\\end{array}\\right)\n0.5\\left(\\begin{array}{ccc}0&-1&0\\\\1&0&0\\\\0&0&1\\end{array}\\right)+\n 0.5\\left(\\begin{array}{ccc}0&1&0\\\\-1&0&0\\\\0&0&1\\end{array}\\right)=\n \\left(\\begin{array}{ccc}0&0&0\\\\0&0&0\\\\0&0&1\\end{array}\\right)\n\n\nIn practice, this means the shape shrinks and collapses in regions where bone\nweights overlap: near joints.\n\n\nDual quaternion skinning presents a solution [#kavan_2008]. This method\nrepresents rigid transformations as a pair of unit quaternions,\n\n\\hat{\\mathbf{q}}\n\\hat{\\mathbf{q}}\n. The linear blend skinning formula is replaced with a\nlinear blend of dual quaternions:\n\n\n\\mathbf{x}' =\n \\cfrac{\\sum\\limits_{i=1}^m w_i(\\mathbf{x})\\hat{\\mathbf{q}_i}}\n {\\left\\|\\sum\\limits_{i=1}^m w_i(\\mathbf{x})\\hat{\\mathbf{q}_i}\\right\\|}\n \\mathbf{x},\n\\mathbf{x}' =\n \\cfrac{\\sum\\limits_{i=1}^m w_i(\\mathbf{x})\\hat{\\mathbf{q}_i}}\n {\\left\\|\\sum\\limits_{i=1}^m w_i(\\mathbf{x})\\hat{\\mathbf{q}_i}\\right\\|}\n \\mathbf{x},\n\n\nwhere \n\\hat{\\mathbf{q}_i}\n\\hat{\\mathbf{q}_i}\n is the dual quaternion representation of the rigid\ntransformation of bone \ni\ni\n. The normalization forces the result of the linear\nblending to again be a unit dual quaternion and thus also a rigid\ntransformation.\n\n\nLike linear blend skinning, dual quaternion skinning is best performed in the\nvertex shader. The only difference being that bone transformations are sent as\ndual quaternions rather than affine transformation matrices.  Libigl supports\nCPU-side dual quaternion skinning with the \nigl::dqs\n function, which takes a\nmore traditional representation of rigid transformations as input and\ninternally converts to the dual quaternion representation before blending:\n\n\n// vQ is a list of rotations as quaternions\n\n\n// vT is a list of translations\n\n\nigl\n::\ndqs\n(\nV\n,\nW\n,\nvQ\n,\nvT\n,\nU\n);\n\n\n\n\n\n\n\nAs-rigid-as-possible\n\u00b6\n\n\nSkinning and other linear methods for deformation are inherently limited.\nDifficult arises especially when large rotations are imposed by the handle\nconstraints.\n\n\nIn the context of energy-minimization approaches, the problem stems from\ncomparing positions (our displacements) in the coordinate frame of the\nundeformed shape. These quadratic energies are at best invariant to global\nrotations of the entire shape, but not smoothly varying local rotations. Thus\nlinear techniques will not produce non-trivial bending and twisting.\n\n\nFurthermore, when considering solid shapes (e.g. discretized with tetrahedral\nmeshes) linear methods struggle to maintain local volume, and they often suffer from\nshrinking and bulging artifacts.\n\n\nNon-linear deformation techniques present a solution to these problems.\nThey work by comparing the deformation of a mesh\nvertex to its rest position \nrotated\n to a new coordinate frame which best\nmatches the deformation. The non-linearity stems from the mutual dependence of\nthe deformation and the best-fit rotation. These techniques are often labeled\n\"as-rigid-as-possible\" as they penalize the sum of all local deformations'\ndeviations from rotations.\n\n\nTo arrive at such an energy, let's consider a simple per-triangle energy:\n\n\nE_\\text{linear}(\\mathbf{X}') = \\sum\\limits_{t \\in T} a_t \\sum\\limits_{\\{i,j\\}\n \\in t} w_{ij} \\left\\|\n \\left(\\mathbf{x}'_i - \\mathbf{x}'_j\\right) -\n \\left(\\mathbf{x}_i - \\mathbf{x}_j\\right)\\right\\|^2\nE_\\text{linear}(\\mathbf{X}') = \\sum\\limits_{t \\in T} a_t \\sum\\limits_{\\{i,j\\}\n \\in t} w_{ij} \\left\\|\n \\left(\\mathbf{x}'_i - \\mathbf{x}'_j\\right) -\n \\left(\\mathbf{x}_i - \\mathbf{x}_j\\right)\\right\\|^2\n\n\nwhere \n\\mathbf{X}'\n\\mathbf{X}'\n are the mesh's unknown deformed vertex positions, \nt\nt\n is a\ntriangle in a list of triangles \nT\nT\n, \na_t\na_t\n is the area of triangle \nt\nt\n and\n\n\\{i,j\\}\n\\{i,j\\}\n is an edge in triangle \nt\nt\n. Thus, this energy measures the norm of\nchange between an edge vector in the original mesh \n\\left(\\mathbf{x}_i -\n\\mathbf{x}_j\\right)\n\\left(\\mathbf{x}_i -\n\\mathbf{x}_j\\right)\n and the unknown mesh \n\\left(\\mathbf{x}'_i -\n\\mathbf{x}'_j\\right)\n\\left(\\mathbf{x}'_i -\n\\mathbf{x}'_j\\right)\n.\n\n\nThis energy is \nnot\n rotation invariant. If we rotate the mesh by 90 degrees\nthe change in edge vectors not aligned with the axis of rotation will be large,\ndespite the overall deformation being perfectly rigid.\n\n\nSo, the \"as-rigid-as-possible\" solution is to append auxiliary variables\n\n\\mathbf{R}_t\n\\mathbf{R}_t\n\nfor each triangle \nt\nt\n which are constrained to be rotations. Then the energy is\nrewritten, this time comparing deformed edge vectors to their rotated rest\ncounterparts:\n\n\nE_\\text{arap}(\\mathbf{X}',\\{\\mathbf{R}_1,\\dots,\\mathbf{R}_{|T|}\\}) = \\sum\\limits_{t \\in T} a_t \\sum\\limits_{\\{i,j\\}\n \\in t} w_{ij} \\left\\|\n \\left(\\mathbf{x}'_i - \\mathbf{x}'_j\\right)-\n \\mathbf{R}_t\\left(\\mathbf{x}_i - \\mathbf{x}_j\\right)\\right\\|^2.\nE_\\text{arap}(\\mathbf{X}',\\{\\mathbf{R}_1,\\dots,\\mathbf{R}_{|T|}\\}) = \\sum\\limits_{t \\in T} a_t \\sum\\limits_{\\{i,j\\}\n \\in t} w_{ij} \\left\\|\n \\left(\\mathbf{x}'_i - \\mathbf{x}'_j\\right)-\n \\mathbf{R}_t\\left(\\mathbf{x}_i - \\mathbf{x}_j\\right)\\right\\|^2.\n\n\nThe separation into the primary vertex position variables \n\\mathbf{X}'\n\\mathbf{X}'\n and the\nrotations \n\\{\\mathbf{R}_1,\\dots,\\mathbf{R}_{|T|}\\}\n\\{\\mathbf{R}_1,\\dots,\\mathbf{R}_{|T|}\\}\n lead to strategy for\noptimization, too. If the rotations \n\\{\\mathbf{R}_1,\\dots,\\mathbf{R}_{|T|}\\}\n\\{\\mathbf{R}_1,\\dots,\\mathbf{R}_{|T|}\\}\n\nare held fixed then the energy is quadratic in the remaining variables\n\n\\mathbf{X}'\n\\mathbf{X}'\n and can be optimized by solving a (sparse) global linear system.\nAlternatively, if \n\\mathbf{X}'\n\\mathbf{X}'\n are held fixed then each rotation is the\nsolution to a localized \nProcrustes\n problem (found via \n3 \\times 3\n3 \\times 3\n SVD or\npolar decompostion). These two steps---local and global---each weakly decrease\nthe energy, thus we may safely iterate them until convergence.\n\n\nThe different flavors of \"as-rigid-as-possible\" depend on the dimension and\ncodimension of the domain and the edge-sets \nT\nT\n. The proposed surface\nmanipulation technique by Sorkine and Alexa [#sorkine_2007][], considers \nT\nT\n to\nbe the set of sets of edges emanating from each vertex (spokes). Later, Chao et\nal.  derived the relationship between \"as-rigid-as-possible\" mesh energies and\nco-rotational elasticity considering 0-codimension elements as edge-sets:\ntriangles in 2D and tetrahedra in 3D [#chao_2010][]. They also showed how\nSorkine and Alexa's edge-sets are not a discretization of a continuous energy,\nproposing instead edge-sets for surfaces containing all edges of elements\nincident on a vertex (spokes and rims). They show that this amounts to\nmeasuring bending, albeit in a discretization-dependent way.\n\n\nLibigl, supports these common flavors. Selecting one is a matter of setting the\nenergy type before the precompuation phase:\n\n\nigl\n::\nARAPData\n \narap_data\n;\n\n\narap_data\n.\nenergy\n \n=\n \nigl\n::\nARAP_ENERGY_TYPE_SPOKES\n;\n\n\n//arap_data.energy = igl::ARAP_ENERGY_TYPE_SPOKES_AND_RIMS;\n\n\n//arap_data.energy = igl::ARAP_ENERGY_TYPE_ELEMENTS; //triangles or tets\n\n\nigl\n::\narap_precomputation\n(\nV\n,\nF\n,\ndim\n,\nb\n,\narap_data\n);\n\n\n\n\n\nJust like \nigl::min_quad_with_fixed_*\n, this precomputation phase only depends\non the mesh, fixed vertex indices \nb\n and the energy parameters. To solve with\ncertain constraints on the positions of vertices in \nb\n, we may call:\n\n\nigl\n::\narap_solve\n(\nbc\n,\narap_data\n,\nU\n);\n\n\n\n\n\nwhich uses \nU\n as an initial guess and then computes the solution into it.\n\n\nLibigl's implementation of as-rigid-as-possible deformation takes advantage of\nthe highly optimized singular value decomposition code from McAdams et al.\n[#mcadams_2011][] which leverages SSE intrinsics.\n\n\n\n\nThe concept of local rigidity will be revisited shortly in the context of\nsurface parameterization.\n\n\nFast automatic skinning transformations\n\u00b6\n\n\nNon-linear optimization is, unsurprisingly, slower than its linear cousins. In\nthe case of the as-rigid-as-possible optimization, the bottleneck is typically\nthe large number of polar decompositions necessary to recover best fit\nrotations for each edge-set (i.e. for each triangle, tetrahedron, or vertex\ncell). Even if this code is optimized, the number of primary degrees of freedom\nis tied to the discretization level, despite the deformations' low frequency\nbehavior.\n\n\nThis invites two routes toward fast non-linear optimization. First, is it\nnecessary (or even advantageous) to find so many best-fit rotations? Second,\ncan we reduce the degrees of freedom to better reflect the frequency of the\ndesired deformations.\n\n\nTaken in turn, these optimizations culminate in a method which optimizes over\nthe space of linear blend skinning deformations spanned by high-quality weights\n(i.e. manually painted ones or bounded biharmonic weights). This space is a\nlow-dimensional subspace of all possible mesh deformations, captured by writing\nlinear blend skinning in matrix form:\n\n\n\\mathbf{X}' = \\mathbf{M}\\mathbf{T}\n\\mathbf{X}' = \\mathbf{M}\\mathbf{T}\n\n\nwhere the mesh vertex positions in the \nn \\times 3\nn \\times 3\n matrix \n\\mathbf{X}'\n\\mathbf{X}'\n are\nreplaced by a linear combination of a small number of degrees of freedom in the\n\n(3+1)m \\times 3\n(3+1)m \\times 3\n stack of transposed \"handle\" transformations. Swapping in\n\n\\mathbf{M}\\mathbf{T}\n\\mathbf{M}\\mathbf{T}\n for \n\\mathbf{X}'\n\\mathbf{X}'\n in the ARAP energies above immediately\nsees performance gains during the global solve step as \nm << n\nm << n\n.\n\n\nThe complexity of the local step---fitting rotations---is still bound\nto the original mesh discretization. However, if the skinning is well behaved,\nwe can make the assumption that places on the shape with similar skinning\nweights will deform similarly and thus imply similar best-fit rotations.\nTherefore, we cluster edge-sets according to their representation in\n\nweight-space\n: where a vertex \n\\mathbf{x}\n\\mathbf{x}\n takes the coordinates\n\n[w_1(\\mathbf{x}),w_2(\\mathbf{x}),\\dots,w_m(\\mathbf{x})]\n[w_1(\\mathbf{x}),w_2(\\mathbf{x}),\\dots,w_m(\\mathbf{x})]\n. The number of\nclustered edge-sets show diminishing returns on the deformation quality so we\nmay choose a small number of clusters, proportional to the number of skinning\nweight functions (rather than the number of discrete mesh vertices).\n\n\nThis proposed deformation model [#jacobson_2012][], can simultaneously be seen as a\nfast, subspace optimization for ARAP and as an automatic method for finding\n\nthe best\n skinning transformation degrees of freedom.\n\n\nA variety of user interfaces are supported via linear equality constraints on\nthe skinning transformations associated with handles. To fix a transformation\nentirely we simply add the constraint:\n\n\n\\left(\\begin{array}{cccc}\n 1 & 0 & 0 & 0\\\\\n 0 & 1 & 0 & 0\\\\\n 0 & 0 & 1 & 0\\\\\n 0 & 0 & 0 & 1\\end{array}\\right)\n \\mathbf{T}_i^T = \\hat{\\mathbf{T}}_i^T,\n\\left(\\begin{array}{cccc}\n 1 & 0 & 0 & 0\\\\\n 0 & 1 & 0 & 0\\\\\n 0 & 0 & 1 & 0\\\\\n 0 & 0 & 0 & 1\\end{array}\\right)\n \\mathbf{T}_i^T = \\hat{\\mathbf{T}}_i^T,\n\n\nwhere \n\\hat{\\mathbf{T}}_i^T\n\\hat{\\mathbf{T}}_i^T\n is the \n(3+1) \\times 3\n(3+1) \\times 3\n transposed fixed\ntransformation for handle \ni\ni\n.\n\n\nTo fix only the origin of a handle, we add a constraint requiring the\ntransformation to interpolate a point in space (typically the centroid of all\npoints with \nw_i = 1\nw_i = 1\n:\n\n\n\\mathbf{c}'^T\\mathbf{T}_i^T = \\mathbf{c}^T,\n\\mathbf{c}'^T\\mathbf{T}_i^T = \\mathbf{c}^T,\n\n\nwhere \n\\mathbf{c}^T\n\\mathbf{c}^T\n is the \n1 \\times (3+1)\n1 \\times (3+1)\n position of the point at rest in\ntransposed homogeneous coordinates, and \n\\mathbf{c}'^T\n\\mathbf{c}'^T\n the point given by the\nuser.\n\n\nWe can similarly fix just the linear part of the transformation at a handle,\nfreeing the translation component (producing a \"chickenhead\" effect):\n\n\n\\left(\\begin{array}{cccc}\n 1&0&0&0\\\\\n 0&1&0&0\\\\\n 0&0&1&0\\end{array}\\right)\n \\mathbf{T}_i^T = \\hat{\\mathbf{L}}_i^T,\n\\left(\\begin{array}{cccc}\n 1&0&0&0\\\\\n 0&1&0&0\\\\\n 0&0&1&0\\end{array}\\right)\n \\mathbf{T}_i^T = \\hat{\\mathbf{L}}_i^T,\n\n\nwhere \n\\hat{\\mathbf{L}}_i^T\n\\hat{\\mathbf{L}}_i^T\n is the fixed \n3 \\times 3\n3 \\times 3\n linear part of the\ntransformation at handle \ni\ni\n.\n\n\nAnd lastly we can allow the user to entirely \nfree\n the transformation's\ndegrees of freedom, delegating the optimization to find the best possible\nvalues for all elements. To do this, we simply abstain from adding a\ncorresponding constraint.\n\n\nARAP with grouped edge-sets\n\u00b6\n\n\nBeing a subspace method, an immediate disadvantage is the reduced degrees of\nfreedom. This brings performance, but in some situations limits behavior too\nmuch. In such cases one can use the skinning subspace to build an effective\nclustering of rotation edge-sets for a traditional ARAP optimization: forgoing\nthe subspace substitution. This has an two-fold effect. The cost of the\nrotation fitting, local step drastically reduces, and the deformations are\n\"regularized\" according the clusters. From a high level point of view, if the\nclusters are derived from skinning weights, then they will discourage bending,\nespecially along isolines of the weight functions. If handles are not known in\nadvance, one could also cluster according to a \"geodesic embedding\" like the\nbiharmonic distance embedding.\n\n\nIn this light, we can think of the \"spokes+rims\" style surface ARAP as a (slight and\nredundant) clustering of the per-triangle edge-sets.\n\n\n\n\nBiharmonic Coordinates\n\u00b6\n\n\nLinear blend skinning (as \nabove\n) deforms a mesh by\npropagating \nfull affine transformations\n at handles (bones, points, regions,\netc.) to the rest of the shape via weights. Another deformation framework,\ncalled \"generalized barycentric coordinates\", is a special case of linear blend\nskinning [#jacobson_skinning_course_2014][]: transformations are restricted to\n\npure translations\n and weights are required to retain \naffine precision\n. This\nlatter requirement means that we can write the rest-position of any vertex in\nthe mesh as the weighted combination of the control handle locations:\n\n\n\\mathbf{x} = \\sum\\limits_{i=1}^m w_i(\\mathbf{x}) * \\mathbf{c}_i,\n\\mathbf{x} = \\sum\\limits_{i=1}^m w_i(\\mathbf{x}) * \\mathbf{c}_i,\n\n\nwhere \n\\mathbf{c}_i\n\\mathbf{c}_i\n is the rest position of the \ni\ni\nth control point. This\nsimplifies the deformation formula at run-time. We can simply take the new\nposition of each point of the shape to be the weighted combination of the\n\ntranslated\n control point positions:\n\n\n\\mathbf{x}' = \\sum\\limits_{i=1}^m w_i(\\mathbf{x}) * \\mathbf{c}_i'.\n\\mathbf{x}' = \\sum\\limits_{i=1}^m w_i(\\mathbf{x}) * \\mathbf{c}_i'.\n\n\nThere are \nmany\n different flavors of \"generalized barycentric coordinates\"\n(see table in \"Automatic Methods\" section,\n[#jacobson_skinning_course_2014][]). The vague goal of \"generalized barycentric\ncoordinates\" is to capture as many properties of simplicial barycentric\ncoordinates (e.g. for triangles in 2D and tetrahedral in 3D) for larger sets of\npoints or polyhedra. Some generalized barycentric coordinates can be computed\nin closed form; others require optimization-based precomputation. Nearly all\nflavors require connectivity information describing how the control points form\na external polyhedron around the input shape: a cage. However, a recent\ntechinique does not require a cage [#wang_bc_2015][]. This method ensures\naffine precision during optimization over weights of a smoothness energy with\naffine functions in its kernel:\n\n\n\\mathop{\\text{min}}_\\mathbf{W}\\,\\, \\text{trace}(\\frac{1}{2}\\mathbf{W}^T \\mathbf{A}\n \\mathbf{W}), \\text{subject to: } \\mathbf{C} = \\mathbf{W}\\mathbf{C}\n\\mathop{\\text{min}}_\\mathbf{W}\\,\\, \\text{trace}(\\frac{1}{2}\\mathbf{W}^T \\mathbf{A}\n \\mathbf{W}), \\text{subject to: } \\mathbf{C} = \\mathbf{W}\\mathbf{C}\n\n\nsubject to interpolation constraints at selected vertices. If \n\\mathbf{A}\n\\mathbf{A}\n has\naffine functions in its kernel---that is, if \n\\mathbf{A}\\mathbf{V} = 0\n\\mathbf{A}\\mathbf{V} = 0\n---then\nthe weights \n\\mathbf{W}\n\\mathbf{W}\n will retain affine precision and we'll have that:\n\n\n\\mathbf{V} = \\mathbf{W}\\mathbf{C}\n\\mathbf{V} = \\mathbf{W}\\mathbf{C}\n\n\nthe matrix form of the equality above. The proposed way to define \n\\mathbf{A}\n\\mathbf{A}\n\nis to construct a matrix \n\\mathbf{K}\n\\mathbf{K}\n that measures the Laplacian at all\ninterior vertices \nand at all boundary vertices\n. The \nusual\n definition of the\ndiscrete Laplacian (e.g. what libigl returns from \nigl::cotmatrix\n), measures\nthe Laplacian of a function for interior vertices, but measures the Laplacian\nof a function \nminus\n the normal derivative of a function for boundary\nvertices. Thus, we can let:\n\n\n\\mathbf{K} = \\mathbf{L} + \\mathbf{N}\n\\mathbf{K} = \\mathbf{L} + \\mathbf{N}\n\n\nwhere \n\\mathbf{L}\n\\mathbf{L}\n is the \nusual\n Laplacian and \n\\mathbf{N}\n\\mathbf{N}\n is matrix that\ncomputes normal derivatives of a piecewise-linear function at boundary vertices\nof a mesh. Then \n\\mathbf{A}\n\\mathbf{A}\n is taken as quadratic form computing the square of\nthe integral-average of \n\\mathbf{K}\n\\mathbf{K}\n applied to a function and integrated over\nthe mesh:\n\n\n\\mathbf{A} = (\\mathbf{M}^{-1}\\mathbf{K})^2_\\mathbf{M} = \\mathbf{K}^T \\mathbf{M}^{-1}\n \\mathbf{K}.\n\\mathbf{A} = (\\mathbf{M}^{-1}\\mathbf{K})^2_\\mathbf{M} = \\mathbf{K}^T \\mathbf{M}^{-1}\n \\mathbf{K}.\n\n\nSince the Laplacian \n\\mathbf{K}\n\\mathbf{K}\n is a second-order derivative it measures zero on affine\nfunctions, thus \n\\mathbf{A}\n\\mathbf{A}\n has affine functions in its null space. A short\nderivation proves that this implies \n\\mathbf{W}\n\\mathbf{W}\n will be affine precise (see\n[#wang_bc_2015][]).\n\n\nMinimizers of this \"squared Laplacian\" energy are in some sense \ndiscrete\nbiharmonic functions\n. Thus they're dubbed \"biharmonic coordinates\" (not the\nsame as \nbounded biharmonic weights\n, which are \nnot\n generalized barycentric\ncoordinates).\n\n\nIn libigl, one can compute biharmonic coordinates given a mesh \n(V,F)\n and a\nlist \nS\n of selected control points or control regions (which act like skinning\nhandles):\n\n\nigl\n::\nbiharmonic_coordinates\n(\nV\n,\nF\n,\nS\n,\nW\n);",
            "title": "Chapter 4: Shape Deformation"
        },
        {
            "location": "/tutorial/chapter-4/#chapter-4-shape-deformation",
            "text": "Modern mesh-based shape deformation methods satisfy user deformation\nconstraints at handles (selected vertices or regions on the mesh) and propagate\nthese handle deformations to the rest of shape  smoothly  and  without removing\nor distorting details . Libigl provides implementations of a variety of\nstate-of-the-art deformation techniques, ranging from quadratic mesh-based\nenergy minimizers, to skinning methods, to non-linear elasticity-inspired\ntechniques.",
            "title": "Chapter 4: Shape deformation"
        },
        {
            "location": "/tutorial/chapter-4/#biharmonic-deformation",
            "text": "The period of research between 2000 and 2010 produced a collection of\ntechniques that cast the problem of handle-based shape deformation as a\nquadratic energy minimization problem or equivalently the solution to a linear\npartial differential equation.  There are many flavors of these techniques, but a prototypical subset are those\nthat consider solutions to the bi-Laplace equation, that is a biharmonic\nfunction [#botsch_2004][]. This fourth-order PDE provides sufficient\nflexibility in boundary conditions to ensure  C^1 C^1  continuity at handle\nconstraints (in the limit under refinement) [#jacobson_mixed_2010][].",
            "title": "Biharmonic deformation"
        },
        {
            "location": "/tutorial/chapter-4/#biharmonic-surfaces",
            "text": "Let us first begin our discussion of biharmonic  deformation , by considering\nbiharmonic  surfaces . We will casually define biharmonic surfaces as surface\nwhose  position functions  are biharmonic with respect to some initial\nparameterization:  \\Delta^2 \\mathbf{x}' = 0 \\Delta^2 \\mathbf{x}' = 0  and subject to some handle constraints, conceptualized as \"boundary\nconditions\":  \\mathbf{x}'_{b} = \\mathbf{x}_{bc}. \\mathbf{x}'_{b} = \\mathbf{x}_{bc}.  where  \\mathbf{x}' \\mathbf{x}'  is the unknown 3D position of a point on the surface. So we\nare asking that the bi-Laplacian of each of spatial coordinate function to be\nzero.  In libigl, one can solve a biharmonic problem with  igl::harmonic \nand setting  k=2 k=2  ( bi -harmonic):  // U_bc contains deformation of boundary vertices b  igl :: harmonic ( V , F , b , U_bc , 2 , U );   This produces a smooth surface that interpolates the handle constraints, but all\noriginal details on the surface will be  smoothed away . Most obviously, if the\noriginal surface is not already biharmonic, then giving all handles the\nidentity deformation (keeping them at their rest positions) will  not \nreproduce the original surface. Rather, the result will be the biharmonic\nsurface that does interpolate those handle positions.  Thus, we may conclude that this is not an intuitive technique for shape\ndeformation.",
            "title": "Biharmonic surfaces"
        },
        {
            "location": "/tutorial/chapter-4/#biharmonic-deformation-fields",
            "text": "Now we know that one useful property for a deformation technique is \"rest pose\nreproduction\": applying no deformation to the handles should apply no\ndeformation to the shape.  To guarantee this by construction we can work with  deformation fields  (ie.\ndisplacements) \\mathbf{d} \\mathbf{d}  rather\nthan directly with positions  \\mathbf{x} \\mathbf{x} . Then the deformed positions can be\nrecovered as  \\mathbf{x}' = \\mathbf{x}+\\mathbf{d}. \\mathbf{x}' = \\mathbf{x}+\\mathbf{d}.  A smooth deformation field  \\mathbf{d} \\mathbf{d}  which interpolates the deformation\nfields of the handle constraints will impose a smooth deformed shape \\mathbf{x}' \\mathbf{x}' . Naturally, we consider  biharmonic deformation fields :  \\Delta^2 \\mathbf{d} = 0 \\Delta^2 \\mathbf{d} = 0  subject to the same handle constraints, but rewritten in terms of their implied\ndeformation field at the boundary (handles):  \\mathbf{d}_b = \\mathbf{x}_{bc} - \\mathbf{x}_b. \\mathbf{d}_b = \\mathbf{x}_{bc} - \\mathbf{x}_b.  Again we can use  igl::harmonic  with  k=2 k=2 , but this time solve for the\ndeformation field and then recover the deformed positions:  // U_bc contains deformation of boundary vertices b  D_bc   =   U_bc   -   igl :: slice ( V , b , 1 );  igl :: harmonic ( V , F , b , D_bc , 2 , D );  U   =   V + D ;",
            "title": "Biharmonic deformation fields"
        },
        {
            "location": "/tutorial/chapter-4/#relationship-to-differential-coordinates-and-laplacian-surface-editing",
            "text": "Biharmonic functions (whether positions or displacements) are solutions to the\nbi-Laplace equation, but also minimizers of the \"Laplacian energy\". For\nexample, for displacements  \\mathbf{d} \\mathbf{d} , the energy reads  \\int\\limits_S \\|\\Delta \\mathbf{d}\\|^2 dA, \\int\\limits_S \\|\\Delta \\mathbf{d}\\|^2 dA,  where we define  \\Delta \\mathbf{d} \\Delta \\mathbf{d}  to simply apply the Laplacian\ncoordinate-wise.  By linearity of the Laplace(-Beltrami) operator we can reexpress this energy in\nterms of the original positions  \\mathbf{x} \\mathbf{x}  and the unknown positions \\mathbf{x}' = \\mathbf{x} - \\mathbf{d} \\mathbf{x}' = \\mathbf{x} - \\mathbf{d} :  \\int\\limits_S \\|\\Delta (\\mathbf{x}' - \\mathbf{x})\\|^2 dA = \\int\\limits_S\n \\|\\Delta \\mathbf{x}' - \\Delta \\mathbf{x})\\|^2 dA. \\int\\limits_S \\|\\Delta (\\mathbf{x}' - \\mathbf{x})\\|^2 dA = \\int\\limits_S\n \\|\\Delta \\mathbf{x}' - \\Delta \\mathbf{x})\\|^2 dA.  In the early work of Sorkine et al., the quantities  \\Delta \\mathbf{x}' \\Delta \\mathbf{x}'  and \\Delta \\mathbf{x} \\Delta \\mathbf{x}  were dubbed \"differential coordinates\" [#sorkine_2004][].\nTheir deformations (without linearized rotations) is thus equivalent to\nbiharmonic deformation fields.",
            "title": "Relationship to \"differential coordinates\" and Laplacian surface editing"
        },
        {
            "location": "/tutorial/chapter-4/#polyharmonic-deformation",
            "text": "We can generalize biharmonic deformation by considering different powers of\nthe Laplacian, resulting in a series of PDEs of the form:  \\Delta^k \\mathbf{d} = 0. \\Delta^k \\mathbf{d} = 0.  with  k\\in{1,2,3,\\dots} k\\in{1,2,3,\\dots} . The choice of  k k  determines the level of continuity\nat the handles. In particular,  k=1 k=1  implies  C^0 C^0  at the boundary,  k=2 k=2 \nimplies  C^1 C^1 ,  k=3 k=3  implies  C^2 C^2  and in general  k k  implies  C^{k-1} C^{k-1} .  int   k   =   2 ; // or 1,3,4,...  igl :: harmonic ( V , F , b , bc , k , Z );",
            "title": "Polyharmonic deformation"
        },
        {
            "location": "/tutorial/chapter-4/#bounded-biharmonic-weights",
            "text": "In computer animation, shape deformation is often referred to as \"skinning\".\nConstraints are posed as relative rotations of internal rigid \"bones\" inside a\ncharacter. The deformation method, or skinning method, determines how the\nsurface of the character (i.e. its skin) should move as a function of the bone\nrotations.  The most popular technique is linear blend skinning. Each point on the shape\ncomputes its new location as a linear combination of bone transformations:  \\mathbf{x}' = \\sum\\limits_{i = 1}^m w_i(\\mathbf{x}) \\mathbf{T}_i\n \\left(\\begin{array}{c}\\mathbf{x}_i\\\\1\\end{array}\\right), \\mathbf{x}' = \\sum\\limits_{i = 1}^m w_i(\\mathbf{x}) \\mathbf{T}_i\n \\left(\\begin{array}{c}\\mathbf{x}_i\\\\1\\end{array}\\right),  where  w_i(\\mathbf{x}) w_i(\\mathbf{x})  is the scalar  weight function  of the ith bone evaluated at \\mathbf{x} \\mathbf{x}  and  \\mathbf{T}_i \\mathbf{T}_i  is the bone transformation as a  4 \\times 3 4 \\times 3 \nmatrix.  This formula is embarassingly parallel (computation at one point does not\ndepend on shared data need by computation at another point). It is often\nimplemented as a vertex shader. The weights and rest positions for each vertex\nare sent as vertex shader  attributes  and bone transformations are sent as uniforms . Then vertices are transformed within the vertex shader, just in\ntime for rendering.  As the skinning formula is linear (hence its name), we can write it as matrix\nmultiplication:  \\mathbf{X}' = \\mathbf{M} \\mathbf{T}, \\mathbf{X}' = \\mathbf{M} \\mathbf{T},  where  \\mathbf{X}' \\mathbf{X}'  is  n \\times 3 n \\times 3  stack of deformed positions as row\nvectors,  \\mathbf{M} \\mathbf{M}  is a  n \\times m\\cdot dim n \\times m\\cdot dim  matrix containing weights and\nrest positions and  \\mathbf{T} \\mathbf{T}  is a  m\\cdot (dim+1) \\times dim m\\cdot (dim+1) \\times dim  stack of\ntransposed bone transformations.  Traditionally, the weight functions  w_j w_j  are painted manually by skilled\nrigging professionals. Modern techniques now exist to compute weight functions\nautomatically given the shape and a description of the skeleton (or in general\nany handle structure such as a cage, collection of points, selected regions,\netc.).  Bounded biharmonic weights are one such technique that casts weight computation\nas a constrained optimization problem [#jacobson_2011][]. The weights enforce\nsmoothness by minimizing the familiar Laplacian energy:  \\sum\\limits_{i = 1}^m \\int_S (\\Delta w_i)^2 dA \\sum\\limits_{i = 1}^m \\int_S (\\Delta w_i)^2 dA  subject to constraints which enforce interpolation of handle constraints:  w_i(\\mathbf{x}) = \\begin{cases} 1 & \\text{ if } \\mathbf{x} \\in H_i\\\\ 0 &\n \\text{ otherwise } \\end{cases}, w_i(\\mathbf{x}) = \\begin{cases} 1 & \\text{ if } \\mathbf{x} \\in H_i\\\\ 0 &\n \\text{ otherwise } \\end{cases},  where  H_i H_i  is the ith handle, and constraints which enforce non-negativity,\nparition of unity and encourage sparsity:  0\\le w_i \\le 1 0\\le w_i \\le 1  and  \\sum\\limits_{i=1}^m w_i = 1. \\sum\\limits_{i=1}^m w_i = 1.  This is a quadratic programming problem and libigl solves it using its active\nset solver or by calling out to  Mosek .",
            "title": "Bounded biharmonic weights"
        },
        {
            "location": "/tutorial/chapter-4/#dual-quaternion-skinning",
            "text": "Even with high quality weights, linear blend skinning is limited. In\nparticular, it suffers from known artifacts stemming from blending rotations as\nas matrices: a weight combination of rotation matrices is not necessarily a\nrotation. Consider an equal blend between rotating by  -\\pi/2 -\\pi/2  and by  \\pi/2 \\pi/2 \nabout the  z z -axis. Intuitively one might expect to get the identity matrix,\nbut instead the blend is a degenerate matrix scaling the  x x  and  y y \ncoordinates by zero:  0.5\\left(\\begin{array}{ccc}0&-1&0\\\\1&0&0\\\\0&0&1\\end{array}\\right)+\n 0.5\\left(\\begin{array}{ccc}0&1&0\\\\-1&0&0\\\\0&0&1\\end{array}\\right)=\n \\left(\\begin{array}{ccc}0&0&0\\\\0&0&0\\\\0&0&1\\end{array}\\right) 0.5\\left(\\begin{array}{ccc}0&-1&0\\\\1&0&0\\\\0&0&1\\end{array}\\right)+\n 0.5\\left(\\begin{array}{ccc}0&1&0\\\\-1&0&0\\\\0&0&1\\end{array}\\right)=\n \\left(\\begin{array}{ccc}0&0&0\\\\0&0&0\\\\0&0&1\\end{array}\\right)  In practice, this means the shape shrinks and collapses in regions where bone\nweights overlap: near joints.  Dual quaternion skinning presents a solution [#kavan_2008]. This method\nrepresents rigid transformations as a pair of unit quaternions, \\hat{\\mathbf{q}} \\hat{\\mathbf{q}} . The linear blend skinning formula is replaced with a\nlinear blend of dual quaternions:  \\mathbf{x}' =\n \\cfrac{\\sum\\limits_{i=1}^m w_i(\\mathbf{x})\\hat{\\mathbf{q}_i}}\n {\\left\\|\\sum\\limits_{i=1}^m w_i(\\mathbf{x})\\hat{\\mathbf{q}_i}\\right\\|}\n \\mathbf{x}, \\mathbf{x}' =\n \\cfrac{\\sum\\limits_{i=1}^m w_i(\\mathbf{x})\\hat{\\mathbf{q}_i}}\n {\\left\\|\\sum\\limits_{i=1}^m w_i(\\mathbf{x})\\hat{\\mathbf{q}_i}\\right\\|}\n \\mathbf{x},  where  \\hat{\\mathbf{q}_i} \\hat{\\mathbf{q}_i}  is the dual quaternion representation of the rigid\ntransformation of bone  i i . The normalization forces the result of the linear\nblending to again be a unit dual quaternion and thus also a rigid\ntransformation.  Like linear blend skinning, dual quaternion skinning is best performed in the\nvertex shader. The only difference being that bone transformations are sent as\ndual quaternions rather than affine transformation matrices.  Libigl supports\nCPU-side dual quaternion skinning with the  igl::dqs  function, which takes a\nmore traditional representation of rigid transformations as input and\ninternally converts to the dual quaternion representation before blending:  // vQ is a list of rotations as quaternions  // vT is a list of translations  igl :: dqs ( V , W , vQ , vT , U );",
            "title": "Dual quaternion skinning"
        },
        {
            "location": "/tutorial/chapter-4/#as-rigid-as-possible",
            "text": "Skinning and other linear methods for deformation are inherently limited.\nDifficult arises especially when large rotations are imposed by the handle\nconstraints.  In the context of energy-minimization approaches, the problem stems from\ncomparing positions (our displacements) in the coordinate frame of the\nundeformed shape. These quadratic energies are at best invariant to global\nrotations of the entire shape, but not smoothly varying local rotations. Thus\nlinear techniques will not produce non-trivial bending and twisting.  Furthermore, when considering solid shapes (e.g. discretized with tetrahedral\nmeshes) linear methods struggle to maintain local volume, and they often suffer from\nshrinking and bulging artifacts.  Non-linear deformation techniques present a solution to these problems.\nThey work by comparing the deformation of a mesh\nvertex to its rest position  rotated  to a new coordinate frame which best\nmatches the deformation. The non-linearity stems from the mutual dependence of\nthe deformation and the best-fit rotation. These techniques are often labeled\n\"as-rigid-as-possible\" as they penalize the sum of all local deformations'\ndeviations from rotations.  To arrive at such an energy, let's consider a simple per-triangle energy:  E_\\text{linear}(\\mathbf{X}') = \\sum\\limits_{t \\in T} a_t \\sum\\limits_{\\{i,j\\}\n \\in t} w_{ij} \\left\\|\n \\left(\\mathbf{x}'_i - \\mathbf{x}'_j\\right) -\n \\left(\\mathbf{x}_i - \\mathbf{x}_j\\right)\\right\\|^2 E_\\text{linear}(\\mathbf{X}') = \\sum\\limits_{t \\in T} a_t \\sum\\limits_{\\{i,j\\}\n \\in t} w_{ij} \\left\\|\n \\left(\\mathbf{x}'_i - \\mathbf{x}'_j\\right) -\n \\left(\\mathbf{x}_i - \\mathbf{x}_j\\right)\\right\\|^2  where  \\mathbf{X}' \\mathbf{X}'  are the mesh's unknown deformed vertex positions,  t t  is a\ntriangle in a list of triangles  T T ,  a_t a_t  is the area of triangle  t t  and \\{i,j\\} \\{i,j\\}  is an edge in triangle  t t . Thus, this energy measures the norm of\nchange between an edge vector in the original mesh  \\left(\\mathbf{x}_i -\n\\mathbf{x}_j\\right) \\left(\\mathbf{x}_i -\n\\mathbf{x}_j\\right)  and the unknown mesh  \\left(\\mathbf{x}'_i -\n\\mathbf{x}'_j\\right) \\left(\\mathbf{x}'_i -\n\\mathbf{x}'_j\\right) .  This energy is  not  rotation invariant. If we rotate the mesh by 90 degrees\nthe change in edge vectors not aligned with the axis of rotation will be large,\ndespite the overall deformation being perfectly rigid.  So, the \"as-rigid-as-possible\" solution is to append auxiliary variables \\mathbf{R}_t \\mathbf{R}_t \nfor each triangle  t t  which are constrained to be rotations. Then the energy is\nrewritten, this time comparing deformed edge vectors to their rotated rest\ncounterparts:  E_\\text{arap}(\\mathbf{X}',\\{\\mathbf{R}_1,\\dots,\\mathbf{R}_{|T|}\\}) = \\sum\\limits_{t \\in T} a_t \\sum\\limits_{\\{i,j\\}\n \\in t} w_{ij} \\left\\|\n \\left(\\mathbf{x}'_i - \\mathbf{x}'_j\\right)-\n \\mathbf{R}_t\\left(\\mathbf{x}_i - \\mathbf{x}_j\\right)\\right\\|^2. E_\\text{arap}(\\mathbf{X}',\\{\\mathbf{R}_1,\\dots,\\mathbf{R}_{|T|}\\}) = \\sum\\limits_{t \\in T} a_t \\sum\\limits_{\\{i,j\\}\n \\in t} w_{ij} \\left\\|\n \\left(\\mathbf{x}'_i - \\mathbf{x}'_j\\right)-\n \\mathbf{R}_t\\left(\\mathbf{x}_i - \\mathbf{x}_j\\right)\\right\\|^2.  The separation into the primary vertex position variables  \\mathbf{X}' \\mathbf{X}'  and the\nrotations  \\{\\mathbf{R}_1,\\dots,\\mathbf{R}_{|T|}\\} \\{\\mathbf{R}_1,\\dots,\\mathbf{R}_{|T|}\\}  lead to strategy for\noptimization, too. If the rotations  \\{\\mathbf{R}_1,\\dots,\\mathbf{R}_{|T|}\\} \\{\\mathbf{R}_1,\\dots,\\mathbf{R}_{|T|}\\} \nare held fixed then the energy is quadratic in the remaining variables \\mathbf{X}' \\mathbf{X}'  and can be optimized by solving a (sparse) global linear system.\nAlternatively, if  \\mathbf{X}' \\mathbf{X}'  are held fixed then each rotation is the\nsolution to a localized  Procrustes  problem (found via  3 \\times 3 3 \\times 3  SVD or\npolar decompostion). These two steps---local and global---each weakly decrease\nthe energy, thus we may safely iterate them until convergence.  The different flavors of \"as-rigid-as-possible\" depend on the dimension and\ncodimension of the domain and the edge-sets  T T . The proposed surface\nmanipulation technique by Sorkine and Alexa [#sorkine_2007][], considers  T T  to\nbe the set of sets of edges emanating from each vertex (spokes). Later, Chao et\nal.  derived the relationship between \"as-rigid-as-possible\" mesh energies and\nco-rotational elasticity considering 0-codimension elements as edge-sets:\ntriangles in 2D and tetrahedra in 3D [#chao_2010][]. They also showed how\nSorkine and Alexa's edge-sets are not a discretization of a continuous energy,\nproposing instead edge-sets for surfaces containing all edges of elements\nincident on a vertex (spokes and rims). They show that this amounts to\nmeasuring bending, albeit in a discretization-dependent way.  Libigl, supports these common flavors. Selecting one is a matter of setting the\nenergy type before the precompuation phase:  igl :: ARAPData   arap_data ;  arap_data . energy   =   igl :: ARAP_ENERGY_TYPE_SPOKES ;  //arap_data.energy = igl::ARAP_ENERGY_TYPE_SPOKES_AND_RIMS;  //arap_data.energy = igl::ARAP_ENERGY_TYPE_ELEMENTS; //triangles or tets  igl :: arap_precomputation ( V , F , dim , b , arap_data );   Just like  igl::min_quad_with_fixed_* , this precomputation phase only depends\non the mesh, fixed vertex indices  b  and the energy parameters. To solve with\ncertain constraints on the positions of vertices in  b , we may call:  igl :: arap_solve ( bc , arap_data , U );   which uses  U  as an initial guess and then computes the solution into it.  Libigl's implementation of as-rigid-as-possible deformation takes advantage of\nthe highly optimized singular value decomposition code from McAdams et al.\n[#mcadams_2011][] which leverages SSE intrinsics.   The concept of local rigidity will be revisited shortly in the context of\nsurface parameterization.",
            "title": "As-rigid-as-possible"
        },
        {
            "location": "/tutorial/chapter-4/#fast-automatic-skinning-transformations",
            "text": "Non-linear optimization is, unsurprisingly, slower than its linear cousins. In\nthe case of the as-rigid-as-possible optimization, the bottleneck is typically\nthe large number of polar decompositions necessary to recover best fit\nrotations for each edge-set (i.e. for each triangle, tetrahedron, or vertex\ncell). Even if this code is optimized, the number of primary degrees of freedom\nis tied to the discretization level, despite the deformations' low frequency\nbehavior.  This invites two routes toward fast non-linear optimization. First, is it\nnecessary (or even advantageous) to find so many best-fit rotations? Second,\ncan we reduce the degrees of freedom to better reflect the frequency of the\ndesired deformations.  Taken in turn, these optimizations culminate in a method which optimizes over\nthe space of linear blend skinning deformations spanned by high-quality weights\n(i.e. manually painted ones or bounded biharmonic weights). This space is a\nlow-dimensional subspace of all possible mesh deformations, captured by writing\nlinear blend skinning in matrix form:  \\mathbf{X}' = \\mathbf{M}\\mathbf{T} \\mathbf{X}' = \\mathbf{M}\\mathbf{T}  where the mesh vertex positions in the  n \\times 3 n \\times 3  matrix  \\mathbf{X}' \\mathbf{X}'  are\nreplaced by a linear combination of a small number of degrees of freedom in the (3+1)m \\times 3 (3+1)m \\times 3  stack of transposed \"handle\" transformations. Swapping in \\mathbf{M}\\mathbf{T} \\mathbf{M}\\mathbf{T}  for  \\mathbf{X}' \\mathbf{X}'  in the ARAP energies above immediately\nsees performance gains during the global solve step as  m << n m << n .  The complexity of the local step---fitting rotations---is still bound\nto the original mesh discretization. However, if the skinning is well behaved,\nwe can make the assumption that places on the shape with similar skinning\nweights will deform similarly and thus imply similar best-fit rotations.\nTherefore, we cluster edge-sets according to their representation in weight-space : where a vertex  \\mathbf{x} \\mathbf{x}  takes the coordinates [w_1(\\mathbf{x}),w_2(\\mathbf{x}),\\dots,w_m(\\mathbf{x})] [w_1(\\mathbf{x}),w_2(\\mathbf{x}),\\dots,w_m(\\mathbf{x})] . The number of\nclustered edge-sets show diminishing returns on the deformation quality so we\nmay choose a small number of clusters, proportional to the number of skinning\nweight functions (rather than the number of discrete mesh vertices).  This proposed deformation model [#jacobson_2012][], can simultaneously be seen as a\nfast, subspace optimization for ARAP and as an automatic method for finding the best  skinning transformation degrees of freedom.  A variety of user interfaces are supported via linear equality constraints on\nthe skinning transformations associated with handles. To fix a transformation\nentirely we simply add the constraint:  \\left(\\begin{array}{cccc}\n 1 & 0 & 0 & 0\\\\\n 0 & 1 & 0 & 0\\\\\n 0 & 0 & 1 & 0\\\\\n 0 & 0 & 0 & 1\\end{array}\\right)\n \\mathbf{T}_i^T = \\hat{\\mathbf{T}}_i^T, \\left(\\begin{array}{cccc}\n 1 & 0 & 0 & 0\\\\\n 0 & 1 & 0 & 0\\\\\n 0 & 0 & 1 & 0\\\\\n 0 & 0 & 0 & 1\\end{array}\\right)\n \\mathbf{T}_i^T = \\hat{\\mathbf{T}}_i^T,  where  \\hat{\\mathbf{T}}_i^T \\hat{\\mathbf{T}}_i^T  is the  (3+1) \\times 3 (3+1) \\times 3  transposed fixed\ntransformation for handle  i i .  To fix only the origin of a handle, we add a constraint requiring the\ntransformation to interpolate a point in space (typically the centroid of all\npoints with  w_i = 1 w_i = 1 :  \\mathbf{c}'^T\\mathbf{T}_i^T = \\mathbf{c}^T, \\mathbf{c}'^T\\mathbf{T}_i^T = \\mathbf{c}^T,  where  \\mathbf{c}^T \\mathbf{c}^T  is the  1 \\times (3+1) 1 \\times (3+1)  position of the point at rest in\ntransposed homogeneous coordinates, and  \\mathbf{c}'^T \\mathbf{c}'^T  the point given by the\nuser.  We can similarly fix just the linear part of the transformation at a handle,\nfreeing the translation component (producing a \"chickenhead\" effect):  \\left(\\begin{array}{cccc}\n 1&0&0&0\\\\\n 0&1&0&0\\\\\n 0&0&1&0\\end{array}\\right)\n \\mathbf{T}_i^T = \\hat{\\mathbf{L}}_i^T, \\left(\\begin{array}{cccc}\n 1&0&0&0\\\\\n 0&1&0&0\\\\\n 0&0&1&0\\end{array}\\right)\n \\mathbf{T}_i^T = \\hat{\\mathbf{L}}_i^T,  where  \\hat{\\mathbf{L}}_i^T \\hat{\\mathbf{L}}_i^T  is the fixed  3 \\times 3 3 \\times 3  linear part of the\ntransformation at handle  i i .  And lastly we can allow the user to entirely  free  the transformation's\ndegrees of freedom, delegating the optimization to find the best possible\nvalues for all elements. To do this, we simply abstain from adding a\ncorresponding constraint.",
            "title": "Fast automatic skinning transformations"
        },
        {
            "location": "/tutorial/chapter-4/#arap-with-grouped-edge-sets",
            "text": "Being a subspace method, an immediate disadvantage is the reduced degrees of\nfreedom. This brings performance, but in some situations limits behavior too\nmuch. In such cases one can use the skinning subspace to build an effective\nclustering of rotation edge-sets for a traditional ARAP optimization: forgoing\nthe subspace substitution. This has an two-fold effect. The cost of the\nrotation fitting, local step drastically reduces, and the deformations are\n\"regularized\" according the clusters. From a high level point of view, if the\nclusters are derived from skinning weights, then they will discourage bending,\nespecially along isolines of the weight functions. If handles are not known in\nadvance, one could also cluster according to a \"geodesic embedding\" like the\nbiharmonic distance embedding.  In this light, we can think of the \"spokes+rims\" style surface ARAP as a (slight and\nredundant) clustering of the per-triangle edge-sets.",
            "title": "ARAP with grouped edge-sets"
        },
        {
            "location": "/tutorial/chapter-4/#biharmonic-coordinates",
            "text": "Linear blend skinning (as  above ) deforms a mesh by\npropagating  full affine transformations  at handles (bones, points, regions,\netc.) to the rest of the shape via weights. Another deformation framework,\ncalled \"generalized barycentric coordinates\", is a special case of linear blend\nskinning [#jacobson_skinning_course_2014][]: transformations are restricted to pure translations  and weights are required to retain  affine precision . This\nlatter requirement means that we can write the rest-position of any vertex in\nthe mesh as the weighted combination of the control handle locations:  \\mathbf{x} = \\sum\\limits_{i=1}^m w_i(\\mathbf{x}) * \\mathbf{c}_i, \\mathbf{x} = \\sum\\limits_{i=1}^m w_i(\\mathbf{x}) * \\mathbf{c}_i,  where  \\mathbf{c}_i \\mathbf{c}_i  is the rest position of the  i i th control point. This\nsimplifies the deformation formula at run-time. We can simply take the new\nposition of each point of the shape to be the weighted combination of the translated  control point positions:  \\mathbf{x}' = \\sum\\limits_{i=1}^m w_i(\\mathbf{x}) * \\mathbf{c}_i'. \\mathbf{x}' = \\sum\\limits_{i=1}^m w_i(\\mathbf{x}) * \\mathbf{c}_i'.  There are  many  different flavors of \"generalized barycentric coordinates\"\n(see table in \"Automatic Methods\" section,\n[#jacobson_skinning_course_2014][]). The vague goal of \"generalized barycentric\ncoordinates\" is to capture as many properties of simplicial barycentric\ncoordinates (e.g. for triangles in 2D and tetrahedral in 3D) for larger sets of\npoints or polyhedra. Some generalized barycentric coordinates can be computed\nin closed form; others require optimization-based precomputation. Nearly all\nflavors require connectivity information describing how the control points form\na external polyhedron around the input shape: a cage. However, a recent\ntechinique does not require a cage [#wang_bc_2015][]. This method ensures\naffine precision during optimization over weights of a smoothness energy with\naffine functions in its kernel:  \\mathop{\\text{min}}_\\mathbf{W}\\,\\, \\text{trace}(\\frac{1}{2}\\mathbf{W}^T \\mathbf{A}\n \\mathbf{W}), \\text{subject to: } \\mathbf{C} = \\mathbf{W}\\mathbf{C} \\mathop{\\text{min}}_\\mathbf{W}\\,\\, \\text{trace}(\\frac{1}{2}\\mathbf{W}^T \\mathbf{A}\n \\mathbf{W}), \\text{subject to: } \\mathbf{C} = \\mathbf{W}\\mathbf{C}  subject to interpolation constraints at selected vertices. If  \\mathbf{A} \\mathbf{A}  has\naffine functions in its kernel---that is, if  \\mathbf{A}\\mathbf{V} = 0 \\mathbf{A}\\mathbf{V} = 0 ---then\nthe weights  \\mathbf{W} \\mathbf{W}  will retain affine precision and we'll have that:  \\mathbf{V} = \\mathbf{W}\\mathbf{C} \\mathbf{V} = \\mathbf{W}\\mathbf{C}  the matrix form of the equality above. The proposed way to define  \\mathbf{A} \\mathbf{A} \nis to construct a matrix  \\mathbf{K} \\mathbf{K}  that measures the Laplacian at all\ninterior vertices  and at all boundary vertices . The  usual  definition of the\ndiscrete Laplacian (e.g. what libigl returns from  igl::cotmatrix ), measures\nthe Laplacian of a function for interior vertices, but measures the Laplacian\nof a function  minus  the normal derivative of a function for boundary\nvertices. Thus, we can let:  \\mathbf{K} = \\mathbf{L} + \\mathbf{N} \\mathbf{K} = \\mathbf{L} + \\mathbf{N}  where  \\mathbf{L} \\mathbf{L}  is the  usual  Laplacian and  \\mathbf{N} \\mathbf{N}  is matrix that\ncomputes normal derivatives of a piecewise-linear function at boundary vertices\nof a mesh. Then  \\mathbf{A} \\mathbf{A}  is taken as quadratic form computing the square of\nthe integral-average of  \\mathbf{K} \\mathbf{K}  applied to a function and integrated over\nthe mesh:  \\mathbf{A} = (\\mathbf{M}^{-1}\\mathbf{K})^2_\\mathbf{M} = \\mathbf{K}^T \\mathbf{M}^{-1}\n \\mathbf{K}. \\mathbf{A} = (\\mathbf{M}^{-1}\\mathbf{K})^2_\\mathbf{M} = \\mathbf{K}^T \\mathbf{M}^{-1}\n \\mathbf{K}.  Since the Laplacian  \\mathbf{K} \\mathbf{K}  is a second-order derivative it measures zero on affine\nfunctions, thus  \\mathbf{A} \\mathbf{A}  has affine functions in its null space. A short\nderivation proves that this implies  \\mathbf{W} \\mathbf{W}  will be affine precise (see\n[#wang_bc_2015][]).  Minimizers of this \"squared Laplacian\" energy are in some sense  discrete\nbiharmonic functions . Thus they're dubbed \"biharmonic coordinates\" (not the\nsame as  bounded biharmonic weights , which are  not  generalized barycentric\ncoordinates).  In libigl, one can compute biharmonic coordinates given a mesh  (V,F)  and a\nlist  S  of selected control points or control regions (which act like skinning\nhandles):  igl :: biharmonic_coordinates ( V , F , S , W );",
            "title": "Biharmonic Coordinates"
        },
        {
            "location": "/tutorial/chapter-5/",
            "text": "Chapter 5: Parametrization [chapter5:parametrization]\n\u00b6\n\n\nIn computer graphics, we denote as surface parametrization a map from the\nsurface to \\(\\mathbf{R}^2\\). It is usually encoded by a new set of 2D\ncoordinates for each vertex of the mesh (and possibly also by a new set of\nfaces in one to one correspondence with the faces of the original surface).\nNote that\nthis definition is the \ninverse\n of the classical differential geometry\ndefinition.\n\n\nA parametrization has many applications, ranging from texture mapping to\nsurface remeshing. Many algorithms have been proposed, and they can be broadly\ndivided in four families:\n\n\n\n\n\n\nSingle patch, fixed boundary\n: these algorithm can parametrize a\ndisk-like part of the surface given fixed 2D positions for its boundary. These\nalgorithms are efficient and simple, but they usually produce high-distortion maps due to the fixed boundary.\n\n\n\n\n\n\nSingle patch, free boundary:\n these algorithms let the boundary\ndeform freely, greatly reducing the map distortion. Care should be taken to\nprevent the border to self-intersect.\n\n\n\n\n\n\nGlobal parametrization\n: these algorithms work on meshes with arbitrary\ngenus. They initially cut the mesh in multiple patches that can be separately parametrized. The generated maps are discontinuous on the cuts (often referred as \nseams\n).\n\n\n\n\n\n\nGlobal seamless parametrization\n: these are global parametrization algorithm that hides the seams, making the parametrization \"continuous\", under specific assumptions that we will discuss later.\n\n\n\n\n\n\nHarmonic parametrization\n [harmonicparametrization]\n\u00b6\n\n\nHarmonic parametrization [#eck_2005][] is a single patch, fixed boundary parametrization\nalgorithm that computes the 2D coordinates of the flattened mesh as two\nharmonic functions.\n\n\nThe algorithm is divided in 3 steps:\n\n\n\n\nDetect of the boundary vertices\n\n\nMap the boundary vertices to a circle\n\n\nCompute two harmonic functions (one for u and one for the v coordinate). The harmonic functions use the fixed vertices on the circle as boundary constraints.\n\n\n\n\nThe algorithm can be coded using libigl as follows:\n\n\nEigen\n::\nVectorXi\n \nbnd\n;\n\n\nigl\n::\nboundary_loop\n(\nV\n,\nF\n,\nbnd\n);\n\n\n\nEigen\n::\nMatrixXd\n \nbnd_uv\n;\n\n\nigl\n::\nmap_vertices_to_circle\n(\nV\n,\nbnd\n,\nbnd_uv\n);\n\n\n\nigl\n::\nharmonic\n(\nV\n,\nF\n,\nbnd\n,\nbnd_uv\n,\n1\n,\nV_uv\n);\n\n\n\n\n\nwhere \nbnd\n contains the indices of the boundary vertices, bnd_uv their position on the UV plane, and \"1\" denotes that we want to compute an harmonic function (2 will be for biharmonic, 3 for triharmonic, etc.). Note that each of the three\nfunctions is designed to be reusable in other parametrization algorithms.\n\n\nA UV parametrization can be visualized in the viewer with:\n\n\nviewer\n.\ndata\n().\nset_uv\n(\nV_uv\n);\n\n\n\n\n\nThe UV coordinates are then used to apply a procedural checkerboard texture to the\nmesh (\nExample 501\n).\n\n\n\n\nLeast squares conformal maps\n [leastsquareconformalmaps]\n\u00b6\n\n\nLeast squares conformal maps parametrization [#levy_2002][] minimizes the\nconformal (angular) distortion of the parametrization. Differently from\nharmonic parametrization, it does not need to have a fixed boundary.\n\n\nLSCM minimizes the following energy:\n\n\n\\[ E_{LSCM}(\\mathbf{u},\\mathbf{v}) = \\int_X \\frac{1}{2}| \\nabla \\mathbf{u}^{\\perp} - \\nabla \\mathbf{v} |^2 dA \\]\n\n\nwhich can be rewritten in matrix form as [#mullen_2008][]:\n\n\n\\[ E_{LSCM}(\\mathbf{u},\\mathbf{v}) = \\frac{1}{2} [\\mathbf{u},\\mathbf{v}]^t (L_c - 2A) [\\mathbf{u},\\mathbf{v}] \\]\n\n\nwhere \nL_c\nL_c\n is the cotangent Laplacian matrix and \nA\nA\n is a matrix such that\n\n[\\mathbf{u},\\mathbf{v}]^t A  [\\mathbf{u},\\mathbf{v}]\n[\\mathbf{u},\\mathbf{v}]^t A  [\\mathbf{u},\\mathbf{v}]\n is equal to the \nvector\narea\n of the mesh.\n\n\nUsing libigl, this matrix energy can be written in a few lines of code. The\ncotangent matrix can be computed using \nigl::cotmatrix\n:\n\n\nSparseMatrix\n<\ndouble\n>\n \nL\n;\n\n\nigl\n::\ncotmatrix\n(\nV\n,\nF\n,\nL\n);\n\n\n\n\n\nNote that we want to apply the Laplacian matrix to the u and v coordinates at\nthe same time, thus we need to extend it taking the left\nKronecker product with a 2x2 identity matrix:\n\n\nSparseMatrix\n<\ndouble\n>\n \nL_flat\n;\n\n\nigl\n::\nrepdiag\n(\nL\n,\n2\n,\nL_flat\n);\n\n\n\n\n\nThe area matrix is computed with \nigl::vector_area_matrix\n:\n\n\nSparseMatrix\n<\ndouble\n>\n \nA\n;\n\n\nigl\n::\nvector_area_matrix\n(\nF\n,\nA\n);\n\n\n\n\n\nThe final energy matrix is \nL_{flat} - 2A\nL_{flat} - 2A\n. Note that in this\ncase we do not need to fix the boundary. To remove the null space of the energy and make the minimum unique, it is sufficient to fix two arbitrary\nvertices to two arbitrary positions. The full source code is provided in \nExample 502\n.\n\n\n\n\nAs-rigid-as-possible parametrization\n [asrigidaspossible]\n\u00b6\n\n\nAs-rigid-as-possible parametrization [#liu_2008][] is a powerful single-patch,\nnon-linear algorithm to compute a parametrization that strives to preserve\ndistances (and thus angles). The idea is very similar to ARAP surface\ndeformation: each triangle is mapped to the plane trying to preserve its\noriginal shape, up to a rigid rotation.\n\n\nThe algorithm can be implemented reusing the functions discussed in the\ndeformation chapter: \nigl::arap_precomputation\n and \nigl::arap_solve\n. The only\ndifference is that the optimization has to be done in 2D instead of 3D and that\nwe need to compute a starting point. While for 3D deformation the optimization\nis bootstrapped with the original mesh, this is not the case for ARAP\nparametrization since the starting point must be a 2D mesh. In \nExample\n503\n, we initialize the optimization with harmonic\nparametrization. Similarly to LSCM, the boundary is free to deform to minimize\nthe distortion.\n\n\n\n\nN-rotationally symmetric tangent fields\n [nrotationallysymmetrictangetfields]\n\u00b6\n\n\nThe design of tangent fields is a basic tool used to design guidance fields for\nuniform quadrilateral and hexahedral remeshing. Libigl contains an\nimplementation of all the state-of-the-art algorithms to design N-RoSy fields\nand their generalizations.\n\n\nIn libigl, tangent unit-length vector fields are piece-wise constant on the\nfaces of a triangle mesh, and they are described by one or more vectors per-face. The function\n\n\nigl\n::\nnrosy\n(\nV\n,\nF\n,\nb\n,\nbc\n,\nb_soft\n,\nb_soft_weight\n,\nbc_soft\n,\nN\n,\n0.5\n,\n\n           \noutput_field\n,\noutput_singularities\n);\n\n\n\n\n\ncreates a smooth unit-length vector field (N=1) starting from a sparse set of\nconstrained faces, whose indices are listed in b and their constrained value is\nspecified in bc. The functions supports soft_constraints (b_soft,\nb_soft_weight, bc_soft), and returns the interpolated field for each face of\nthe triangle mesh (output_field), plus the singularities of the field\n(output_singularities).\n\n\n\n\nThe singularities are vertices where the field vanishes (highlighted in red in\nthe figure above). \nigl::nrosy\n can also generate N-RoSy fields [#levy_2008][],\nwhich are a generalization of vector fields where in every face the vector is\ndefined up to a constant rotation of \n2\\pi / N\n2\\pi / N\n. As can be observed in\nthe following figure, the singularities of the fields generated with different\nN are of different types and they appear in different positions.\n\n\n\n\nWe demonstrate how to call and plot N-RoSy fields in \nExample\n504\n, where the degree of the field can be change\npressing the number keys. \nigl::nrosy\n implements the algorithm proposed in\n[#bommes_2009][]. N-RoSy fields can also be interpolated with many other algorithms,\nsee the library \nlibdirectional\n for\na reference implementation of the most popular ones. For a complete categorization\nof fields used in various applications see Vaxman et al. 2016 [#vaxman_2016].\n\n\nGlobal, seamless integer-grid parametrization\n [globalseamlessintegergridparametrization]\n\u00b6\n\n\nThe previous parametrization methods were focusing on creating parametrizations\nof surface patches aimed at texture mapping or baking of other surface\nproperties such as normals and high-frequency details. Global, seamless\nparametrization aims at parametrizing complex shapes with a parametrization\nthat is aligned with a given set of directions for the purpose of surface\nremeshing. In libigl, we provide a reference  implementation of the pipeline\nproposed in the mixed integer quadrangulation paper [#bommes_2009][].\n\n\nThe first step involves the design of a 4-RoSy field (sometimes called \ncross\n\nfield) that describes the alignment of the edges of the desired quadrilateral\nremeshing. The field constraints are usually manually specified or extracted\nfrom the principal curvature directions. In [\nExample\n506\n], we simply fix one face in a random direction.\n\n\n\n\nCombing and cutting\n\u00b6\n\n\nGiven the cross field, we now want to cut the surface so that it becomes\nhomeomorphic to a disk. While this could be done directly on the cross-field, we\nopt to perform this operation on its bisector field (a copy of the field\nrotated by 45 degrees) since it is more stable and generic. Working on the\nbisectors allow us to take as input generalized, non-orthogonal and non-unit\nlength cross fields.\n\n\nWe thus rotate the field,\n\n\n\n\nand we remove the rotation ambiguity by assigning to each face a u and a v\ndirection. The assignment is done with a breadth-first search starting from a\nrandom face.\n\n\n\n\nYou can imagine this process as combing an hairy surface: you will be able to\ncomb part of it, but at some point you will not be able to consistently comb\nthe entire surface (\nHairy ball\ntheorem\n). The discontinuities\nin the combing define the cut graph:\n\n\n\n\nFinally, we rotate the combed field by 45 degrees to undo the initial degrees\nrotation:\n\n\n\n\nThe combed cross field can be seen as the ideal Jacobian of the parametrization\nthat will be computed in the next section.\n\n\nPoisson parametrization\n\u00b6\n\n\nThe mesh is cut along the seams and a parametrization is computed trying to\nfind two scalar functions whose gradient matches the combed cross field\ndirections. This is a classical Poisson problem, that is solved minimizing the\nfollowing quadratic energy:\n\n\n\\[ E(\\mathbf{u},\\mathbf{v}) = |\\nabla \\mathbf{u} - X_u|^2 + |\\nabla \\mathbf{v} - X_v|^2 \\]\n\n\nwhere \nX_u\nX_u\n and \nX_u\nX_u\n denotes the combed cross field. Solving this\nproblem generates a parametrization whose u and v isolines are aligned with the\ninput cross field.\n\n\n\n\nWe hide the seams by adding integer constraints to the Poisson problem\nthat align the isolines on both sides of each seam [#bommes_2009].\n\n\n\n\nNote that this parametrization can only be used for remeshing purposes, since\nit contains many overlaps.\n\n\n\n\nA quad mesh can be extracted from this parametrization using\n\nlibQEx\n (not included in libigl).\nThe full pipeline is implemented in \nExample 505\n.\n\n\nAnisotropic remeshing\n [anisotropicremeshingusingframefields]\n\u00b6\n\n\nAnisotropic and non-uniform quad remeshing is important to concentrate the\nelements in the regions with more details. It is possible to extend the MIQ\nquad meshing framework to generate anisotropic quad meshes using a mesh\ndeformation approach [#panozzo_2014][].\n\n\nThe input of the anisotropic remeshing algorithm is a sparse set of constraints\nthat define the shape and scale of the desired quads. This can be encoded as a\nframe field, which is a pair of non-orthogonal and non-unit length vectors. The\nframe field can be interpolated by decomposing it in a 4-RoSy field and a\nunique affine transformation. The two parts can then be interpolated\nseparately, using \nigl::nrosy\n for the cross field, and an harmonic interpolant\nfor the affine part.\n\n\n\n\nAfter the interpolation, the surface is warped to transform each frame into an\northogonal and unit length cross (i.e. removing the scaling and skewness from\nthe frame). This deformation defines a new embedding (and a new metric) for the\nsurface.\n\n\n\n\nThe deformed surface can the be isotropically remeshed using the MIQ algorithm\nthat has been presented in the previous section.\n\n\n\n\nThe UV coordinates of the deformed surface can then be used to transport the\nparametrization to the original surface, where the isolines will trace a quad\nmesh whose elements are similar to the shape prescribed in the input frame\nfield.\n\n\n\n\nOur implementation (\nExample 506\n) uses MIQ to\ngenerate the UV parametrization, but other algorithms could be applied: the\nonly desiderata is that the generated quad mesh should be as isotropic as\npossible.\n\n\nPlanarization\n [planarization]\n\u00b6\n\n\nA quad mesh can be transformed in a planar quad mesh with Shape-Up\n[#bouaziz_2012], a local/global approach that uses the global step to enforce\nsurface continuity and the local step to enforce planarity.\n\n\nExample 507\n planarizes a quad mesh until it\nsatisfies a user-given planarity threshold.",
            "title": "Chapter 5: Parametrization"
        },
        {
            "location": "/tutorial/chapter-5/#chapter-5-parametrization-chapter5parametrization",
            "text": "In computer graphics, we denote as surface parametrization a map from the\nsurface to \\(\\mathbf{R}^2\\). It is usually encoded by a new set of 2D\ncoordinates for each vertex of the mesh (and possibly also by a new set of\nfaces in one to one correspondence with the faces of the original surface).\nNote that\nthis definition is the  inverse  of the classical differential geometry\ndefinition.  A parametrization has many applications, ranging from texture mapping to\nsurface remeshing. Many algorithms have been proposed, and they can be broadly\ndivided in four families:    Single patch, fixed boundary : these algorithm can parametrize a\ndisk-like part of the surface given fixed 2D positions for its boundary. These\nalgorithms are efficient and simple, but they usually produce high-distortion maps due to the fixed boundary.    Single patch, free boundary:  these algorithms let the boundary\ndeform freely, greatly reducing the map distortion. Care should be taken to\nprevent the border to self-intersect.    Global parametrization : these algorithms work on meshes with arbitrary\ngenus. They initially cut the mesh in multiple patches that can be separately parametrized. The generated maps are discontinuous on the cuts (often referred as  seams ).    Global seamless parametrization : these are global parametrization algorithm that hides the seams, making the parametrization \"continuous\", under specific assumptions that we will discuss later.",
            "title": "Chapter 5: Parametrization [chapter5:parametrization]"
        },
        {
            "location": "/tutorial/chapter-5/#harmonic-parametrization-harmonicparametrization",
            "text": "Harmonic parametrization [#eck_2005][] is a single patch, fixed boundary parametrization\nalgorithm that computes the 2D coordinates of the flattened mesh as two\nharmonic functions.  The algorithm is divided in 3 steps:   Detect of the boundary vertices  Map the boundary vertices to a circle  Compute two harmonic functions (one for u and one for the v coordinate). The harmonic functions use the fixed vertices on the circle as boundary constraints.   The algorithm can be coded using libigl as follows:  Eigen :: VectorXi   bnd ;  igl :: boundary_loop ( V , F , bnd );  Eigen :: MatrixXd   bnd_uv ;  igl :: map_vertices_to_circle ( V , bnd , bnd_uv );  igl :: harmonic ( V , F , bnd , bnd_uv , 1 , V_uv );   where  bnd  contains the indices of the boundary vertices, bnd_uv their position on the UV plane, and \"1\" denotes that we want to compute an harmonic function (2 will be for biharmonic, 3 for triharmonic, etc.). Note that each of the three\nfunctions is designed to be reusable in other parametrization algorithms.  A UV parametrization can be visualized in the viewer with:  viewer . data (). set_uv ( V_uv );   The UV coordinates are then used to apply a procedural checkerboard texture to the\nmesh ( Example 501 ).",
            "title": "Harmonic parametrization [harmonicparametrization]"
        },
        {
            "location": "/tutorial/chapter-5/#least-squares-conformal-maps-leastsquareconformalmaps",
            "text": "Least squares conformal maps parametrization [#levy_2002][] minimizes the\nconformal (angular) distortion of the parametrization. Differently from\nharmonic parametrization, it does not need to have a fixed boundary.  LSCM minimizes the following energy:  \\[ E_{LSCM}(\\mathbf{u},\\mathbf{v}) = \\int_X \\frac{1}{2}| \\nabla \\mathbf{u}^{\\perp} - \\nabla \\mathbf{v} |^2 dA \\]  which can be rewritten in matrix form as [#mullen_2008][]:  \\[ E_{LSCM}(\\mathbf{u},\\mathbf{v}) = \\frac{1}{2} [\\mathbf{u},\\mathbf{v}]^t (L_c - 2A) [\\mathbf{u},\\mathbf{v}] \\]  where  L_c L_c  is the cotangent Laplacian matrix and  A A  is a matrix such that [\\mathbf{u},\\mathbf{v}]^t A  [\\mathbf{u},\\mathbf{v}] [\\mathbf{u},\\mathbf{v}]^t A  [\\mathbf{u},\\mathbf{v}]  is equal to the  vector\narea  of the mesh.  Using libigl, this matrix energy can be written in a few lines of code. The\ncotangent matrix can be computed using  igl::cotmatrix :  SparseMatrix < double >   L ;  igl :: cotmatrix ( V , F , L );   Note that we want to apply the Laplacian matrix to the u and v coordinates at\nthe same time, thus we need to extend it taking the left\nKronecker product with a 2x2 identity matrix:  SparseMatrix < double >   L_flat ;  igl :: repdiag ( L , 2 , L_flat );   The area matrix is computed with  igl::vector_area_matrix :  SparseMatrix < double >   A ;  igl :: vector_area_matrix ( F , A );   The final energy matrix is  L_{flat} - 2A L_{flat} - 2A . Note that in this\ncase we do not need to fix the boundary. To remove the null space of the energy and make the minimum unique, it is sufficient to fix two arbitrary\nvertices to two arbitrary positions. The full source code is provided in  Example 502 .",
            "title": "Least squares conformal maps [leastsquareconformalmaps]"
        },
        {
            "location": "/tutorial/chapter-5/#as-rigid-as-possible-parametrization-asrigidaspossible",
            "text": "As-rigid-as-possible parametrization [#liu_2008][] is a powerful single-patch,\nnon-linear algorithm to compute a parametrization that strives to preserve\ndistances (and thus angles). The idea is very similar to ARAP surface\ndeformation: each triangle is mapped to the plane trying to preserve its\noriginal shape, up to a rigid rotation.  The algorithm can be implemented reusing the functions discussed in the\ndeformation chapter:  igl::arap_precomputation  and  igl::arap_solve . The only\ndifference is that the optimization has to be done in 2D instead of 3D and that\nwe need to compute a starting point. While for 3D deformation the optimization\nis bootstrapped with the original mesh, this is not the case for ARAP\nparametrization since the starting point must be a 2D mesh. In  Example\n503 , we initialize the optimization with harmonic\nparametrization. Similarly to LSCM, the boundary is free to deform to minimize\nthe distortion.",
            "title": "As-rigid-as-possible parametrization [asrigidaspossible]"
        },
        {
            "location": "/tutorial/chapter-5/#n-rotationally-symmetric-tangent-fields-nrotationallysymmetrictangetfields",
            "text": "The design of tangent fields is a basic tool used to design guidance fields for\nuniform quadrilateral and hexahedral remeshing. Libigl contains an\nimplementation of all the state-of-the-art algorithms to design N-RoSy fields\nand their generalizations.  In libigl, tangent unit-length vector fields are piece-wise constant on the\nfaces of a triangle mesh, and they are described by one or more vectors per-face. The function  igl :: nrosy ( V , F , b , bc , b_soft , b_soft_weight , bc_soft , N , 0.5 , \n            output_field , output_singularities );   creates a smooth unit-length vector field (N=1) starting from a sparse set of\nconstrained faces, whose indices are listed in b and their constrained value is\nspecified in bc. The functions supports soft_constraints (b_soft,\nb_soft_weight, bc_soft), and returns the interpolated field for each face of\nthe triangle mesh (output_field), plus the singularities of the field\n(output_singularities).   The singularities are vertices where the field vanishes (highlighted in red in\nthe figure above).  igl::nrosy  can also generate N-RoSy fields [#levy_2008][],\nwhich are a generalization of vector fields where in every face the vector is\ndefined up to a constant rotation of  2\\pi / N 2\\pi / N . As can be observed in\nthe following figure, the singularities of the fields generated with different\nN are of different types and they appear in different positions.   We demonstrate how to call and plot N-RoSy fields in  Example\n504 , where the degree of the field can be change\npressing the number keys.  igl::nrosy  implements the algorithm proposed in\n[#bommes_2009][]. N-RoSy fields can also be interpolated with many other algorithms,\nsee the library  libdirectional  for\na reference implementation of the most popular ones. For a complete categorization\nof fields used in various applications see Vaxman et al. 2016 [#vaxman_2016].",
            "title": "N-rotationally symmetric tangent fields [nrotationallysymmetrictangetfields]"
        },
        {
            "location": "/tutorial/chapter-5/#global-seamless-integer-grid-parametrization-globalseamlessintegergridparametrization",
            "text": "The previous parametrization methods were focusing on creating parametrizations\nof surface patches aimed at texture mapping or baking of other surface\nproperties such as normals and high-frequency details. Global, seamless\nparametrization aims at parametrizing complex shapes with a parametrization\nthat is aligned with a given set of directions for the purpose of surface\nremeshing. In libigl, we provide a reference  implementation of the pipeline\nproposed in the mixed integer quadrangulation paper [#bommes_2009][].  The first step involves the design of a 4-RoSy field (sometimes called  cross \nfield) that describes the alignment of the edges of the desired quadrilateral\nremeshing. The field constraints are usually manually specified or extracted\nfrom the principal curvature directions. In [ Example\n506 ], we simply fix one face in a random direction.",
            "title": "Global, seamless integer-grid parametrization [globalseamlessintegergridparametrization]"
        },
        {
            "location": "/tutorial/chapter-5/#combing-and-cutting",
            "text": "Given the cross field, we now want to cut the surface so that it becomes\nhomeomorphic to a disk. While this could be done directly on the cross-field, we\nopt to perform this operation on its bisector field (a copy of the field\nrotated by 45 degrees) since it is more stable and generic. Working on the\nbisectors allow us to take as input generalized, non-orthogonal and non-unit\nlength cross fields.  We thus rotate the field,   and we remove the rotation ambiguity by assigning to each face a u and a v\ndirection. The assignment is done with a breadth-first search starting from a\nrandom face.   You can imagine this process as combing an hairy surface: you will be able to\ncomb part of it, but at some point you will not be able to consistently comb\nthe entire surface ( Hairy ball\ntheorem ). The discontinuities\nin the combing define the cut graph:   Finally, we rotate the combed field by 45 degrees to undo the initial degrees\nrotation:   The combed cross field can be seen as the ideal Jacobian of the parametrization\nthat will be computed in the next section.",
            "title": "Combing and cutting"
        },
        {
            "location": "/tutorial/chapter-5/#poisson-parametrization",
            "text": "The mesh is cut along the seams and a parametrization is computed trying to\nfind two scalar functions whose gradient matches the combed cross field\ndirections. This is a classical Poisson problem, that is solved minimizing the\nfollowing quadratic energy:  \\[ E(\\mathbf{u},\\mathbf{v}) = |\\nabla \\mathbf{u} - X_u|^2 + |\\nabla \\mathbf{v} - X_v|^2 \\]  where  X_u X_u  and  X_u X_u  denotes the combed cross field. Solving this\nproblem generates a parametrization whose u and v isolines are aligned with the\ninput cross field.   We hide the seams by adding integer constraints to the Poisson problem\nthat align the isolines on both sides of each seam [#bommes_2009].   Note that this parametrization can only be used for remeshing purposes, since\nit contains many overlaps.   A quad mesh can be extracted from this parametrization using libQEx  (not included in libigl).\nThe full pipeline is implemented in  Example 505 .",
            "title": "Poisson parametrization"
        },
        {
            "location": "/tutorial/chapter-5/#anisotropic-remeshing-anisotropicremeshingusingframefields",
            "text": "Anisotropic and non-uniform quad remeshing is important to concentrate the\nelements in the regions with more details. It is possible to extend the MIQ\nquad meshing framework to generate anisotropic quad meshes using a mesh\ndeformation approach [#panozzo_2014][].  The input of the anisotropic remeshing algorithm is a sparse set of constraints\nthat define the shape and scale of the desired quads. This can be encoded as a\nframe field, which is a pair of non-orthogonal and non-unit length vectors. The\nframe field can be interpolated by decomposing it in a 4-RoSy field and a\nunique affine transformation. The two parts can then be interpolated\nseparately, using  igl::nrosy  for the cross field, and an harmonic interpolant\nfor the affine part.   After the interpolation, the surface is warped to transform each frame into an\northogonal and unit length cross (i.e. removing the scaling and skewness from\nthe frame). This deformation defines a new embedding (and a new metric) for the\nsurface.   The deformed surface can the be isotropically remeshed using the MIQ algorithm\nthat has been presented in the previous section.   The UV coordinates of the deformed surface can then be used to transport the\nparametrization to the original surface, where the isolines will trace a quad\nmesh whose elements are similar to the shape prescribed in the input frame\nfield.   Our implementation ( Example 506 ) uses MIQ to\ngenerate the UV parametrization, but other algorithms could be applied: the\nonly desiderata is that the generated quad mesh should be as isotropic as\npossible.",
            "title": "Anisotropic remeshing [anisotropicremeshingusingframefields]"
        },
        {
            "location": "/tutorial/chapter-5/#planarization-planarization",
            "text": "A quad mesh can be transformed in a planar quad mesh with Shape-Up\n[#bouaziz_2012], a local/global approach that uses the global step to enforce\nsurface continuity and the local step to enforce planarity.  Example 507  planarizes a quad mesh until it\nsatisfies a user-given planarity threshold.",
            "title": "Planarization [planarization]"
        },
        {
            "location": "/tutorial/chapter-6/",
            "text": "Chapter 6: External libraries [chapter6:externallibraries]\n\u00b6\n\n\nAn additional positive side effect of using matrices as basic types is that it\nis easy to exchange data between libigl and other software and libraries.\n\n\nState serialization\n [stateserialization]\n\u00b6\n\n\nGeometry processing applications often require a considerable amount of\ncomputational time and/or manual input. Serializing the state of the application\nis a simple strategy to greatly increase the development efficiency. It allows\nto quickly start debugging just before the crash happens, avoiding to wait for\nthe precomputation to take place every time and it also makes your experiments\nreproducible, allowing to quickly test algorithms variants on the same input\ndata.\n\n\nSerialization is often not considered in geometry processing due to the extreme\ndifficulty in serializing pointer-based data structured, such as an half-edge\ndata structure (\nOpenMesh\n, \nCGAL\n),\nor a pointer based indexed structure\n(\nVCG\n).\n\n\nIn libigl, serialization is much simpler, since the majority of the functions\nuse basic types, and pointers are used in very rare cases (usually to interface\nwith external libraries). Libigl bundles a simple and self-contained binary and\nXML serialization framework, that drastically reduces the overhead required to\nadd serialization to your applications.\n\n\nTo de-/serialize a set of variables use the following method:\n\n\n#include\n \n\"igl/serialize.h\"\n\n\n\nbool\n \nb\n \n=\n \ntrue\n;\n\n\nunsigned\n \nint\n \nnum\n \n=\n \n10\n;\n\n\nstd\n::\nvector\n<\nfloat\n>\n \nvec\n \n=\n \n{\n0.1\n,\n0.002\n,\n5.3\n};\n\n\n\n// use overwrite = true for the first serialization to create or overwrite an\n\n\n// existing file\n\n\nigl\n::\nserialize\n(\nb\n,\n\"B\"\n,\n\"filename\"\n,\ntrue\n);\n\n\n// append following serialization to existing file\n\n\nigl\n::\nserialize\n(\nnum\n,\n\"Number\"\n,\n\"filename\"\n);\n\n\nigl\n::\nserialize\n(\nvec\n,\n\"VectorName\"\n,\n\"filename\"\n);\n\n\n\n// deserialize back to variables\n\n\nigl\n::\ndeserialize\n(\nb\n,\n\"B\"\n,\n\"filename\"\n);\n\n\nigl\n::\ndeserialize\n(\nnum\n,\n\"Number\"\n,\n\"filename\"\n);\n\n\nigl\n::\ndeserialize\n(\nvec\n,\n\"VectorName\"\n,\n\"filename\"\n);\n\n\n\n\n\nCurrently all fundamental data types (bool, int, float, double, ...) are\nsupported, as well as std::string, basic \nSTL\n containers, dense and sparse\nEigen matrices and nestings of those.  Some limitations apply to pointers.\nCurrently, loops or many to one type of link structures are not handled\ncorrectly. Each pointer is assumed to point to a different independent object.\nUninitialized pointers must be set to \nnullptr\n before de-/serialization to\navoid memory leaks. Cross-platform issues like little-, big-endianess is\ncurrently not supported.  To make user defined types serializable, just derive\nfrom \nigl::Serializable\n and trivially implementing the \nInitSerialization\n\nmethod.\n\n\nAssume that the state of your application is a mesh and a set of integer ids:\n\n\n#include\n \n\"igl/serialize.h\"\n\n\n\nstruct\n \nState\n \n:\n \npublic\n \nigl\n::\nSerializable\n\n\n{\n\n  \nEigen\n::\nMatrixXd\n \nV\n;\n\n  \nEigen\n::\nMatrixXi\n \nF\n;\n\n  \nstd\n::\nvector\n<\nint\n>\n \nids\n;\n\n\n  \nvoid\n \nInitSerialization\n()\n\n  \n{\n\n    \nthis\n->\nAdd\n(\nV\n  \n,\n \n\"V\"\n);\n\n    \nthis\n->\nAdd\n(\nF\n  \n,\n \n\"F\"\n);\n\n    \nthis\n->\nAdd\n(\nids\n,\n \n\"ids\"\n);\n\n  \n}\n\n\n};\n\n\n\n\n\nIf you need more control over the serialization of your types, you can override\nthe following functions or directly inherit from the interface\n\nigl::SerializableBase\n.\n\n\nbool\n \nSerializable\n::\nPreSerialization\n()\n \nconst\n;\n\n\nvoid\n \nSerializable\n::\nPostSerialization\n()\n \nconst\n;\n\n\nbool\n \nSerializable\n::\nPreDeserialization\n();\n\n\nvoid\n \nSerializable\n::\nPostDeserialization\n();\n\n\n\n\n\nAlternatively, if you want a non-intrusive way of serializing your state you can\noverload the following functions:\n\n\nnamespace\n \nigl\n\n\n{\n\n  \nnamespace\n \nserialization\n\n  \n{\n\n    \ntemplate\n \n<>\n \ninline\n \nvoid\n \nserialize\n(\nconst\n \nState\n&\n \nobj\n,\nstd\n::\nvector\n<\nchar\n>&\n \nbuffer\n)\n\n    \n{\n\n      \n::\nigl\n::\nserialize\n(\nobj\n.\nV\n,\nstd\n::\nstring\n(\n\"V\"\n),\nbuffer\n);\n\n      \n::\nigl\n::\nserialize\n(\nobj\n.\nF\n,\nstd\n::\nstring\n(\n\"F\"\n),\nbuffer\n);\n\n      \n::\nigl\n::\nserialize\n(\nobj\n.\nids\n,\nstd\n::\nstring\n(\n\"ids\"\n),\nbuffer\n);\n\n    \n}\n\n    \ntemplate\n \n<>\n \ninline\n \nvoid\n \ndeserialize\n(\nState\n&\n \nobj\n,\nconst\n \nstd\n::\nvector\n<\nchar\n>&\n \nbuffer\n)\n\n    \n{\n\n      \n::\nigl\n::\ndeserialize\n(\nobj\n.\nV\n,\nstd\n::\nstring\n(\n\"V\"\n),\nbuffer\n);\n\n      \n::\nigl\n::\ndeserialize\n(\nobj\n.\nF\n,\nstd\n::\nstring\n(\n\"F\"\n),\nbuffer\n);\n\n      \n::\nigl\n::\ndeserialize\n(\nobj\n.\nids\n,\nstd\n::\nstring\n(\n\"ids\"\n),\nbuffer\n);\n\n    \n}\n\n  \n}\n\n\n}\n\n\n\n\n\nEquivalently, you can use the following macros:\n\n\nSERIALIZE_TYPE\n(\nState\n,\n\n \nSERIALIZE_MEMBER\n(\nV\n)\n\n \nSERIALIZE_MEMBER\n(\nF\n)\n\n \nSERIALIZE_MEMBER_NAME\n(\nids\n,\n\"ids\"\n)\n\n\n)\n\n\n\n\n\nAll the former code is for binary serialization which is especially useful if\nyou have to handle larger data where the loading and saving times become more\nimportant.  For cases where you want to read and edit the serialized data by\nhand we provide a serialization to XML files which is based on the library\n\ntinyxml2\n.  There you also have the\noption to create a partial binary serialization of your data by using the binary\nparameter, exposed in the function \nserialize_xml()\n:\n\n\n#include\n \n\"igl/xml/serialize_xml.h\"\n\n\n\nint\n \nnumber\n;\n\n\n\n// binary = false, overwrite = true\n\n\nigl\n::\nserialize_xml\n(\nvec\n,\n\"VectorXML\"\n,\nxmlFile\n,\nfalse\n,\ntrue\n);\n\n\n// binary = true, overwrite = true\n\n\nigl\n::\nserialize_xml\n(\nvec\n,\n\"VectorBin\"\n,\nxmlFile\n,\ntrue\n,\ntrue\n);\n\n\nigl\n::\ndeserialize_xml\n(\nvec\n,\n\"VectorXML\"\n,\nxmlFile\n);\n\n\nigl\n::\ndeserialize_xml\n(\nvec\n,\n\"VectorBin\"\n,\nxmlFile\n);\n\n\n\n\n\nFor user defined types derive from \nXMLSerializable\n.\n\n\nThe code snippets above are extracted from \nExample\n601\n. We strongly suggest that you make the entire\nstate of your application always serializable since it will save you a lot of\ntroubles when you will be preparing figures for a scientific report. It is very\ncommon to have to do small changes to figures, and being able to serialize the\nentire state just before you take screenshots will save you many painful hours\nbefore a submission deadline.\n\n\nMixing Matlab code\n [mixingmatlabcode]\n\u00b6\n\n\nLibigl can be interfaced with Matlab to offload numerically heavy computation\nto a Matlab script. The major advantage of this approach is that you will be\nable to develop efficient and complex user-interfaces in C++, while exploring\nthe syntax and fast protototyping features of matlab. In particular, the use of\nan external Matlab script in a libigl application allows to change the Matlab\ncode while the C++ application is running, greatly increasing coding\nefficiency.\n\n\nWe demonstrate how to integrate Matlab in a libigl application in \nExample\n602\n. The example uses Matlab to compute the\nEigenfunctions of the discrete Laplacian operator, relying on libigl for mesh\nIO, visualization and for computing the Laplacian operator.\n\n\nLibigl can connect to an existing instance of Matlab (or launching a new one on\nLinux/MacOSX) using:\n\n\nigl\n::\nmlinit\n(\n&\nengine\n);\n\n\n\n\n\nThe cotangent Laplacian is computed using igl::cotmatrix and uploaded to the\nMatlab workspace:\n\n\nigl\n::\ncotmatrix\n(\nV\n,\nF\n,\nL\n);\n\n\nigl\n::\nmlsetmatrix\n(\n&\nengine\n,\n\"L\"\n,\nL\n);\n\n\n\n\n\nIt is now possible to use any Matlab function on the data. For example, we can\nsee the sparsity pattern of L using spy:\n\n\nigl\n::\nmleval\n(\n&\nengine\n,\n\"spy(L)\"\n);\n\n\n\n\n\n\n\nThe results of Matlab computations can be returned back to the C++ application\n\n\nigl\n::\nmleval\n(\n&\nengine\n,\n\"[EV,~] = eigs(-L,10,'sm')\"\n);\n\n\nigl\n::\nmlgetmatrix\n(\n&\nengine\n,\n\"EV\"\n,\nEV\n);\n\n\n\n\n\nand plotted using the libigl viewer.\n\n\n\n\nSaving a Matlab workspace\n\u00b6\n\n\nTo aid debugging, libigl also supplies functions to write Matlab \n.mat\n\n\"Workspaces\". This C++ snippet saves a mesh and it's sparse Laplacian matrix to\na file:\n\n\nigl\n::\nreadOFF\n(\nTUTORIAL_SHARED_PATH\n \n\"/fertility.off\"\n,\n \nV\n,\n \nF\n);\n\n\nigl\n::\ncotmatrix\n(\nV\n,\nF\n,\nL\n);\n\n\nigl\n::\nMatlabWorkspace\n \nmw\n;\n\n\nmw\n.\nsave\n(\nV\n,\n\"V\"\n);\n\n\nmw\n.\nsave_index\n(\nF\n,\n\"F\"\n);\n\n\nmw\n.\nsave\n(\nL\n,\n\"L\"\n);\n\n\nmw\n.\nwrite\n(\n\"fertility.mat\"\n);\n\n\n\n\n\nThen this workspace can be loaded into a Matlab IDE:\n\n\nload\n \nfertility\n.\nmat\n\n\n\n\n\nThe \nigl::MatlabWorkspace\n depends on Matlab libraries to compile and run,\nbut---in contrast to the engine routines above---will avoid launching a Matlab\ninstance upon execution.\n\n\nDumping Eigen matrices to copy and paste into Matlab\n\u00b6\n\n\nEigen supplies a sophisticated API for printing its matrix types to the screen.\nLibigl has wrapped up a particularly useful formatting which makes it simple to\ncopy standard output from a C++ program into a Matlab IDE. The code:\n\n\nigl\n::\nreadOFF\n(\nTUTORIAL_SHARED_PATH\n \n\"/2triangles.off\"\n,\n \nV\n,\n \nF\n);\n\n\nigl\n::\ncotmatrix\n(\nV\n,\nF\n,\nL\n);\n\n\nstd\n::\ncout\n<<\nigl\n::\nmatlab_format\n(\nV\n,\n\"V\"\n)\n<<\nstd\n::\nendl\n;\n\n\nstd\n::\ncout\n<<\nigl\n::\nmatlab_format\n((\nF\n.\narray\n()\n+\n1\n).\neval\n(),\n\"F\"\n)\n<<\nstd\n::\nendl\n;\n\n\nstd\n::\ncout\n<<\nigl\n::\nmatlab_format\n(\nL\n,\n\"L\"\n)\n<<\nstd\n::\nendl\n;\n\n\n\n\n\nproduces the output:\n\n\nV\n \n=\n \n[\n\n  \n0\n \n0\n \n0\n\n  \n1\n \n0\n \n0\n\n  \n1\n \n1\n \n1\n\n  \n2\n \n1\n \n0\n\n\n];\n\n\nF\n \n=\n \n[\n\n  \n1\n \n2\n \n3\n\n  \n2\n \n4\n \n3\n\n\n];\n\n\nLIJV\n \n=\n \n[\n\n\n1\n  \n1\n    \n-\n0.7071067811865476\n\n\n2\n  \n1\n     \n0.7071067811865475\n\n\n3\n  \n1\n  \n1.570092458683775e-16\n\n\n1\n  \n2\n     \n0.7071067811865475\n\n\n2\n  \n2\n     \n-\n1.638010440969447\n\n\n3\n  \n2\n     \n0.6422285251880865\n\n\n4\n  \n2\n     \n0.2886751345948129\n\n\n1\n  \n3\n  \n1.570092458683775e-16\n\n\n2\n  \n3\n     \n0.6422285251880865\n\n\n3\n  \n3\n    \n-\n0.9309036597828995\n\n\n4\n  \n3\n     \n0.2886751345948129\n\n\n2\n  \n4\n     \n0.2886751345948129\n\n\n3\n  \n4\n     \n0.2886751345948129\n\n\n4\n  \n4\n    \n-\n0.5773502691896258\n\n\n];\n\n\nL\n \n=\n \nsparse\n(\nLIJV\n(:,\n1\n),\nLIJV\n(:,\n2\n),\nLIJV\n(:,\n3\n));\n\n\n\n\n\nwhich is easily copied and pasted into Matlab for debugging, etc.\n\n\nCalling libigl functions from Matlab\n [callinglibiglfunctionsfrommatlab]\n\u00b6\n\n\nIt is also possible to call libigl functions from matlab, compiling them as MEX\nfunctions. This can be used to offload to C++ code the computationally\nintensive parts of a Matlab application.\n\n\nWe provide a wrapper for \nigl::readOBJ\n in \nExample 603\n.\nWe plan to provide wrappers for all our functions in the future, if you are\ninterested in this feature (or if you want to help implementing it) please let\nus know.\n\n\nTriangulation of closed polygons\n [triangulationofclosedpolygons]\n\u00b6\n\n\nThe generation of high-quality triangle and tetrahedral meshes is a very common\ntask in geometry processing. We provide wrappers in libigl to\n\ntriangle\n and\n\nTetgen\n.\n\n\nA triangle mesh with a given boundary can be created with:\n\n\nigl\n::\ntriangulate\n(\nV\n,\nE\n,\nH\n,\nV2\n,\nF2\n,\n\"a0.005q\"\n);\n\n\n\n\n\nwhere \nE\n is a set of boundary edges (#E by 2), \nH\n is a set of 2D positions of\npoints contained in holes of the triangulation (#H by 2) and (\nV2\n,\nF2\n) is the\ngenerated triangulation. Additional parameters can be passed to \ntriangle\n, to\ncontrol the quality: \n\"a0.005q\"\n enforces a bound on the maximal area of the\ntriangles and a minimal angle of 20 degrees. In \nExample\n604\n, the interior of a square (excluded a smaller square\nin its interior) is triangulated.\n\n\n\n\nTetrahedralization of closed surfaces\n [tetrahedralizationofclosedsurfaces]\n\u00b6\n\n\nSimilarly, the interior of a closed manifold surface can be tetrahedralized\nusing the function \nigl::tetrahedralize\n which wraps the Tetgen library (\nExample\n605\n):\n\n\nigl\n::\ntetrahedralize\n(\nV\n,\nF\n,\n\"pq1.414\"\n,\n \nTV\n,\nTT\n,\nTF\n);\n\n\n\n\n\n\n\nBaking ambient occlusion\n [bakingambientocclusion]\n\u00b6\n\n\nAmbient occlusion\n is a\nrendering technique used to calculate the exposure of each point in a surface\nto ambient lighting. It is usually encoded as a scalar (normalized between 0\nand 1) associated with the vertice of a mesh.\n\n\nFormally, ambient occlusion is defined as:\n\n\n\\[ A_p = \\frac{1}{\\pi} \\int_\\omega V_{p,\\omega}(n \\cdot \\omega) d\\omega \\]\n\n\nwhere \nV_{p,\\omega}\nV_{p,\\omega}\n is the visibility function at  p, defined to be zero if p\nis occluded in the direction \n\\omega\n\\omega\n and one otherwise, and \nd\\omega\nd\\omega\n is the\ninfinitesimal solid angle step of the integration variable \n\\omega\n\\omega\n.\n\n\nThe integral is usually approximated by casting rays in random directions\naround each vertex. This approximation can be computed using the function:\n\n\nigl\n::\nambient_occlusion\n(\nV\n,\nF\n,\nV_samples\n,\nN_samples\n,\n500\n,\nAO\n);\n\n\n\n\n\nthat given a scene described in \nV\n and \nF\n, computes the ambient occlusion of\nthe points in \nV_samples\n whose associated normals are \nN_samples\n. The\nnumber of casted rays can be controlled (usually at least 300-500 rays are\nrequired to get a smooth result) and the result is returned in \nAO\n, as a\nsingle scalar for each sample.\n\n\nAmbient occlusion can be used to darken the surface colors, as shown in\n\nExample 606\n\n\n\n\nScreen Capture\n [screencapture]\n\u00b6\n\n\nLibigl supports read and writing to .png files via the\n\nstb image\n code.\n\n\nWith the viewer used in this tutorial, it is possible to render the scene in a\nmemory buffer using the function, \nigl::opengl::ViewerCore::draw_buffer\n:\n\n\n// Allocate temporary buffers for 1280x800 image\n\n\nEigen\n::\nMatrix\n<\nunsigned\n \nchar\n,\nEigen\n::\nDynamic\n,\nEigen\n::\nDynamic\n>\n \nR\n(\n1280\n,\n800\n);\n\n\nEigen\n::\nMatrix\n<\nunsigned\n \nchar\n,\nEigen\n::\nDynamic\n,\nEigen\n::\nDynamic\n>\n \nG\n(\n1280\n,\n800\n);\n\n\nEigen\n::\nMatrix\n<\nunsigned\n \nchar\n,\nEigen\n::\nDynamic\n,\nEigen\n::\nDynamic\n>\n \nB\n(\n1280\n,\n800\n);\n\n\nEigen\n::\nMatrix\n<\nunsigned\n \nchar\n,\nEigen\n::\nDynamic\n,\nEigen\n::\nDynamic\n>\n \nA\n(\n1280\n,\n800\n);\n\n\n\n// Draw the scene in the buffers\n\n\nviewer\n.\ncore\n.\ndraw_buffer\n(\nviewer\n.\ndata\n,\nviewer\n.\nopengl\n,\nfalse\n,\nR\n,\nG\n,\nB\n,\nA\n);\n\n\n\n// Save it to a PNG\n\n\nigl\n::\npng\n::\nwritePNG\n(\nR\n,\nG\n,\nB\n,\nA\n,\n\"out.png\"\n);\n\n\n\n\n\nIn \nExample 607\n a scene is rendered in a temporary\npng and used to texture a quadrilateral.\n\n\nLocally Injective Maps\n [locallyinjectivemaps]\n\u00b6\n\n\nExtreme deformations or parametrizations with high-distortion might flip\nelements.  This is undesirable in many applications, and it is possible to\navoid it by introducing a non-linear constraints that guarantees that the area\nof every element remain positive.\n\n\nLibigl can be used to compute Locally Injective Maps [#schuller_2013][] using a variety of\ndeformation energies. A simple deformation of a 2D grid is computed in \nExample\n608\n.\n\n\n\n\nBoolean operations on meshes\n [booleanoperationsonmeshes]\n\u00b6\n\n\nConstructive solid geometry (CSG) is a technique to define a complex surface as\nthe result of a number of set operations on solid regions of space: union,\nintersection, set difference, symmetric difference, complement. Typically, CSG\nlibraries represent the inputs and outputs to these operations \nimplicitly\n:\nthe solid \nA\nA\n is defined as the open set of points \n\\mathbf{x}\n\\mathbf{x}\n for which some\nfunction \na(\\mathbf{x})\na(\\mathbf{x})\n \"returns true\". The surface of this shape is the\n\nclosure\n of all points \nx\nx\n in \nA\nA\n.\n\n\nWith this sort of representation, boolean\noperations are straightforward. For example, the union of solids \nA\nA\n and \nB\nB\n\nis simply\n\n\nA \\cup B = \\{\\mathbf{x} \\left.\\right|\n  a(\\mathbf{x}) \\text{ or } b(\\mathbf{x})\\},\nA \\cup B = \\{\\mathbf{x} \\left.\\right|\n  a(\\mathbf{x}) \\text{ or } b(\\mathbf{x})\\},\n\n\nthe intersection is\n\n\nA \\cap B = \\{\\mathbf{x} \\left.\\right|\n  a(\\mathbf{x}) \\text{ and } b(\\mathbf{x})\\},\nA \\cap B = \\{\\mathbf{x} \\left.\\right|\n  a(\\mathbf{x}) \\text{ and } b(\\mathbf{x})\\},\n\n\nthe difference \nA\nA\n \nminus\n \nB\nB\n is\n\n\nA \\setminus B = \\{\\mathbf{x} \\left.\\right|\n  a(\\mathbf{x}) \\text{ and _not_ } b(\\mathbf{x})\\},\nA \\setminus B = \\{\\mathbf{x} \\left.\\right|\n  a(\\mathbf{x}) \\text{ and _not_ } b(\\mathbf{x})\\},\n\n\nand the symmetric difference (XOR) is\n\n\nA \\triangle B = \\{\\mathbf{x} \\left.\\right|\n  \\text{either } a(\\mathbf{x}) \\text{ or } b(\\mathbf{x}) \\text{ but not both }\\}.\nA \\triangle B = \\{\\mathbf{x} \\left.\\right|\n  \\text{either } a(\\mathbf{x}) \\text{ or } b(\\mathbf{x}) \\text{ but not both }\\}.\n\n\nStringing together many of these operations, one can design quite complex\nshapes. A typical CSG library might only keep explicit \nbase-case\n\nrepresentations of canonical shapes: half-spaces, quadrics, etc.\n\n\nIn libigl, we do currently \nnot\n have an implicit surface representation.\nInstead we expect our users to be working with \nexplicit\n triangle mesh\n\nboundary representations\n of solid shapes. CSG operations are much hard to\ncompute robustly with boundary representations, but are nonetheless useful.\n\n\nTo compute a boolean operation on a triangle mesh with vertices \nVA\n and\ntriangles \nFA\n and another mesh \nVB\n and \nFB\n, libigl first computes a unified\n\"mesh arrangement\" (see [#zhou_2016][]) with vertices \nV\n and triangles \nF\n where all triangle-triangle\nintersections have been \"resolved\". That is, edges and vertices are added\nexactly at the intersection lines, so the resulting \nnon-manifold\n mesh \n(V,F)\n\nhas no self-intersections.\n\n\nThen libigl labels each \"cell\" bounded by surfaces of the arrangement according\nto its \nwinding number vector\n: winding number with respect to each input mesh\n\n(w_A,w_B)\n(w_A,w_B)\n. Finally, according to the desired operation (e.g. union,\nintersection) the boundary of the corresponding cells are extracted.\n\n\nCalling libigl's boolean operations is simple. To compute the union of\n\n(VA,FA)\n and \n(VB,FB)\n into a new mesh \n(VC,FC)\n, use:\n\n\nigl\n::\ncopyleft\n::\ncgal\n::\nmesh_boolean\n(\nVA\n,\nFA\n,\nVB\n,\nFB\n,\nMESH_BOOLEAN_TYPE_UNION\n,\nVC\n,\nFC\n);\n\n\n\n\n\nThe following figure shows each boolean operation on two meshes.\n\n\n\n\nThe union, symmetric difference and \"resolve\" have the same outward\nappearance, but differ in their treatment of internal structures. The union has\nno internal surfaces: the triangles are not included in the output. The\nsymmetric difference is the same set of triangles as the \"resolve\", but\ninternal surfaces have been reversed in orientation, indicating that the solid\nresult of the operation. The \"resolve\" operation is not really a boolean\noperation, it is simply the result of resolving all intersections and gluing\ntogether coincident vertices, maintaining original triangle orientations.\n\n\nLibigl also provides a wrapper \nigl::copyleft::cork::mesh_boolean\n to the\n\ncork\n, which is typically faster, but is not\nalways robust.\n\n\nCSG Tree\n [csgtree]\n\u00b6\n\n\nThe \nprevious section\n discusses using\n\nigl::copyleft::cgal::mesh_boolean\n to compute the result of a \nsingle\n boolean\noperation on two input triangle meshes. When employing constructive solid\ngeometry (CSG) as a modeling paradigm, shapes are represented as the result of\nmany such binary operations. The sequence is stored in a binary tree.\n\n\nLibigl uses exact arithmetic internally to construct the intermediary boolean\nresults robustly. \"Rounding\" this result to floating point (even double\nprecision) would cause problems if re-injected into a further boolean\noperation. To facilitate CSG tree operations and encourage callers \nnot\n to\ncall \nigl::copyleft::cgal::mesh_boolean\n multiple times explicitly, libigl implements\na class \nigl::copyleft::cgal::CSGTree\n. Leaf nodes of this class are simply \"solid\"\nmeshes (otherwise good input to \nigl::copyleft::cgal::mesh_boolean\n). Interior nodes\nof the tree combine two children with a boolean operation. Using the intializer\nlist constructor it is easy to hard-code specific tree constructions. Here's an\nexample taking the \nintersection\n of a cube A and sphere B \nminus\n the \nunion\n\nof three cylinders:\n\n\n// Compute result of (A \u2229 B) \\ ((C \u222a D) \u222a E)\n\n\nigl\n::\ncopyleft\n::\ncgal\n::\nCSGTree\n<\nMatrixXi\n>\n \nCSGTree\n \n=\n\n  \n{{{\nVA\n,\nFA\n},{\nVB\n,\nFB\n},\n\"i\"\n},{{{\nVC\n,\nFC\n},{\nVD\n,\nFD\n},\n\"u\"\n},{\nVE\n,\nFE\n},\n\"u\"\n},\n\"m\"\n};\n\n\n\n\n\n\n\nExample \n610\n computes each intermediary CSG result and\nthen the final composite.",
            "title": "Chapter 6: External libraries"
        },
        {
            "location": "/tutorial/chapter-6/#chapter-6-external-libraries-chapter6externallibraries",
            "text": "An additional positive side effect of using matrices as basic types is that it\nis easy to exchange data between libigl and other software and libraries.",
            "title": "Chapter 6: External libraries [chapter6:externallibraries]"
        },
        {
            "location": "/tutorial/chapter-6/#state-serialization-stateserialization",
            "text": "Geometry processing applications often require a considerable amount of\ncomputational time and/or manual input. Serializing the state of the application\nis a simple strategy to greatly increase the development efficiency. It allows\nto quickly start debugging just before the crash happens, avoiding to wait for\nthe precomputation to take place every time and it also makes your experiments\nreproducible, allowing to quickly test algorithms variants on the same input\ndata.  Serialization is often not considered in geometry processing due to the extreme\ndifficulty in serializing pointer-based data structured, such as an half-edge\ndata structure ( OpenMesh ,  CGAL ),\nor a pointer based indexed structure\n( VCG ).  In libigl, serialization is much simpler, since the majority of the functions\nuse basic types, and pointers are used in very rare cases (usually to interface\nwith external libraries). Libigl bundles a simple and self-contained binary and\nXML serialization framework, that drastically reduces the overhead required to\nadd serialization to your applications.  To de-/serialize a set of variables use the following method:  #include   \"igl/serialize.h\"  bool   b   =   true ;  unsigned   int   num   =   10 ;  std :: vector < float >   vec   =   { 0.1 , 0.002 , 5.3 };  // use overwrite = true for the first serialization to create or overwrite an  // existing file  igl :: serialize ( b , \"B\" , \"filename\" , true );  // append following serialization to existing file  igl :: serialize ( num , \"Number\" , \"filename\" );  igl :: serialize ( vec , \"VectorName\" , \"filename\" );  // deserialize back to variables  igl :: deserialize ( b , \"B\" , \"filename\" );  igl :: deserialize ( num , \"Number\" , \"filename\" );  igl :: deserialize ( vec , \"VectorName\" , \"filename\" );   Currently all fundamental data types (bool, int, float, double, ...) are\nsupported, as well as std::string, basic  STL  containers, dense and sparse\nEigen matrices and nestings of those.  Some limitations apply to pointers.\nCurrently, loops or many to one type of link structures are not handled\ncorrectly. Each pointer is assumed to point to a different independent object.\nUninitialized pointers must be set to  nullptr  before de-/serialization to\navoid memory leaks. Cross-platform issues like little-, big-endianess is\ncurrently not supported.  To make user defined types serializable, just derive\nfrom  igl::Serializable  and trivially implementing the  InitSerialization \nmethod.  Assume that the state of your application is a mesh and a set of integer ids:  #include   \"igl/serialize.h\"  struct   State   :   public   igl :: Serializable  { \n   Eigen :: MatrixXd   V ; \n   Eigen :: MatrixXi   F ; \n   std :: vector < int >   ids ; \n\n   void   InitSerialization () \n   { \n     this -> Add ( V    ,   \"V\" ); \n     this -> Add ( F    ,   \"F\" ); \n     this -> Add ( ids ,   \"ids\" ); \n   }  };   If you need more control over the serialization of your types, you can override\nthe following functions or directly inherit from the interface igl::SerializableBase .  bool   Serializable :: PreSerialization ()   const ;  void   Serializable :: PostSerialization ()   const ;  bool   Serializable :: PreDeserialization ();  void   Serializable :: PostDeserialization ();   Alternatively, if you want a non-intrusive way of serializing your state you can\noverload the following functions:  namespace   igl  { \n   namespace   serialization \n   { \n     template   <>   inline   void   serialize ( const   State &   obj , std :: vector < char >&   buffer ) \n     { \n       :: igl :: serialize ( obj . V , std :: string ( \"V\" ), buffer ); \n       :: igl :: serialize ( obj . F , std :: string ( \"F\" ), buffer ); \n       :: igl :: serialize ( obj . ids , std :: string ( \"ids\" ), buffer ); \n     } \n     template   <>   inline   void   deserialize ( State &   obj , const   std :: vector < char >&   buffer ) \n     { \n       :: igl :: deserialize ( obj . V , std :: string ( \"V\" ), buffer ); \n       :: igl :: deserialize ( obj . F , std :: string ( \"F\" ), buffer ); \n       :: igl :: deserialize ( obj . ids , std :: string ( \"ids\" ), buffer ); \n     } \n   }  }   Equivalently, you can use the following macros:  SERIALIZE_TYPE ( State , \n  SERIALIZE_MEMBER ( V ) \n  SERIALIZE_MEMBER ( F ) \n  SERIALIZE_MEMBER_NAME ( ids , \"ids\" )  )   All the former code is for binary serialization which is especially useful if\nyou have to handle larger data where the loading and saving times become more\nimportant.  For cases where you want to read and edit the serialized data by\nhand we provide a serialization to XML files which is based on the library tinyxml2 .  There you also have the\noption to create a partial binary serialization of your data by using the binary\nparameter, exposed in the function  serialize_xml() :  #include   \"igl/xml/serialize_xml.h\"  int   number ;  // binary = false, overwrite = true  igl :: serialize_xml ( vec , \"VectorXML\" , xmlFile , false , true );  // binary = true, overwrite = true  igl :: serialize_xml ( vec , \"VectorBin\" , xmlFile , true , true );  igl :: deserialize_xml ( vec , \"VectorXML\" , xmlFile );  igl :: deserialize_xml ( vec , \"VectorBin\" , xmlFile );   For user defined types derive from  XMLSerializable .  The code snippets above are extracted from  Example\n601 . We strongly suggest that you make the entire\nstate of your application always serializable since it will save you a lot of\ntroubles when you will be preparing figures for a scientific report. It is very\ncommon to have to do small changes to figures, and being able to serialize the\nentire state just before you take screenshots will save you many painful hours\nbefore a submission deadline.",
            "title": "State serialization [stateserialization]"
        },
        {
            "location": "/tutorial/chapter-6/#mixing-matlab-code-mixingmatlabcode",
            "text": "Libigl can be interfaced with Matlab to offload numerically heavy computation\nto a Matlab script. The major advantage of this approach is that you will be\nable to develop efficient and complex user-interfaces in C++, while exploring\nthe syntax and fast protototyping features of matlab. In particular, the use of\nan external Matlab script in a libigl application allows to change the Matlab\ncode while the C++ application is running, greatly increasing coding\nefficiency.  We demonstrate how to integrate Matlab in a libigl application in  Example\n602 . The example uses Matlab to compute the\nEigenfunctions of the discrete Laplacian operator, relying on libigl for mesh\nIO, visualization and for computing the Laplacian operator.  Libigl can connect to an existing instance of Matlab (or launching a new one on\nLinux/MacOSX) using:  igl :: mlinit ( & engine );   The cotangent Laplacian is computed using igl::cotmatrix and uploaded to the\nMatlab workspace:  igl :: cotmatrix ( V , F , L );  igl :: mlsetmatrix ( & engine , \"L\" , L );   It is now possible to use any Matlab function on the data. For example, we can\nsee the sparsity pattern of L using spy:  igl :: mleval ( & engine , \"spy(L)\" );    The results of Matlab computations can be returned back to the C++ application  igl :: mleval ( & engine , \"[EV,~] = eigs(-L,10,'sm')\" );  igl :: mlgetmatrix ( & engine , \"EV\" , EV );   and plotted using the libigl viewer.",
            "title": "Mixing Matlab code [mixingmatlabcode]"
        },
        {
            "location": "/tutorial/chapter-6/#saving-a-matlab-workspace",
            "text": "To aid debugging, libigl also supplies functions to write Matlab  .mat \n\"Workspaces\". This C++ snippet saves a mesh and it's sparse Laplacian matrix to\na file:  igl :: readOFF ( TUTORIAL_SHARED_PATH   \"/fertility.off\" ,   V ,   F );  igl :: cotmatrix ( V , F , L );  igl :: MatlabWorkspace   mw ;  mw . save ( V , \"V\" );  mw . save_index ( F , \"F\" );  mw . save ( L , \"L\" );  mw . write ( \"fertility.mat\" );   Then this workspace can be loaded into a Matlab IDE:  load   fertility . mat   The  igl::MatlabWorkspace  depends on Matlab libraries to compile and run,\nbut---in contrast to the engine routines above---will avoid launching a Matlab\ninstance upon execution.",
            "title": "Saving a Matlab workspace"
        },
        {
            "location": "/tutorial/chapter-6/#dumping-eigen-matrices-to-copy-and-paste-into-matlab",
            "text": "Eigen supplies a sophisticated API for printing its matrix types to the screen.\nLibigl has wrapped up a particularly useful formatting which makes it simple to\ncopy standard output from a C++ program into a Matlab IDE. The code:  igl :: readOFF ( TUTORIAL_SHARED_PATH   \"/2triangles.off\" ,   V ,   F );  igl :: cotmatrix ( V , F , L );  std :: cout << igl :: matlab_format ( V , \"V\" ) << std :: endl ;  std :: cout << igl :: matlab_format (( F . array () + 1 ). eval (), \"F\" ) << std :: endl ;  std :: cout << igl :: matlab_format ( L , \"L\" ) << std :: endl ;   produces the output:  V   =   [ \n   0   0   0 \n   1   0   0 \n   1   1   1 \n   2   1   0  ];  F   =   [ \n   1   2   3 \n   2   4   3  ];  LIJV   =   [  1    1      - 0.7071067811865476  2    1       0.7071067811865475  3    1    1.570092458683775e-16  1    2       0.7071067811865475  2    2       - 1.638010440969447  3    2       0.6422285251880865  4    2       0.2886751345948129  1    3    1.570092458683775e-16  2    3       0.6422285251880865  3    3      - 0.9309036597828995  4    3       0.2886751345948129  2    4       0.2886751345948129  3    4       0.2886751345948129  4    4      - 0.5773502691896258  ];  L   =   sparse ( LIJV (:, 1 ), LIJV (:, 2 ), LIJV (:, 3 ));   which is easily copied and pasted into Matlab for debugging, etc.",
            "title": "Dumping Eigen matrices to copy and paste into Matlab"
        },
        {
            "location": "/tutorial/chapter-6/#calling-libigl-functions-from-matlab-callinglibiglfunctionsfrommatlab",
            "text": "It is also possible to call libigl functions from matlab, compiling them as MEX\nfunctions. This can be used to offload to C++ code the computationally\nintensive parts of a Matlab application.  We provide a wrapper for  igl::readOBJ  in  Example 603 .\nWe plan to provide wrappers for all our functions in the future, if you are\ninterested in this feature (or if you want to help implementing it) please let\nus know.",
            "title": "Calling libigl functions from Matlab [callinglibiglfunctionsfrommatlab]"
        },
        {
            "location": "/tutorial/chapter-6/#triangulation-of-closed-polygons-triangulationofclosedpolygons",
            "text": "The generation of high-quality triangle and tetrahedral meshes is a very common\ntask in geometry processing. We provide wrappers in libigl to triangle  and Tetgen .  A triangle mesh with a given boundary can be created with:  igl :: triangulate ( V , E , H , V2 , F2 , \"a0.005q\" );   where  E  is a set of boundary edges (#E by 2),  H  is a set of 2D positions of\npoints contained in holes of the triangulation (#H by 2) and ( V2 , F2 ) is the\ngenerated triangulation. Additional parameters can be passed to  triangle , to\ncontrol the quality:  \"a0.005q\"  enforces a bound on the maximal area of the\ntriangles and a minimal angle of 20 degrees. In  Example\n604 , the interior of a square (excluded a smaller square\nin its interior) is triangulated.",
            "title": "Triangulation of closed polygons [triangulationofclosedpolygons]"
        },
        {
            "location": "/tutorial/chapter-6/#tetrahedralization-of-closed-surfaces-tetrahedralizationofclosedsurfaces",
            "text": "Similarly, the interior of a closed manifold surface can be tetrahedralized\nusing the function  igl::tetrahedralize  which wraps the Tetgen library ( Example\n605 ):  igl :: tetrahedralize ( V , F , \"pq1.414\" ,   TV , TT , TF );",
            "title": "Tetrahedralization of closed surfaces [tetrahedralizationofclosedsurfaces]"
        },
        {
            "location": "/tutorial/chapter-6/#baking-ambient-occlusion-bakingambientocclusion",
            "text": "Ambient occlusion  is a\nrendering technique used to calculate the exposure of each point in a surface\nto ambient lighting. It is usually encoded as a scalar (normalized between 0\nand 1) associated with the vertice of a mesh.  Formally, ambient occlusion is defined as:  \\[ A_p = \\frac{1}{\\pi} \\int_\\omega V_{p,\\omega}(n \\cdot \\omega) d\\omega \\]  where  V_{p,\\omega} V_{p,\\omega}  is the visibility function at  p, defined to be zero if p\nis occluded in the direction  \\omega \\omega  and one otherwise, and  d\\omega d\\omega  is the\ninfinitesimal solid angle step of the integration variable  \\omega \\omega .  The integral is usually approximated by casting rays in random directions\naround each vertex. This approximation can be computed using the function:  igl :: ambient_occlusion ( V , F , V_samples , N_samples , 500 , AO );   that given a scene described in  V  and  F , computes the ambient occlusion of\nthe points in  V_samples  whose associated normals are  N_samples . The\nnumber of casted rays can be controlled (usually at least 300-500 rays are\nrequired to get a smooth result) and the result is returned in  AO , as a\nsingle scalar for each sample.  Ambient occlusion can be used to darken the surface colors, as shown in Example 606",
            "title": "Baking ambient occlusion [bakingambientocclusion]"
        },
        {
            "location": "/tutorial/chapter-6/#screen-capture-screencapture",
            "text": "Libigl supports read and writing to .png files via the stb image  code.  With the viewer used in this tutorial, it is possible to render the scene in a\nmemory buffer using the function,  igl::opengl::ViewerCore::draw_buffer :  // Allocate temporary buffers for 1280x800 image  Eigen :: Matrix < unsigned   char , Eigen :: Dynamic , Eigen :: Dynamic >   R ( 1280 , 800 );  Eigen :: Matrix < unsigned   char , Eigen :: Dynamic , Eigen :: Dynamic >   G ( 1280 , 800 );  Eigen :: Matrix < unsigned   char , Eigen :: Dynamic , Eigen :: Dynamic >   B ( 1280 , 800 );  Eigen :: Matrix < unsigned   char , Eigen :: Dynamic , Eigen :: Dynamic >   A ( 1280 , 800 );  // Draw the scene in the buffers  viewer . core . draw_buffer ( viewer . data , viewer . opengl , false , R , G , B , A );  // Save it to a PNG  igl :: png :: writePNG ( R , G , B , A , \"out.png\" );   In  Example 607  a scene is rendered in a temporary\npng and used to texture a quadrilateral.",
            "title": "Screen Capture [screencapture]"
        },
        {
            "location": "/tutorial/chapter-6/#locally-injective-maps-locallyinjectivemaps",
            "text": "Extreme deformations or parametrizations with high-distortion might flip\nelements.  This is undesirable in many applications, and it is possible to\navoid it by introducing a non-linear constraints that guarantees that the area\nof every element remain positive.  Libigl can be used to compute Locally Injective Maps [#schuller_2013][] using a variety of\ndeformation energies. A simple deformation of a 2D grid is computed in  Example\n608 .",
            "title": "Locally Injective Maps [locallyinjectivemaps]"
        },
        {
            "location": "/tutorial/chapter-6/#boolean-operations-on-meshes-booleanoperationsonmeshes",
            "text": "Constructive solid geometry (CSG) is a technique to define a complex surface as\nthe result of a number of set operations on solid regions of space: union,\nintersection, set difference, symmetric difference, complement. Typically, CSG\nlibraries represent the inputs and outputs to these operations  implicitly :\nthe solid  A A  is defined as the open set of points  \\mathbf{x} \\mathbf{x}  for which some\nfunction  a(\\mathbf{x}) a(\\mathbf{x})  \"returns true\". The surface of this shape is the closure  of all points  x x  in  A A .  With this sort of representation, boolean\noperations are straightforward. For example, the union of solids  A A  and  B B \nis simply  A \\cup B = \\{\\mathbf{x} \\left.\\right|\n  a(\\mathbf{x}) \\text{ or } b(\\mathbf{x})\\}, A \\cup B = \\{\\mathbf{x} \\left.\\right|\n  a(\\mathbf{x}) \\text{ or } b(\\mathbf{x})\\},  the intersection is  A \\cap B = \\{\\mathbf{x} \\left.\\right|\n  a(\\mathbf{x}) \\text{ and } b(\\mathbf{x})\\}, A \\cap B = \\{\\mathbf{x} \\left.\\right|\n  a(\\mathbf{x}) \\text{ and } b(\\mathbf{x})\\},  the difference  A A   minus   B B  is  A \\setminus B = \\{\\mathbf{x} \\left.\\right|\n  a(\\mathbf{x}) \\text{ and _not_ } b(\\mathbf{x})\\}, A \\setminus B = \\{\\mathbf{x} \\left.\\right|\n  a(\\mathbf{x}) \\text{ and _not_ } b(\\mathbf{x})\\},  and the symmetric difference (XOR) is  A \\triangle B = \\{\\mathbf{x} \\left.\\right|\n  \\text{either } a(\\mathbf{x}) \\text{ or } b(\\mathbf{x}) \\text{ but not both }\\}. A \\triangle B = \\{\\mathbf{x} \\left.\\right|\n  \\text{either } a(\\mathbf{x}) \\text{ or } b(\\mathbf{x}) \\text{ but not both }\\}.  Stringing together many of these operations, one can design quite complex\nshapes. A typical CSG library might only keep explicit  base-case \nrepresentations of canonical shapes: half-spaces, quadrics, etc.  In libigl, we do currently  not  have an implicit surface representation.\nInstead we expect our users to be working with  explicit  triangle mesh boundary representations  of solid shapes. CSG operations are much hard to\ncompute robustly with boundary representations, but are nonetheless useful.  To compute a boolean operation on a triangle mesh with vertices  VA  and\ntriangles  FA  and another mesh  VB  and  FB , libigl first computes a unified\n\"mesh arrangement\" (see [#zhou_2016][]) with vertices  V  and triangles  F  where all triangle-triangle\nintersections have been \"resolved\". That is, edges and vertices are added\nexactly at the intersection lines, so the resulting  non-manifold  mesh  (V,F) \nhas no self-intersections.  Then libigl labels each \"cell\" bounded by surfaces of the arrangement according\nto its  winding number vector : winding number with respect to each input mesh (w_A,w_B) (w_A,w_B) . Finally, according to the desired operation (e.g. union,\nintersection) the boundary of the corresponding cells are extracted.  Calling libigl's boolean operations is simple. To compute the union of (VA,FA)  and  (VB,FB)  into a new mesh  (VC,FC) , use:  igl :: copyleft :: cgal :: mesh_boolean ( VA , FA , VB , FB , MESH_BOOLEAN_TYPE_UNION , VC , FC );   The following figure shows each boolean operation on two meshes.   The union, symmetric difference and \"resolve\" have the same outward\nappearance, but differ in their treatment of internal structures. The union has\nno internal surfaces: the triangles are not included in the output. The\nsymmetric difference is the same set of triangles as the \"resolve\", but\ninternal surfaces have been reversed in orientation, indicating that the solid\nresult of the operation. The \"resolve\" operation is not really a boolean\noperation, it is simply the result of resolving all intersections and gluing\ntogether coincident vertices, maintaining original triangle orientations.  Libigl also provides a wrapper  igl::copyleft::cork::mesh_boolean  to the cork , which is typically faster, but is not\nalways robust.",
            "title": "Boolean operations on meshes [booleanoperationsonmeshes]"
        },
        {
            "location": "/tutorial/chapter-6/#csg-tree-csgtree",
            "text": "The  previous section  discusses using igl::copyleft::cgal::mesh_boolean  to compute the result of a  single  boolean\noperation on two input triangle meshes. When employing constructive solid\ngeometry (CSG) as a modeling paradigm, shapes are represented as the result of\nmany such binary operations. The sequence is stored in a binary tree.  Libigl uses exact arithmetic internally to construct the intermediary boolean\nresults robustly. \"Rounding\" this result to floating point (even double\nprecision) would cause problems if re-injected into a further boolean\noperation. To facilitate CSG tree operations and encourage callers  not  to\ncall  igl::copyleft::cgal::mesh_boolean  multiple times explicitly, libigl implements\na class  igl::copyleft::cgal::CSGTree . Leaf nodes of this class are simply \"solid\"\nmeshes (otherwise good input to  igl::copyleft::cgal::mesh_boolean ). Interior nodes\nof the tree combine two children with a boolean operation. Using the intializer\nlist constructor it is easy to hard-code specific tree constructions. Here's an\nexample taking the  intersection  of a cube A and sphere B  minus  the  union \nof three cylinders:  // Compute result of (A \u2229 B) \\ ((C \u222a D) \u222a E)  igl :: copyleft :: cgal :: CSGTree < MatrixXi >   CSGTree   = \n   {{{ VA , FA },{ VB , FB }, \"i\" },{{{ VC , FC },{ VD , FD }, \"u\" },{ VE , FE }, \"u\" }, \"m\" };    Example  610  computes each intermediary CSG result and\nthen the final composite.",
            "title": "CSG Tree [csgtree]"
        },
        {
            "location": "/tutorial/chapter-7/",
            "text": "Miscellaneous [chapter7:miscellaneous]\n\u00b6\n\n\nLibigl contains a \nwide\n variety of geometry processing tools and functions for\ndealing with meshes and the linear algebra related to them: far too many to\ndiscuss in this introductory tutorial. We've pulled out a couple of the\ninteresting functions in this chapter to highlight.\n\n\nMesh Statistics\n [meshstatistics]\n\u00b6\n\n\nLibigl contains various mesh statistics, including face angles, face areas and\nthe detection of singular vertices, which are vertices with more or less than 6\nneighbours in triangulations or 4 in quadrangulations.\n\n\nThe example \nStatistics\n computes these quantities and\ndoes a basic statistic analysis that allows to estimate the isometry and\nregularity of a mesh:\n\n\nIrregular vertices:\n\n136\n/2400 \n(\n5\n.67%\n)\n\nAreas \n(\nMin/Max\n)\n/Avg_Area Sigma:\n\n0\n.01/5.33 \n(\n0\n.87\n)\n\nAngles in degrees \n(\nMin/Max\n)\n Sigma:\n\n17\n.21/171.79 \n(\n15\n.36\n)\n\n\n\n\n\nThe first row contains the number and percentage of irregular vertices, which\nis particularly important for quadrilateral meshes when they are used to define\nsubdivision surfaces: every singular point will result in a point of the\nsurface that is only C^1.\n\n\nThe second row reports the area of the minimal element, maximal element and the\nstandard deviation.  These numbers are normalized by the mean area, so in the\nexample above 5.33 max area means that the biggest face is 5 times larger than\nthe average face. An ideal isotropic mesh would have both min and max area\nclose to 1.\n\n\nThe third row measures the face angles, which should be close to 60 degrees (90\nfor quads) in a perfectly regular triangulation. For FEM purposes, the closer\nthe angles are to 60 degrees the more stable will the optimization be. In this\ncase, it is clear that the mesh is of bad quality and it will probably result\nin artifacts if used for solving PDEs.\n\n\nGeneralized Winding Number\n [generalizedwindingnumber]\n\u00b6\n\n\nThe problem of tetrahedralizing the interior of closed watertight surface mesh\nis a difficult, but well-posed problem (see our [Tetgen wrappers][tetrahedralizationofclosedsurfaces]).  But\nblack-box tet-meshers like TetGen will \nrefuse\n input triangle meshes with\nself-intersections, open boundaries, non-manifold edges from multiple connected\ncomponents.\nThe problem is two-fold: self-intersections present contradictory facet\nconstraints and self-intersections/open-boundaries/non-manifold edges make the\nproblem of determining inside from outside ill-posed without further\nassumptions.\n\n\nThe first problem is \neasily\n solved by \"resolving\" all self-intersections.\nThat is, meshing intersecting triangles so that intersects occur exactly at\nedges and vertices. This is accomplished using \nigl::selfintersect\n.\n\n\nTetGen can usually tetrahedralize the convex hull of this \"resolved\" mesh, and\nthen the problem becomes determining which of these tets are \ninside\n the input\nmesh and which are outside. That is, which should be kept and which should be\nremoved.\n\n\nThe \"Generalized Winding Number\" is a robust method for determined\ninside and outside for troublesome meshes [#jacobson_2013][].  The generalized\nwinding number with respect to \n(V,F)\n at some point \n\\mathbf{p} \\in\n\\mathcal{R}^3\n\\mathbf{p} \\in\n\\mathcal{R}^3\n is defined as scalar function:\n\n\nw(\\mathbf{p}) = \\sum\\limits_{f_i\\in F} \\frac{1}{4\\pi}\\Omega_{f_i}(\\mathbf{p})\nw(\\mathbf{p}) = \\sum\\limits_{f_i\\in F} \\frac{1}{4\\pi}\\Omega_{f_i}(\\mathbf{p})\n<span><span class=\"MathJax_Preview\">w(\\mathbf{p}) = \\sum\\limits_{f_i\\in F} \\frac{1}{4\\pi}\\Omega_{f_i}(\\mathbf{p})</span><script type=\"math/tex\">w(\\mathbf{p}) = \\sum\\limits_{f_i\\in F} \\frac{1}{4\\pi}\\Omega_{f_i}(\\mathbf{p})\n\n\nwhere \n\\Omega_{f_i}\n\\Omega_{f_i}\n is the \nsolid angle\n subtended by \nf_i\nf_i\n (the ith face in\n\nF\n) at the point \n\\mathbf{p}\n\\mathbf{p}\n. This solid angle contribution is a simple,\nclosed-form expression involving \natan2\n and some dot-products.\n\n\nIf \n(V,F)\n \ndoes\n form a closed watertight surface, then \nw(\\mathbf{p})=1\nw(\\mathbf{p})=1\n if\n\n\\mathbf{p}\n\\mathbf{p}\n lies inside \n(V,F)\n and \nw(\\mathbf{p})=0\nw(\\mathbf{p})=0\n if outside \n(V,F)\n.  If\n\n(V,F)\n is closed but overlaps itself then \nw(\\mathbf{p})\nw(\\mathbf{p})\n is an integer value\ncounting how many (signed) times \n(V,F)\n \nwraps\n around \n\\mathbf{p}\n\\mathbf{p}\n.  Finally,\nif \n(V,F)\n is not closed or not even manifold (but at least consistently\noriented), then \nw(\\mathbf{p})\nw(\\mathbf{p})\n tends smoothly toward 1 as \n\\mathbf{p}\n\\mathbf{p}\n is\n\nmore\n inside \n(V,F)\n, and toward 0 as \n\\mathbf{p}\n\\mathbf{p}\n is more outside.\n\n\n\n\nMesh Decimation\n [meshdecimation]\n\u00b6\n\n\nThe study of mesh simplification or \ndecimation\n is nearly as old as meshes\nthemselves. Given a high resolution mesh with too many triangles, find a \"well\napproximating\" low resolution mesh with far fewer triangles. By now there are a\nvariety of different paradigms for solving this problem and state-of-the-art\nmethods are fairly advanced.\n\n\nOne family of mesh decimation methods operates by successively remove elements\nfrom the mesh. In particular, Hoppe advocates for successively remove or rather\ncollapsing edges [#hoppe_1996][]. The generic form of this technique is to\nconstruct a sequence of n meshes from the initial high-resolution mesh \nM_0\nM_0\n to\nthe lowest resolution mesh \nM_n\nM_n\n by collapsing a single edge:\n\n\nM_0 \\mathop{\\longrightarrow}_\\text{edge collapse}\n  M_1 \\mathop{\\longrightarrow}_\\text{edge collapse}\n  \\dots \\mathop{\\longrightarrow}_\\text{edge collapse}\n  M_{n-1} \\mathop{\\longrightarrow}_\\text{edge collapse} M_n.\nM_0 \\mathop{\\longrightarrow}_\\text{edge collapse}\n  M_1 \\mathop{\\longrightarrow}_\\text{edge collapse}\n  \\dots \\mathop{\\longrightarrow}_\\text{edge collapse}\n  M_{n-1} \\mathop{\\longrightarrow}_\\text{edge collapse} M_n.\n\n\nHoppe's original method and subsequent follow-up works propose various ways to\nchoose the next edge to collapse in this sequence. Using a cost-based paradigm,\none can maintain a priority queue of edges based on their \"cost\" (how much\n\"worse\" will my approximation be if I remove this edge?). The cheapest edge is\ncollapsed and costs of neighboring edges are updated.\n\n\nIn order to maintain the topology (e.g. if the mesh is combinatorially as\nsphere or a torus etc.), one should assign infinite cost to edges whose\ncollapse would alter the mesh topology. Indeed this happens if and only if the\nnumber of mutual neighbors of the endpoints of the collapsing edge is not\nexactly two!\n\n\nIf there exists a third shared vertex, then another face will be removed, but 2\nedges will be removed. This can result in unwanted holes or non-manifold\n\"flaps\".\n\n\n\n\n\n\nThere is also a one-off condition that no edges of a tetrahedron should be\ncollapsed.\n\n\n\n\nBecause libigl (purposefully) does not center its implementations around a\ndynamic mesh data structure (e.g. half-edge datastructure), support for\ntopology changes are limited. Nonetheless, libigl has support for isolated edge\ncollapses, sequences of edge-collapses (each in O(log) time) and priority queue\nbased decimation.\n\n\nThe simplest is \nigl::decimation\n. By calling\n\n\nigl\n::\ndecimate\n(\nV\n,\nF\n,\n1000\n,\nU\n,\nG\n);\n\n\n\n\n\nthe mesh \n(V,F)\n will be decimated to a new mesh \n(U,G)\n so that \nG\n has at\nmost \n1000\n faces. This uses default (naive) criteria for determining the cost\nof an edge collapse and the placement of the merged vertex. Shortest edges are\ncollapsed first, and merged vertices are placed at edge midpoints.\n\n\nOne can also provide function handles (\nc++\n lambda functions are convenient\nhere) \ncost_and_placement\n and \nstopping_condition\n for determining the\ncost/placement of an edge collapse and the stopping condition respectively. For\nexample, the default version above is implemented as:\n\n\nigl\n::\ndecimate\n(\nV\n,\nF\n,\nshortest_edge_and_midpoint\n,\nmax_m\n,\nU\n,\nG\n);\n\n\n\n\n\nwhere \nshortest_edge_and_midpoint\n assign the edge's length as cost and its\nmidpoint as the merged vertex placement and \nmax_m\n counts the current number\nof faces (valid collapses decrease count by 2) and returns \ntrue\n if the count\ndrops below \nm=1000\n.\n\n\nOne can also scratch deeper inside the decimation loop and call\n\nigl::collapse_edge\n directly. In order to operate efficiently, this routine\nneeds more than the usual \n(V,F)\n mesh representation. We need \nE\n a list of\nedge indices, where \nE.row(i) --> [s,d]\n; we need \nEMAP\n which maps the\n\"half\"-edges of each triangle in \nF\n to its corresponding edge in \nE\n so that\n\nE.row(EMAP(f+i*F.rows)) --> [s,d]\n if the edge across from the ith corner of the\nfth face is \n[s,d]\n (up to orientation); we need \nEF\n and \nEI\n which keep track\nof the faces incident on each edge and across from which corner of those faces\nthe edges appears, so that \nEF(e,o) = f\n and \nEI(e,o) = i\n means that the edge\n\nE.row(e) --> [s,d]\n appears in the fth face across from its ith corner (for\n\no=0\n the edge orientations should match, for \no=1\n the orientations are\nopposite).\n\n\nWhen a collapse occurs, the sizes of the \nF\n,\nE\n, etc. matrices do not change.\nRather rows corresponding to \"removed\" faces and edges are set to a special\nconstant value \nIGL_COLLAPSE_EDGE_NULL\n. Doing this ensures that we're able to\nremove edges in truly constant time O(1).\n\n\n\n\nConveniently \nIGL_COLLAPSE_EDGE_NULL==0\n. This means most OPENGL style renderings of \nF\n\nwill simply draw a bunch of 0-area triangles at the first vertex.\n\n\n\n\nThe following will collapse the first\nedge and place its merged vertex at the origin:\n\n\nigl\n::\ncollapse_edge\n(\n0\n,\nRowVector3d\n(\n0\n,\n0\n,\n0\n),\nV\n,\nF\n,\nE\n,\nEMAP\n,\nEF\n,\nEI\n);\n\n\n\nIf valid, then \nV\n,\nF\n,\nE\n,\nEF\n,\nEI\n are adjusted accordingly.\n\n\nThis is powerful, but low level. To build a decimator around this you'd need to\nkeep track which edges are left to collapse and which to collapse next.\nFortunately, libigl also exposes a priority queue based edge collapse with\nfunction handles to adjust costs and placements.\n\n\nThe priority queue is implemented as a (ordered) set \nQ\n or (cost,edge index)\npairs and a list of iterators \nQit\n so that \nQit[e]\n reveals the iterator in\n\nQ\n corresponding to the eth edge. Placements are stored in a #E list of\npositions \nC\n. When the following is called:\n\n\nigl\n::\ncollapse_edge\n(\ncost_and_placement\n,\nV\n,\nF\n,\nE\n,\nEMAP\n,\nEF\n,\nEI\n,\nQ\n,\nQit\n,\nC\n);\n\n\n\n\n\nthe lowest cost edge collapse according to \nQ\n is attempted. If valid, then\n\nV\n,\nF\n,etc. are adjusted accordingly and that edge is \"popped\" from \nQ\n. Using\n\nQit\n its neighboring edges are also popped from \nQ\n and re-inserted after\nupdating their costs according to \ncost_and_placement\n, new placements are\nremembered in \nC\n. If not valid, then the edge is \"popped\" from \nQ\n and\nreinserted with infinite cost.\n\n\n\n\nThe \nExample 703\n demonstrates using this priority\nqueue based approach with the simple shortest-edge-midpoint cost/placement\nstrategy discussed above.\n\n\nSigned Distances\n [signeddistances]\n\u00b6\n\n\nIn the [Generalized Winding Number section][generalizedwindingnumber], we\nexamined a robust method for determining whether points lie inside or outside\nof a given triangle soup mesh. Libigl complements this algorithm with\naccelerated signed and unsigned distance queries and \"in element\" queries for\nplanar triangle meshes and 3D tetrahedral meshes. These routines make use of\nlibigl's general purpose axis-aligned bounding box hierarchy (\nigl/AABB.h\n).\nThis class is lightweight and---by design---does not store a copy of the mesh\n(taking it as inputs to its member functions instead).\n\n\nPoint location\n\u00b6\n\n\nFor tetrahedral meshes, this is useful for \"in element\" or \"point location\"\nqueries: given a point \n\\mathbf{q}\\in\\mathcal{R}^3\n\\mathbf{q}\\in\\mathcal{R}^3\n and a tetrahedral mesh\n\n(V,T)\n(V,T)\n determine in which tetrahedron \n\\mathbf{q}\n\\mathbf{q}\n lies. This is accomplished\nin libigl for a tet mesh \nV,T\n and a list of query points in the rows of \nQ\n\nvia the \nigl::in_element()\n:\n\n\n// Initialize AABB tree\n\n\nigl\n::\nAABB\n<\nMatrixXd\n,\n3\n>\n \ntree\n;\n\n\ntree\n.\ninit\n(\nV\n,\nT\n);\n\n\nVectorXi\n \nI\n;\n\n\nigl\n::\nin_element\n(\nV\n,\nT\n,\nQ\n,\ntree\n,\nI\n);\n\n\n\n\n\nthe resulting vector \nI\n is a list of indices into \nT\n revealing the \nfirst\n\ntetrahedron found to contain the corresponding point in \nQ\n.\n\n\nFor overlapping meshes, a point \n\\mathbf{q}\n\\mathbf{q}\n may belong to more than one\ntetrahedron. In those cases, one can find them all (not just the first) by\nusing the \nigl::in_element\n overload with a \nSparseMatrix\n as the output:\n\n\nSparseMatrix\n<\nint\n>\n \nI\n;\n\n\nigl\n::\nin_element\n(\nV\n,\nT\n,\nQ\n,\ntree\n,\nI\n);\n\n\n\n\n\nnow each row of \nI\n reveals whether each tet contains the corresponding row in\n\nQ\n: \nI(q,e)!=0\n means that point \nq\n is in element \ne\n.\n\n\nClosest points\n\u00b6\n\n\nFor Triangle meshes, we use the AABB tree to accelerate point-mesh closest\npoint queries: given a mesh \n(V,F)\n(V,F)\n and a query point\n\n\\mathbf{q}\\in\\mathcal{R}^3\n\\mathbf{q}\\in\\mathcal{R}^3\n find the closest point \n\\mathbf{c} \\in (V,F)\n\\mathbf{c} \\in (V,F)\n\n(where \n\\mathbf{c}\n\\mathbf{c}\n is not necessarily a vertex of \n(V,F)\n(V,F)\n). This is\naccomplished for a triangle mesh \nV,F\n and a list of points in the rows of \nP\n\nvia \nigl::point_mesh_squared_distance\n:\n\n\nVectorXd\n \nsqrD\n;\n\n\nVectorXi\n \nI\n;\n\n\nMatrixXd\n \nC\n;\n\n\nigl\n::\npoint_mesh_squared_distance\n(\nP\n,\nV\n,\nF\n,\nsqrD\n,\nI\n,\nC\n);\n\n\n\n\n\nthe output \nsqrD\n contains the (unsigned) squared distance from each point in\n\nP\n to its closest point given in \nC\n which lies on the element in \nF\n given by\n\nI\n (e.g. from which one could recover barycentric coordinates, using\n\nigl::barycentric_coordinates\n).\n\n\nIf the mesh \nV,F\n is static, but the point set \nP\n is changing dynamically then\nit's best to reuse the AABB hierarchy that's being built during\n\nigl::point_mesh_squared_distance\n:\n\n\nigl\n::\nAABB\n \ntree\n;\n\n\ntree\n.\ninit\n(\nV\n,\nF\n);\n\n\ntree\n.\nsquared_distance\n(\nV\n,\nF\n,\nP\n,\nsqrD\n,\nI\n,\nC\n);\n\n\n...\n \n// P changes, but (V,F) does not\n\n\ntree\n.\nsquared_distance\n(\nV\n,\nF\n,\nP\n,\nsqrD\n,\nI\n,\nC\n);\n\n\n\n\n\nSigned distance\n\u00b6\n\n\nFinally, from the closest point or the winding number it's possible to \nsign\n\nthis distance. In \nigl::signed_distance\n we provide two methods for signing:\nthe so-called \"pseudo-normal test\" [#baerentzen_2005][] and the generalized\nwinding number [#jacobson_2013][].\n\n\nThe pseudo-normal test (see also \nigl::pseudonormal_test\n) assumes the input\nmesh is a watertight (closed, non-self-intersecting, manifold) mesh. Then given\na query point \n\\mathbf{q}\n\\mathbf{q}\n and its closest point \n\\mathbf{c} \\in (V,F)\n\\mathbf{c} \\in (V,F)\n, it\ncarefully chooses an outward normal \n\\mathbf{n}\n\\mathbf{n}\n at \n\\mathbf{c}\n\\mathbf{c}\n so that\n\n\\text{sign}(\\mathbf{q}-\\mathbf{c})\\cdot \\mathbf{n}\n\\text{sign}(\\mathbf{q}-\\mathbf{c})\\cdot \\mathbf{n}\n reveals whether\n\n\\mathbf{q}\n\\mathbf{q}\n is inside \n(V,F)\n(V,F)\n: -1, or outside: +1. This is a fast \nO(1)\nO(1)\n test\nonce \n\\mathbf{c}\n\\mathbf{c}\n is located, but may fail if \nV,F\n is not watertight.\n\n\nAn alternative is to use the [generalized winding\nnumber][generalizedwindingnumber] to determine the sign. This is very robust to\nunclean meshes \nV,F\n but slower: something like \nO(\\sqrt{n})\nO(\\sqrt{n})\n once \n\\mathbf{c}\n\\mathbf{c}\n\nis located.\n\n\nIn either case, the interface via \nigl::signed_distance\n is:\n\n\n// Choose type of signing to use\n\n\nigl\n::\nSignedDistanceType\n \ntype\n \n=\n \nSIGNED_DISTANCE_TYPE_PSEUDONORMAL\n;\n\n\nigl\n::\nsigned_distance\n(\nP\n,\nV\n,\nF\n,\nsign_type\n,\nS\n,\nI\n,\nC\n,\nN\n);\n\n\n\n\n\nthe outputs are as above for \nigl::point_mesh_squared_distance\n but now \nS\n\ncontains signed (unsquared) distances and the extra output \nN\n (only set when\n\ntype == SIGNED_DISTANCE_TYPE_PSEUDON\n) contains the normals used for signing\nwith the pseudo-normal test.\n\n\n\n\nMarching Cubes\n [marchingcubes]\n\u00b6\n\n\nOften 3D data is captured as scalar field defined over space \nf(\\mathbf{x}) :\n\\mathcal{R}^3 \\rightarrow \\mathcal{R}\nf(\\mathbf{x}) :\n\\mathcal{R}^3 \\rightarrow \\mathcal{R}\n. Lurking within this field,\n\niso-surfaces\n of the scalar field are often salient geometric objects. The\niso-surface at value \nv\nv\n is composed of all points \n\\mathbf{x}\n\\mathbf{x}\n in\n\n\\mathcal{R}^3\n\\mathcal{R}^3\n such that \nf(\\mathbf{x}) = v\nf(\\mathbf{x}) = v\n. A core problem in geometry\nprocessing is to extract an iso-surface as a triangle mesh for further\nmesh-based processing or visualization. This is referred to as iso-contouring.\n\n\n\"Marching Cubes\" [#lorensen_1987] is a \nfamous\nmethod\n for iso-contouring\ntri-linear functions \nf\nf\n on a regular lattice (aka grid). The core idea of this\nmethod is to contour the iso-surface passing through each cell  (if it does at\nall) with a predefined topology (aka connectivity) chosen from a look up table\ndepending on the function values at each vertex of the cell. The method\niterates (\"marches\") over all cells (\"cubes\") in the grid and stitches together\nthe final, watertight mesh.\n\n\nIn libigl, \nigl::marching_cubes\n constructs a triangle mesh \n(V,F)\n from an\ninput scalar field \nS\n sampled at vertex locations \nGV\n of a \nnx\n by \nny\n by\n\nnz\n regular grid:\n\n\nigl\n::\nmarching_cubes\n(\nS\n,\nGV\n,\nnx\n,\nny\n,\nnz\n,\nV\n,\nF\n);\n\n\n\n\n\n\n\nFacet Orientation\n [facetorientation]\n\u00b6\n\n\nModels from the web occasionally arrive \nunorientated\n in the sense that\nthe orderings of each triangles vertices do not consistently agree. Determining\na consistent facet orientation for a mesh is essential for two-sided lighting\n(e.g., a cloth with red velvet on one side and gold silk on the other side) and\nfor inside-outside determination(e.g., using \ngeneralized winding\nnumbers\n).\n\n\nFor (open) surfaces representing two-sided sheets, libigl provides a routine to\nforce consistent orientations within each orientable patch\n(\nigl::orientable_patches\n) of a mesh:\n\n\nigl\n::\nbfs_orient\n(\nF\n,\nFF\n,\nC\n);\n\n\n\n\n\nThis simple routine will use breadth-first search on each patch of the mesh to\nenforce a consistent facet orientation in the output faces \nFF\n.\n\n\nFor (closed or nearly closed) surfaces representing the boundary of a solid\nobject, libigl provides a routine to reorient faces so that the vertex ordering\ncorresponds to a counter-clockwise ordering of the vertices with a\nright-hand-rule normal pointing outward. This method [#takayama14][] assumes\nthat \nmost of the universe is\nempty\n.\nThat is, most points in space are outside of the solid object than inside.\nPoints are sampled over surface patches. For each sample point, rays are shot\ninto both hemispheres to compute average of the (distance weighted) ambient\nocclusion on each side. A patch is oriented so that the outward side is \nless\noccluded\n (lighter, i.e., facing more void space).\n\n\nigl\n::\nembree\n::\nreorient_facets_raycast\n(\nV\n,\nF\n,\nFF\n,\nI\n);\n\n\n\n\n\nThe boolean vector \nI\n reveals which rows of \nF\n have been flipped in \nFF\n.\n\n\n\n\nSwept Volume\n [sweptvolume]\n\u00b6\n\n\nThe swept volume \nS\nS\n of a moving solid object \nA\nA\n can be defined as any point in\nspace such that at one moment in time the point lies inside the solid. In other\nwords, it is the union of the solid object transformed by the rigid motion\n\nf(t)\nf(t)\n over time:\n\n\nS = \\bigcup \\limits_{t\\in [0,1]} f(t) A.\nS = \\bigcup \\limits_{t\\in [0,1]} f(t) A.\n\n\nThe surface of the swept volume of a solid bounded by a triangle mesh\nundergoing a rigid motion with non-trivial rotation is \nnot\n a surface\nexactly representably by triangle mesh: it will be a piecewise-ruled surface.\n\n\nTo see this, consider the surface swept by a single edge's line segment as it\nperforms a screw motion.\n\n\nThis means that if we'd like to the surface of the swept volume of a triangle\nmesh undergoing a rigid motion and we'd like the output to be another triangle\nmesh, then we're going to have to be happy with some amount of approximation\nerror.\n\n\nWith this in mind, the simplest method for computing an approximate swept\nvolume is by exploiting an alternative definition of the swept volume based on\nsigned distances:\n\n\nS = \\left\\{ \\mathbf{p}\\ \\middle| \\ d(\\mathbf{p},\\partial S) < 0 \\right\\} = \\left\\{ \\mathbf{p}\\\n\\middle|\\\n\\min\\limits_{t \\in [0,1]} d(\\mathbf{p},f(t)\\ \\partial A) < 0 \\right\\}\nS = \\left\\{ \\mathbf{p}\\ \\middle| \\ d(\\mathbf{p},\\partial S) < 0 \\right\\} = \\left\\{ \\mathbf{p}\\\n\\middle|\\\n\\min\\limits_{t \\in [0,1]} d(\\mathbf{p},f(t)\\ \\partial A) < 0 \\right\\}\n\n\nIf \n\\partial A\n\\partial A\n is a triangle mesh, then we can approximate this by 1)\ndiscretizing time at a finite step of steps \n[0,\\Delta t,2\\Delta t, \\dots, 1]\n[0,\\Delta t,2\\Delta t, \\dots, 1]\n\nand by 2) discretizing space with a regular grid and representing the distance\nfield using trilinear interpolation of grid values. Finally the output mesh,\n\n\\partial S\n\\partial S\n is approximated by contouring using Marching Cubes\n[#lorensen_1987].\n\n\nThis method is similar to one described by Schroeder et al. in 1994\n[#schroeder_1994], and the one used in conjunction with boolean operations by\nGarg et al. 2016 [#garg_2016].\n\n\nIn libigl, if your input solid's surface is represented by \n(V,F)\n then the\noutput surface mesh will be \n(SV,SF)\n after calling:\n\n\nigl\n::\ncopyleft\n::\nswept_volume\n(\nV\n,\nF\n,\nnum_time_steps\n,\ngrid_size\n,\nisolevel\n,\nSV\n,\nSF\n);\n\n\n\n\n\nThe \nisolevel\n parameter can be set to zero to approximate the exact swept\nvolume, greater than zero to approximate a positive offset of the swept volume\nor less than zero to approximate a negative offset.\n\n\n\n\nPicking\n [pickingverticesandfaces]\n\u00b6\n\n\nPicking vertices and faces using the mouse is very common in geometry\nprocessing applications. While this might seem a simple operation, its\nimplementation is not straightforward. Libigl contains a function that solves this problem using the\n\nEmbree\n\nraycaster. Its usage is demonstrated in \nExample 708\n:\n\n\nbool\n \nhit\n \n=\n \nigl\n::\nunproject_onto_mesh\n(\n\n  \nVector2f\n(\nx\n,\ny\n),\n\n  \nF\n,\n\n  \nviewer\n.\ncore\n.\nview\n \n*\n \nviewer\n.\ncore\n.\nmodel\n,\n\n  \nviewer\n.\ncore\n.\nproj\n,\n\n  \nviewer\n.\ncore\n.\nviewport\n,\n\n  \n*\nei\n,\n\n  \nfid\n,\n\n  \nvid\n);\n\n\n\n\n\nThis function casts a ray from the view plane in the view direction. Variables\n\nx\n and \ny\n are\nthe mouse screen coordinates; \nview\n, \nmodel\n, \nproj\n are the view, model and\nprojection matrix respectively; \nviewport\n is the viewport in OpenGL format;\n\nei\n\ncontains a \nBounding Volume\nHierarchy\n constructed\nby Embree, and \nfid\n and \nvid\n are the picked face and vertex, respectively.\n\n\n\n\nVector Field Visualization\n [vectorfieldvisualizer]\n\u00b6\n\n\nVector fields on surfaces are commonly visualized by tracing [streamlines] (\nhttps://en.wikipedia.org/wiki/Streamlines,_streaklines,_and_pathlines\n). Libigl\nsupports the seeding and tracing of streamlines, for both simple vector fields\nand for N-rosy fields. The seeds for the streamlines are initialized using \nstreamlines_init\n,\nand the lines are traced using \nstreamlines_next\n. Each call to \nstreamlines_next\n extends\neach line by one triangle, allowing interactive rendering of the traced lines, as demonstrated\nin \nExample 709\n.\n\n\n\n\nScalable Locally Injective Maps\n [slim]\n\u00b6\n\n\nThe Scalable Locally Injective Maps [#rabinovich_2016] algorithm allows to\ncompute locally injective maps on massive datasets. The algorithm shares many\nsimilarities with ARAP, but uses a reweighting scheme to minimize arbitrary\ndistortion energies, including those that prevent the introduction of flips.\n\n\nExample 710\n contains three demos: (1) an example of large\nscale 2D parametrization, (2) an example of 2D deformation with soft\nconstraints, and (3) an example of 3D deformation with soft constraints. The\nimplementation in libigl is self-contained and relies on Eigen for the solution\nof the linear system used in the global step. An optimized version that relies\non Pardiso is available\n\nhere\n.\n\n\n\n\nSubdivision surfaces\n [subdivision]\n\u00b6\n\n\nGiven a coarse mesh (aka cage) with vertices \nV\n and faces \nF\n, one can createa\nhigher-resolution mesh with more vertices and faces by \nsubdividing\n every\nface. That is, each coarse triangle in the input is replaced by many smaller\ntriangles. Libigl has three different methods for subdividing a triangle mesh.\n\n\nAn \"in plane\" subdivision method will not change the point set or carrier\nsurface of the mesh. New vertices are added on the planes of existing triangles\nand vertices surviving from the original mesh are not moved.\n\n\nBy adding new faces, a subdivision algorithm changes the \ncombinatorics\n of the\nmesh. The change in combinatorics and the formula for positioning the\nhigh-resolution vertices is called the \"subdivision rule\".\n\n\nFor example, in the \nin plane\n subdivision method of \nigl::upsample\n, vertices\nare added at the midpoint of every edge: \nv_{ab} = \\frac{1}{2}(v_a + v_b)\nv_{ab} = \\frac{1}{2}(v_a + v_b)\n and\neach triangle \n(i_a,i_b,i_c)\n(i_a,i_b,i_c)\n is replaced with four triangles:\n\n(i_a,i_{ab},i_{ca})\n(i_a,i_{ab},i_{ca})\n, \n(i_b,i_{bc},i_{ab})\n(i_b,i_{bc},i_{ab})\n, \n(i_{ab},i_{bc},i_{ca})\n(i_{ab},i_{bc},i_{ca})\n, and\n\n(i_{bc},i_{c},i_{ca})\n(i_{bc},i_{c},i_{ca})\n. This process may be applied recursively, resulting in\na finer and finer mesh.\n\n\nThe subdivision method of \nigl::loop\n is not in plane. The vertices of the\nrefined mesh are moved to weight combinations of their neighbors: the mesh is\nsmoothed as it is refined [#loop_1987]. This and other \nsmooth subdivision\n\nmethods can be understood as generalizations of spline curves to surfaces. In\nparticular the Loop subdivision method will converge to a \nC^1\nC^1\n surface as we\nconsider the limit of recursive applications of subdivision. Away from\n\"irregular\" or \"extraordinary\" vertices (vertices of the original cage with\nvalence not equal to 6), the surface is \nC^2\nC^2\n. The combinatorics (connectivity\nand number of faces) of \nigl::loop\n and \nigl::upsample\n are identical: the only\ndifference is that the vertices have been smoothed in \nigl::loop\n.\n\n\nFinally, libigl also implements a form of \nin plane\n \"false barycentric\nsubdivision\" in \nigl::false_barycentric_subdivision\n. This method simply adds\nthe barycenter of every triangle as a new vertex \nv_{abc}\nv_{abc}\n and replaces each\ntriangle with three triangles \n(i_a,i_b,i_{abc})\n(i_a,i_b,i_{abc})\n, \n(i_b,i_c,i_{abc})\n(i_b,i_c,i_{abc})\n, and\n\n(i_c,i_a,i_{abc})\n(i_c,i_a,i_{abc})\n. In contrast to \nigl::upsample\n, this method will create\ntriangles with smaller and smaller internal angles and new vertices will sample\nthe carrier surfaces with extreme bias.\n\n\n\n\nData smoothing\n [datasmoothing]\n\u00b6\n\n\nA noisy function \nf\nf\n defined on a surface \n\\Omega\n\\Omega\n can be smoothed using an\nenergy minimization that balances a smoothing term \nE_S\nE_S\n with a quadratic\nfitting term:\n\n\nu = \\operatorname{argmin}_u \\alpha E_S(u) + (1-\\alpha)\\int_\\Omega ||u-f||^2 dx\nu = \\operatorname{argmin}_u \\alpha E_S(u) + (1-\\alpha)\\int_\\Omega ||u-f||^2 dx\n\n\nThe parameter \n\\alpha\n\\alpha\n determines how aggressively the function is smoothed.\n\n\nA classical choice for the smoothness energy is the Laplacian energy of the\nfunction with zero Neumann boundary conditions, which is a form of the\nbiharmonic energy. It is constructed using the cotangent Laplacian \nL\n and\nthe mass matrix \nM\n: \nQL = L'*(M\\L)\n. Because of the implicit zero Neumann\nboundary conditions however, the function behavior is significantly warped at\nthe boundary if \nf\nf\n does not have zero normal gradient at the boundary.\n\n\nIn #[stein_2017] it is suggested to use the Biharmonic energy with natural\nHessian boundary conditions instead, which corresponds to the hessian energy\nwith the matrix \nQH = H'*(M2\\H)\n, where \nH\n is a finite element Hessian and\n\nM2\n is a stacked mass matrix. The matrices \nH\n and \nQH\n are implemented in\nlibigl as \nigl::hessian\n and \nigl::hessian_energy\n respectively. An example\nof how to use the function is given in \nExample 712\n.\n\n\nIn the following image the differences between the Laplacian energy with\nzero Neumann boundary conditions and the Hessian energy can be clearly seen:\nwhereas the zero Neumann boundary condition in the third image bias the isolines\nof the function to be perpendicular to the boundary, the Hessian energy gives\nan unbiased result.\n\n\n\n\nShapeUp Projections\n [shapeup]\n\u00b6\n\n\nOur input is a set of points \nP_0\nP_0\n (not necessarily part of any mesh), and a set of constraints \nS=\\left\\{S_1,S_2,...S_m\\right\\}\nS=\\left\\{S_1,S_2,...S_m\\right\\}\n, where each constraint is defined on a different, and sparse, subset of \nP_0\nP_0\n. We wish to create a new set of points \nP\nP\n that are close to the original set \nP_0\nP_0\n (each point with corresponding indices), while adhering to the constraints. Other objectives, such as smoothness, can be employed. The constraints can be nonlinear, which makes the problem nonconvex, difficult, and without a guaranteed global optimum. A very popular lightweight approach to such problems is a local-global iterative algorithm, comprising these two steps:\n\n\nFor iteration \nk\nk\n:\n1. \nLocal step\n: compute the projections of the set \nP_{k-1}\nP_{k-1}\n onto \nS\nS\n, individually per constraint; that would mean fragmenting each point that appears in multiple constraints. That can be a nonlinear operation, but if the constraints are sparse, it is a a set of many small systems.\n2. \nGlobal step\n: integrate the set \nP_k\nP_k\n to be as close as possible to the projected fragmented set, with auxiliary objective functions possible. That results in a global, but quadratic objective function. Moreover, the resulting linear system has a constant matrix, and therefore can be pre-factored.\n\n\nThe version we implement in libigl is the general version described by [#bouaziz_2012], and is in two files: \n<igl/shapeup.h>\n and \n<igl/shapeup_local_projections.h>\n. A demo implementing regularity constraints (creating a mesh in which each face is as regular as possible) is in \nExample 713\n. \n\n\nThe local step is instantiated by a function of type \nigl::shapeup_projection_function\n. The global step is done by two functions: \nigl::shapeup_precomputation()\n, which precomputes the matrices required for the global step, and \nigl::shapeup_solve()\n, which solves the problem, according to the initial solution \nP_0\nP_0\n and the input local projection function. The data struct \nigl::ShapeUpData\n contains the information necessary to run the algorithm, and can be configured; for instance, the self-explanatory variable \nMaxiterations\n.\n\n\nThe global step minimizes the following energy:\n\n\n\n\nE_{total}=\\lambda_{shape}E_{shape}+\\lambda_{close}E_{close}+\\lambda_{smooth}E_{smooth},\n\n\nE_{total}=\\lambda_{shape}E_{shape}+\\lambda_{close}E_{close}+\\lambda_{smooth}E_{smooth},\n\n\n\n\nwhere the \n\\lambda\n\\lambda\n coefficients are encoded in \nigl::ShapeUpData\n, and can be updated \nprior\n to calling \nigl::shapeup_precomputation()\n. The \nE_{shape}\nE_{shape}\n component is the integration energy (fitting \nP_k\nP_k\n to the local projections). The \nE_{close}\nE_{close}\n component is adherence to positional constraints, given by \nb\n and \nbc\n parameters. The \nE_{smooth}\nE_{smooth}\n component is an optional objective function, to minimize differences (in the Dirichlet sense) between points, encodes by \"edges\" in parameter \nE\n. Both \nE_{close}\nE_{close}\n and \nE_{shape}\nE_{shape}\n are also weighted by \nwClose\n and \nwShape\n function parameters, respectively.",
            "title": "Chapter 7: Miscellaneous"
        },
        {
            "location": "/tutorial/chapter-7/#miscellaneous-chapter7miscellaneous",
            "text": "Libigl contains a  wide  variety of geometry processing tools and functions for\ndealing with meshes and the linear algebra related to them: far too many to\ndiscuss in this introductory tutorial. We've pulled out a couple of the\ninteresting functions in this chapter to highlight.",
            "title": "Miscellaneous [chapter7:miscellaneous]"
        },
        {
            "location": "/tutorial/chapter-7/#mesh-statistics-meshstatistics",
            "text": "Libigl contains various mesh statistics, including face angles, face areas and\nthe detection of singular vertices, which are vertices with more or less than 6\nneighbours in triangulations or 4 in quadrangulations.  The example  Statistics  computes these quantities and\ndoes a basic statistic analysis that allows to estimate the isometry and\nregularity of a mesh:  Irregular vertices: 136 /2400  ( 5 .67% ) \nAreas  ( Min/Max ) /Avg_Area Sigma: 0 .01/5.33  ( 0 .87 ) \nAngles in degrees  ( Min/Max )  Sigma: 17 .21/171.79  ( 15 .36 )   The first row contains the number and percentage of irregular vertices, which\nis particularly important for quadrilateral meshes when they are used to define\nsubdivision surfaces: every singular point will result in a point of the\nsurface that is only C^1.  The second row reports the area of the minimal element, maximal element and the\nstandard deviation.  These numbers are normalized by the mean area, so in the\nexample above 5.33 max area means that the biggest face is 5 times larger than\nthe average face. An ideal isotropic mesh would have both min and max area\nclose to 1.  The third row measures the face angles, which should be close to 60 degrees (90\nfor quads) in a perfectly regular triangulation. For FEM purposes, the closer\nthe angles are to 60 degrees the more stable will the optimization be. In this\ncase, it is clear that the mesh is of bad quality and it will probably result\nin artifacts if used for solving PDEs.",
            "title": "Mesh Statistics [meshstatistics]"
        },
        {
            "location": "/tutorial/chapter-7/#generalized-winding-number-generalizedwindingnumber",
            "text": "The problem of tetrahedralizing the interior of closed watertight surface mesh\nis a difficult, but well-posed problem (see our [Tetgen wrappers][tetrahedralizationofclosedsurfaces]).  But\nblack-box tet-meshers like TetGen will  refuse  input triangle meshes with\nself-intersections, open boundaries, non-manifold edges from multiple connected\ncomponents.\nThe problem is two-fold: self-intersections present contradictory facet\nconstraints and self-intersections/open-boundaries/non-manifold edges make the\nproblem of determining inside from outside ill-posed without further\nassumptions.  The first problem is  easily  solved by \"resolving\" all self-intersections.\nThat is, meshing intersecting triangles so that intersects occur exactly at\nedges and vertices. This is accomplished using  igl::selfintersect .  TetGen can usually tetrahedralize the convex hull of this \"resolved\" mesh, and\nthen the problem becomes determining which of these tets are  inside  the input\nmesh and which are outside. That is, which should be kept and which should be\nremoved.  The \"Generalized Winding Number\" is a robust method for determined\ninside and outside for troublesome meshes [#jacobson_2013][].  The generalized\nwinding number with respect to  (V,F)  at some point  \\mathbf{p} \\in\n\\mathcal{R}^3 \\mathbf{p} \\in\n\\mathcal{R}^3  is defined as scalar function:  w(\\mathbf{p}) = \\sum\\limits_{f_i\\in F} \\frac{1}{4\\pi}\\Omega_{f_i}(\\mathbf{p}) w(\\mathbf{p}) = \\sum\\limits_{f_i\\in F} \\frac{1}{4\\pi}\\Omega_{f_i}(\\mathbf{p}) <span><span class=\"MathJax_Preview\">w(\\mathbf{p}) = \\sum\\limits_{f_i\\in F} \\frac{1}{4\\pi}\\Omega_{f_i}(\\mathbf{p})</span><script type=\"math/tex\">w(\\mathbf{p}) = \\sum\\limits_{f_i\\in F} \\frac{1}{4\\pi}\\Omega_{f_i}(\\mathbf{p})  where  \\Omega_{f_i} \\Omega_{f_i}  is the  solid angle  subtended by  f_i f_i  (the ith face in F ) at the point  \\mathbf{p} \\mathbf{p} . This solid angle contribution is a simple,\nclosed-form expression involving  atan2  and some dot-products.  If  (V,F)   does  form a closed watertight surface, then  w(\\mathbf{p})=1 w(\\mathbf{p})=1  if \\mathbf{p} \\mathbf{p}  lies inside  (V,F)  and  w(\\mathbf{p})=0 w(\\mathbf{p})=0  if outside  (V,F) .  If (V,F)  is closed but overlaps itself then  w(\\mathbf{p}) w(\\mathbf{p})  is an integer value\ncounting how many (signed) times  (V,F)   wraps  around  \\mathbf{p} \\mathbf{p} .  Finally,\nif  (V,F)  is not closed or not even manifold (but at least consistently\noriented), then  w(\\mathbf{p}) w(\\mathbf{p})  tends smoothly toward 1 as  \\mathbf{p} \\mathbf{p}  is more  inside  (V,F) , and toward 0 as  \\mathbf{p} \\mathbf{p}  is more outside.",
            "title": "Generalized Winding Number [generalizedwindingnumber]"
        },
        {
            "location": "/tutorial/chapter-7/#mesh-decimation-meshdecimation",
            "text": "The study of mesh simplification or  decimation  is nearly as old as meshes\nthemselves. Given a high resolution mesh with too many triangles, find a \"well\napproximating\" low resolution mesh with far fewer triangles. By now there are a\nvariety of different paradigms for solving this problem and state-of-the-art\nmethods are fairly advanced.  One family of mesh decimation methods operates by successively remove elements\nfrom the mesh. In particular, Hoppe advocates for successively remove or rather\ncollapsing edges [#hoppe_1996][]. The generic form of this technique is to\nconstruct a sequence of n meshes from the initial high-resolution mesh  M_0 M_0  to\nthe lowest resolution mesh  M_n M_n  by collapsing a single edge:  M_0 \\mathop{\\longrightarrow}_\\text{edge collapse}\n  M_1 \\mathop{\\longrightarrow}_\\text{edge collapse}\n  \\dots \\mathop{\\longrightarrow}_\\text{edge collapse}\n  M_{n-1} \\mathop{\\longrightarrow}_\\text{edge collapse} M_n. M_0 \\mathop{\\longrightarrow}_\\text{edge collapse}\n  M_1 \\mathop{\\longrightarrow}_\\text{edge collapse}\n  \\dots \\mathop{\\longrightarrow}_\\text{edge collapse}\n  M_{n-1} \\mathop{\\longrightarrow}_\\text{edge collapse} M_n.  Hoppe's original method and subsequent follow-up works propose various ways to\nchoose the next edge to collapse in this sequence. Using a cost-based paradigm,\none can maintain a priority queue of edges based on their \"cost\" (how much\n\"worse\" will my approximation be if I remove this edge?). The cheapest edge is\ncollapsed and costs of neighboring edges are updated.  In order to maintain the topology (e.g. if the mesh is combinatorially as\nsphere or a torus etc.), one should assign infinite cost to edges whose\ncollapse would alter the mesh topology. Indeed this happens if and only if the\nnumber of mutual neighbors of the endpoints of the collapsing edge is not\nexactly two!  If there exists a third shared vertex, then another face will be removed, but 2\nedges will be removed. This can result in unwanted holes or non-manifold\n\"flaps\".    There is also a one-off condition that no edges of a tetrahedron should be\ncollapsed.   Because libigl (purposefully) does not center its implementations around a\ndynamic mesh data structure (e.g. half-edge datastructure), support for\ntopology changes are limited. Nonetheless, libigl has support for isolated edge\ncollapses, sequences of edge-collapses (each in O(log) time) and priority queue\nbased decimation.  The simplest is  igl::decimation . By calling  igl :: decimate ( V , F , 1000 , U , G );   the mesh  (V,F)  will be decimated to a new mesh  (U,G)  so that  G  has at\nmost  1000  faces. This uses default (naive) criteria for determining the cost\nof an edge collapse and the placement of the merged vertex. Shortest edges are\ncollapsed first, and merged vertices are placed at edge midpoints.  One can also provide function handles ( c++  lambda functions are convenient\nhere)  cost_and_placement  and  stopping_condition  for determining the\ncost/placement of an edge collapse and the stopping condition respectively. For\nexample, the default version above is implemented as:  igl :: decimate ( V , F , shortest_edge_and_midpoint , max_m , U , G );   where  shortest_edge_and_midpoint  assign the edge's length as cost and its\nmidpoint as the merged vertex placement and  max_m  counts the current number\nof faces (valid collapses decrease count by 2) and returns  true  if the count\ndrops below  m=1000 .  One can also scratch deeper inside the decimation loop and call igl::collapse_edge  directly. In order to operate efficiently, this routine\nneeds more than the usual  (V,F)  mesh representation. We need  E  a list of\nedge indices, where  E.row(i) --> [s,d] ; we need  EMAP  which maps the\n\"half\"-edges of each triangle in  F  to its corresponding edge in  E  so that E.row(EMAP(f+i*F.rows)) --> [s,d]  if the edge across from the ith corner of the\nfth face is  [s,d]  (up to orientation); we need  EF  and  EI  which keep track\nof the faces incident on each edge and across from which corner of those faces\nthe edges appears, so that  EF(e,o) = f  and  EI(e,o) = i  means that the edge E.row(e) --> [s,d]  appears in the fth face across from its ith corner (for o=0  the edge orientations should match, for  o=1  the orientations are\nopposite).  When a collapse occurs, the sizes of the  F , E , etc. matrices do not change.\nRather rows corresponding to \"removed\" faces and edges are set to a special\nconstant value  IGL_COLLAPSE_EDGE_NULL . Doing this ensures that we're able to\nremove edges in truly constant time O(1).   Conveniently  IGL_COLLAPSE_EDGE_NULL==0 . This means most OPENGL style renderings of  F \nwill simply draw a bunch of 0-area triangles at the first vertex.   The following will collapse the first\nedge and place its merged vertex at the origin:  igl :: collapse_edge ( 0 , RowVector3d ( 0 , 0 , 0 ), V , F , E , EMAP , EF , EI );  \nIf valid, then  V , F , E , EF , EI  are adjusted accordingly.  This is powerful, but low level. To build a decimator around this you'd need to\nkeep track which edges are left to collapse and which to collapse next.\nFortunately, libigl also exposes a priority queue based edge collapse with\nfunction handles to adjust costs and placements.  The priority queue is implemented as a (ordered) set  Q  or (cost,edge index)\npairs and a list of iterators  Qit  so that  Qit[e]  reveals the iterator in Q  corresponding to the eth edge. Placements are stored in a #E list of\npositions  C . When the following is called:  igl :: collapse_edge ( cost_and_placement , V , F , E , EMAP , EF , EI , Q , Qit , C );   the lowest cost edge collapse according to  Q  is attempted. If valid, then V , F ,etc. are adjusted accordingly and that edge is \"popped\" from  Q . Using Qit  its neighboring edges are also popped from  Q  and re-inserted after\nupdating their costs according to  cost_and_placement , new placements are\nremembered in  C . If not valid, then the edge is \"popped\" from  Q  and\nreinserted with infinite cost.   The  Example 703  demonstrates using this priority\nqueue based approach with the simple shortest-edge-midpoint cost/placement\nstrategy discussed above.",
            "title": "Mesh Decimation [meshdecimation]"
        },
        {
            "location": "/tutorial/chapter-7/#signed-distances-signeddistances",
            "text": "In the [Generalized Winding Number section][generalizedwindingnumber], we\nexamined a robust method for determining whether points lie inside or outside\nof a given triangle soup mesh. Libigl complements this algorithm with\naccelerated signed and unsigned distance queries and \"in element\" queries for\nplanar triangle meshes and 3D tetrahedral meshes. These routines make use of\nlibigl's general purpose axis-aligned bounding box hierarchy ( igl/AABB.h ).\nThis class is lightweight and---by design---does not store a copy of the mesh\n(taking it as inputs to its member functions instead).",
            "title": "Signed Distances [signeddistances]"
        },
        {
            "location": "/tutorial/chapter-7/#point-location",
            "text": "For tetrahedral meshes, this is useful for \"in element\" or \"point location\"\nqueries: given a point  \\mathbf{q}\\in\\mathcal{R}^3 \\mathbf{q}\\in\\mathcal{R}^3  and a tetrahedral mesh (V,T) (V,T)  determine in which tetrahedron  \\mathbf{q} \\mathbf{q}  lies. This is accomplished\nin libigl for a tet mesh  V,T  and a list of query points in the rows of  Q \nvia the  igl::in_element() :  // Initialize AABB tree  igl :: AABB < MatrixXd , 3 >   tree ;  tree . init ( V , T );  VectorXi   I ;  igl :: in_element ( V , T , Q , tree , I );   the resulting vector  I  is a list of indices into  T  revealing the  first \ntetrahedron found to contain the corresponding point in  Q .  For overlapping meshes, a point  \\mathbf{q} \\mathbf{q}  may belong to more than one\ntetrahedron. In those cases, one can find them all (not just the first) by\nusing the  igl::in_element  overload with a  SparseMatrix  as the output:  SparseMatrix < int >   I ;  igl :: in_element ( V , T , Q , tree , I );   now each row of  I  reveals whether each tet contains the corresponding row in Q :  I(q,e)!=0  means that point  q  is in element  e .",
            "title": "Point location"
        },
        {
            "location": "/tutorial/chapter-7/#closest-points",
            "text": "For Triangle meshes, we use the AABB tree to accelerate point-mesh closest\npoint queries: given a mesh  (V,F) (V,F)  and a query point \\mathbf{q}\\in\\mathcal{R}^3 \\mathbf{q}\\in\\mathcal{R}^3  find the closest point  \\mathbf{c} \\in (V,F) \\mathbf{c} \\in (V,F) \n(where  \\mathbf{c} \\mathbf{c}  is not necessarily a vertex of  (V,F) (V,F) ). This is\naccomplished for a triangle mesh  V,F  and a list of points in the rows of  P \nvia  igl::point_mesh_squared_distance :  VectorXd   sqrD ;  VectorXi   I ;  MatrixXd   C ;  igl :: point_mesh_squared_distance ( P , V , F , sqrD , I , C );   the output  sqrD  contains the (unsigned) squared distance from each point in P  to its closest point given in  C  which lies on the element in  F  given by I  (e.g. from which one could recover barycentric coordinates, using igl::barycentric_coordinates ).  If the mesh  V,F  is static, but the point set  P  is changing dynamically then\nit's best to reuse the AABB hierarchy that's being built during igl::point_mesh_squared_distance :  igl :: AABB   tree ;  tree . init ( V , F );  tree . squared_distance ( V , F , P , sqrD , I , C );  ...   // P changes, but (V,F) does not  tree . squared_distance ( V , F , P , sqrD , I , C );",
            "title": "Closest points"
        },
        {
            "location": "/tutorial/chapter-7/#signed-distance",
            "text": "Finally, from the closest point or the winding number it's possible to  sign \nthis distance. In  igl::signed_distance  we provide two methods for signing:\nthe so-called \"pseudo-normal test\" [#baerentzen_2005][] and the generalized\nwinding number [#jacobson_2013][].  The pseudo-normal test (see also  igl::pseudonormal_test ) assumes the input\nmesh is a watertight (closed, non-self-intersecting, manifold) mesh. Then given\na query point  \\mathbf{q} \\mathbf{q}  and its closest point  \\mathbf{c} \\in (V,F) \\mathbf{c} \\in (V,F) , it\ncarefully chooses an outward normal  \\mathbf{n} \\mathbf{n}  at  \\mathbf{c} \\mathbf{c}  so that \\text{sign}(\\mathbf{q}-\\mathbf{c})\\cdot \\mathbf{n} \\text{sign}(\\mathbf{q}-\\mathbf{c})\\cdot \\mathbf{n}  reveals whether \\mathbf{q} \\mathbf{q}  is inside  (V,F) (V,F) : -1, or outside: +1. This is a fast  O(1) O(1)  test\nonce  \\mathbf{c} \\mathbf{c}  is located, but may fail if  V,F  is not watertight.  An alternative is to use the [generalized winding\nnumber][generalizedwindingnumber] to determine the sign. This is very robust to\nunclean meshes  V,F  but slower: something like  O(\\sqrt{n}) O(\\sqrt{n})  once  \\mathbf{c} \\mathbf{c} \nis located.  In either case, the interface via  igl::signed_distance  is:  // Choose type of signing to use  igl :: SignedDistanceType   type   =   SIGNED_DISTANCE_TYPE_PSEUDONORMAL ;  igl :: signed_distance ( P , V , F , sign_type , S , I , C , N );   the outputs are as above for  igl::point_mesh_squared_distance  but now  S \ncontains signed (unsquared) distances and the extra output  N  (only set when type == SIGNED_DISTANCE_TYPE_PSEUDON ) contains the normals used for signing\nwith the pseudo-normal test.",
            "title": "Signed distance"
        },
        {
            "location": "/tutorial/chapter-7/#marching-cubes-marchingcubes",
            "text": "Often 3D data is captured as scalar field defined over space  f(\\mathbf{x}) :\n\\mathcal{R}^3 \\rightarrow \\mathcal{R} f(\\mathbf{x}) :\n\\mathcal{R}^3 \\rightarrow \\mathcal{R} . Lurking within this field, iso-surfaces  of the scalar field are often salient geometric objects. The\niso-surface at value  v v  is composed of all points  \\mathbf{x} \\mathbf{x}  in \\mathcal{R}^3 \\mathcal{R}^3  such that  f(\\mathbf{x}) = v f(\\mathbf{x}) = v . A core problem in geometry\nprocessing is to extract an iso-surface as a triangle mesh for further\nmesh-based processing or visualization. This is referred to as iso-contouring.  \"Marching Cubes\" [#lorensen_1987] is a  famous\nmethod  for iso-contouring\ntri-linear functions  f f  on a regular lattice (aka grid). The core idea of this\nmethod is to contour the iso-surface passing through each cell  (if it does at\nall) with a predefined topology (aka connectivity) chosen from a look up table\ndepending on the function values at each vertex of the cell. The method\niterates (\"marches\") over all cells (\"cubes\") in the grid and stitches together\nthe final, watertight mesh.  In libigl,  igl::marching_cubes  constructs a triangle mesh  (V,F)  from an\ninput scalar field  S  sampled at vertex locations  GV  of a  nx  by  ny  by nz  regular grid:  igl :: marching_cubes ( S , GV , nx , ny , nz , V , F );",
            "title": "Marching Cubes [marchingcubes]"
        },
        {
            "location": "/tutorial/chapter-7/#facet-orientation-facetorientation",
            "text": "Models from the web occasionally arrive  unorientated  in the sense that\nthe orderings of each triangles vertices do not consistently agree. Determining\na consistent facet orientation for a mesh is essential for two-sided lighting\n(e.g., a cloth with red velvet on one side and gold silk on the other side) and\nfor inside-outside determination(e.g., using  generalized winding\nnumbers ).  For (open) surfaces representing two-sided sheets, libigl provides a routine to\nforce consistent orientations within each orientable patch\n( igl::orientable_patches ) of a mesh:  igl :: bfs_orient ( F , FF , C );   This simple routine will use breadth-first search on each patch of the mesh to\nenforce a consistent facet orientation in the output faces  FF .  For (closed or nearly closed) surfaces representing the boundary of a solid\nobject, libigl provides a routine to reorient faces so that the vertex ordering\ncorresponds to a counter-clockwise ordering of the vertices with a\nright-hand-rule normal pointing outward. This method [#takayama14][] assumes\nthat  most of the universe is\nempty .\nThat is, most points in space are outside of the solid object than inside.\nPoints are sampled over surface patches. For each sample point, rays are shot\ninto both hemispheres to compute average of the (distance weighted) ambient\nocclusion on each side. A patch is oriented so that the outward side is  less\noccluded  (lighter, i.e., facing more void space).  igl :: embree :: reorient_facets_raycast ( V , F , FF , I );   The boolean vector  I  reveals which rows of  F  have been flipped in  FF .",
            "title": "Facet Orientation [facetorientation]"
        },
        {
            "location": "/tutorial/chapter-7/#swept-volume-sweptvolume",
            "text": "The swept volume  S S  of a moving solid object  A A  can be defined as any point in\nspace such that at one moment in time the point lies inside the solid. In other\nwords, it is the union of the solid object transformed by the rigid motion f(t) f(t)  over time:  S = \\bigcup \\limits_{t\\in [0,1]} f(t) A. S = \\bigcup \\limits_{t\\in [0,1]} f(t) A.  The surface of the swept volume of a solid bounded by a triangle mesh\nundergoing a rigid motion with non-trivial rotation is  not  a surface\nexactly representably by triangle mesh: it will be a piecewise-ruled surface.  To see this, consider the surface swept by a single edge's line segment as it\nperforms a screw motion.  This means that if we'd like to the surface of the swept volume of a triangle\nmesh undergoing a rigid motion and we'd like the output to be another triangle\nmesh, then we're going to have to be happy with some amount of approximation\nerror.  With this in mind, the simplest method for computing an approximate swept\nvolume is by exploiting an alternative definition of the swept volume based on\nsigned distances:  S = \\left\\{ \\mathbf{p}\\ \\middle| \\ d(\\mathbf{p},\\partial S) < 0 \\right\\} = \\left\\{ \\mathbf{p}\\\n\\middle|\\\n\\min\\limits_{t \\in [0,1]} d(\\mathbf{p},f(t)\\ \\partial A) < 0 \\right\\} S = \\left\\{ \\mathbf{p}\\ \\middle| \\ d(\\mathbf{p},\\partial S) < 0 \\right\\} = \\left\\{ \\mathbf{p}\\\n\\middle|\\\n\\min\\limits_{t \\in [0,1]} d(\\mathbf{p},f(t)\\ \\partial A) < 0 \\right\\}  If  \\partial A \\partial A  is a triangle mesh, then we can approximate this by 1)\ndiscretizing time at a finite step of steps  [0,\\Delta t,2\\Delta t, \\dots, 1] [0,\\Delta t,2\\Delta t, \\dots, 1] \nand by 2) discretizing space with a regular grid and representing the distance\nfield using trilinear interpolation of grid values. Finally the output mesh, \\partial S \\partial S  is approximated by contouring using Marching Cubes\n[#lorensen_1987].  This method is similar to one described by Schroeder et al. in 1994\n[#schroeder_1994], and the one used in conjunction with boolean operations by\nGarg et al. 2016 [#garg_2016].  In libigl, if your input solid's surface is represented by  (V,F)  then the\noutput surface mesh will be  (SV,SF)  after calling:  igl :: copyleft :: swept_volume ( V , F , num_time_steps , grid_size , isolevel , SV , SF );   The  isolevel  parameter can be set to zero to approximate the exact swept\nvolume, greater than zero to approximate a positive offset of the swept volume\nor less than zero to approximate a negative offset.",
            "title": "Swept Volume [sweptvolume]"
        },
        {
            "location": "/tutorial/chapter-7/#picking-pickingverticesandfaces",
            "text": "Picking vertices and faces using the mouse is very common in geometry\nprocessing applications. While this might seem a simple operation, its\nimplementation is not straightforward. Libigl contains a function that solves this problem using the Embree \nraycaster. Its usage is demonstrated in  Example 708 :  bool   hit   =   igl :: unproject_onto_mesh ( \n   Vector2f ( x , y ), \n   F , \n   viewer . core . view   *   viewer . core . model , \n   viewer . core . proj , \n   viewer . core . viewport , \n   * ei , \n   fid , \n   vid );   This function casts a ray from the view plane in the view direction. Variables x  and  y  are\nthe mouse screen coordinates;  view ,  model ,  proj  are the view, model and\nprojection matrix respectively;  viewport  is the viewport in OpenGL format; ei \ncontains a  Bounding Volume\nHierarchy  constructed\nby Embree, and  fid  and  vid  are the picked face and vertex, respectively.",
            "title": "Picking [pickingverticesandfaces]"
        },
        {
            "location": "/tutorial/chapter-7/#vector-field-visualization-vectorfieldvisualizer",
            "text": "Vector fields on surfaces are commonly visualized by tracing [streamlines] ( https://en.wikipedia.org/wiki/Streamlines,_streaklines,_and_pathlines ). Libigl\nsupports the seeding and tracing of streamlines, for both simple vector fields\nand for N-rosy fields. The seeds for the streamlines are initialized using  streamlines_init ,\nand the lines are traced using  streamlines_next . Each call to  streamlines_next  extends\neach line by one triangle, allowing interactive rendering of the traced lines, as demonstrated\nin  Example 709 .",
            "title": "Vector Field Visualization [vectorfieldvisualizer]"
        },
        {
            "location": "/tutorial/chapter-7/#scalable-locally-injective-maps-slim",
            "text": "The Scalable Locally Injective Maps [#rabinovich_2016] algorithm allows to\ncompute locally injective maps on massive datasets. The algorithm shares many\nsimilarities with ARAP, but uses a reweighting scheme to minimize arbitrary\ndistortion energies, including those that prevent the introduction of flips.  Example 710  contains three demos: (1) an example of large\nscale 2D parametrization, (2) an example of 2D deformation with soft\nconstraints, and (3) an example of 3D deformation with soft constraints. The\nimplementation in libigl is self-contained and relies on Eigen for the solution\nof the linear system used in the global step. An optimized version that relies\non Pardiso is available here .",
            "title": "Scalable Locally Injective Maps [slim]"
        },
        {
            "location": "/tutorial/chapter-7/#subdivision-surfaces-subdivision",
            "text": "Given a coarse mesh (aka cage) with vertices  V  and faces  F , one can createa\nhigher-resolution mesh with more vertices and faces by  subdividing  every\nface. That is, each coarse triangle in the input is replaced by many smaller\ntriangles. Libigl has three different methods for subdividing a triangle mesh.  An \"in plane\" subdivision method will not change the point set or carrier\nsurface of the mesh. New vertices are added on the planes of existing triangles\nand vertices surviving from the original mesh are not moved.  By adding new faces, a subdivision algorithm changes the  combinatorics  of the\nmesh. The change in combinatorics and the formula for positioning the\nhigh-resolution vertices is called the \"subdivision rule\".  For example, in the  in plane  subdivision method of  igl::upsample , vertices\nare added at the midpoint of every edge:  v_{ab} = \\frac{1}{2}(v_a + v_b) v_{ab} = \\frac{1}{2}(v_a + v_b)  and\neach triangle  (i_a,i_b,i_c) (i_a,i_b,i_c)  is replaced with four triangles: (i_a,i_{ab},i_{ca}) (i_a,i_{ab},i_{ca}) ,  (i_b,i_{bc},i_{ab}) (i_b,i_{bc},i_{ab}) ,  (i_{ab},i_{bc},i_{ca}) (i_{ab},i_{bc},i_{ca}) , and (i_{bc},i_{c},i_{ca}) (i_{bc},i_{c},i_{ca}) . This process may be applied recursively, resulting in\na finer and finer mesh.  The subdivision method of  igl::loop  is not in plane. The vertices of the\nrefined mesh are moved to weight combinations of their neighbors: the mesh is\nsmoothed as it is refined [#loop_1987]. This and other  smooth subdivision \nmethods can be understood as generalizations of spline curves to surfaces. In\nparticular the Loop subdivision method will converge to a  C^1 C^1  surface as we\nconsider the limit of recursive applications of subdivision. Away from\n\"irregular\" or \"extraordinary\" vertices (vertices of the original cage with\nvalence not equal to 6), the surface is  C^2 C^2 . The combinatorics (connectivity\nand number of faces) of  igl::loop  and  igl::upsample  are identical: the only\ndifference is that the vertices have been smoothed in  igl::loop .  Finally, libigl also implements a form of  in plane  \"false barycentric\nsubdivision\" in  igl::false_barycentric_subdivision . This method simply adds\nthe barycenter of every triangle as a new vertex  v_{abc} v_{abc}  and replaces each\ntriangle with three triangles  (i_a,i_b,i_{abc}) (i_a,i_b,i_{abc}) ,  (i_b,i_c,i_{abc}) (i_b,i_c,i_{abc}) , and (i_c,i_a,i_{abc}) (i_c,i_a,i_{abc}) . In contrast to  igl::upsample , this method will create\ntriangles with smaller and smaller internal angles and new vertices will sample\nthe carrier surfaces with extreme bias.",
            "title": "Subdivision surfaces [subdivision]"
        },
        {
            "location": "/tutorial/chapter-7/#data-smoothing-datasmoothing",
            "text": "A noisy function  f f  defined on a surface  \\Omega \\Omega  can be smoothed using an\nenergy minimization that balances a smoothing term  E_S E_S  with a quadratic\nfitting term:  u = \\operatorname{argmin}_u \\alpha E_S(u) + (1-\\alpha)\\int_\\Omega ||u-f||^2 dx u = \\operatorname{argmin}_u \\alpha E_S(u) + (1-\\alpha)\\int_\\Omega ||u-f||^2 dx  The parameter  \\alpha \\alpha  determines how aggressively the function is smoothed.  A classical choice for the smoothness energy is the Laplacian energy of the\nfunction with zero Neumann boundary conditions, which is a form of the\nbiharmonic energy. It is constructed using the cotangent Laplacian  L  and\nthe mass matrix  M :  QL = L'*(M\\L) . Because of the implicit zero Neumann\nboundary conditions however, the function behavior is significantly warped at\nthe boundary if  f f  does not have zero normal gradient at the boundary.  In #[stein_2017] it is suggested to use the Biharmonic energy with natural\nHessian boundary conditions instead, which corresponds to the hessian energy\nwith the matrix  QH = H'*(M2\\H) , where  H  is a finite element Hessian and M2  is a stacked mass matrix. The matrices  H  and  QH  are implemented in\nlibigl as  igl::hessian  and  igl::hessian_energy  respectively. An example\nof how to use the function is given in  Example 712 .  In the following image the differences between the Laplacian energy with\nzero Neumann boundary conditions and the Hessian energy can be clearly seen:\nwhereas the zero Neumann boundary condition in the third image bias the isolines\nof the function to be perpendicular to the boundary, the Hessian energy gives\nan unbiased result.",
            "title": "Data smoothing [datasmoothing]"
        },
        {
            "location": "/tutorial/chapter-7/#shapeup-projections-shapeup",
            "text": "Our input is a set of points  P_0 P_0  (not necessarily part of any mesh), and a set of constraints  S=\\left\\{S_1,S_2,...S_m\\right\\} S=\\left\\{S_1,S_2,...S_m\\right\\} , where each constraint is defined on a different, and sparse, subset of  P_0 P_0 . We wish to create a new set of points  P P  that are close to the original set  P_0 P_0  (each point with corresponding indices), while adhering to the constraints. Other objectives, such as smoothness, can be employed. The constraints can be nonlinear, which makes the problem nonconvex, difficult, and without a guaranteed global optimum. A very popular lightweight approach to such problems is a local-global iterative algorithm, comprising these two steps:  For iteration  k k :\n1.  Local step : compute the projections of the set  P_{k-1} P_{k-1}  onto  S S , individually per constraint; that would mean fragmenting each point that appears in multiple constraints. That can be a nonlinear operation, but if the constraints are sparse, it is a a set of many small systems.\n2.  Global step : integrate the set  P_k P_k  to be as close as possible to the projected fragmented set, with auxiliary objective functions possible. That results in a global, but quadratic objective function. Moreover, the resulting linear system has a constant matrix, and therefore can be pre-factored.  The version we implement in libigl is the general version described by [#bouaziz_2012], and is in two files:  <igl/shapeup.h>  and  <igl/shapeup_local_projections.h> . A demo implementing regularity constraints (creating a mesh in which each face is as regular as possible) is in  Example 713 .   The local step is instantiated by a function of type  igl::shapeup_projection_function . The global step is done by two functions:  igl::shapeup_precomputation() , which precomputes the matrices required for the global step, and  igl::shapeup_solve() , which solves the problem, according to the initial solution  P_0 P_0  and the input local projection function. The data struct  igl::ShapeUpData  contains the information necessary to run the algorithm, and can be configured; for instance, the self-explanatory variable  Maxiterations .  The global step minimizes the following energy:   E_{total}=\\lambda_{shape}E_{shape}+\\lambda_{close}E_{close}+\\lambda_{smooth}E_{smooth},  E_{total}=\\lambda_{shape}E_{shape}+\\lambda_{close}E_{close}+\\lambda_{smooth}E_{smooth},   where the  \\lambda \\lambda  coefficients are encoded in  igl::ShapeUpData , and can be updated  prior  to calling  igl::shapeup_precomputation() . The  E_{shape} E_{shape}  component is the integration energy (fitting  P_k P_k  to the local projections). The  E_{close} E_{close}  component is adherence to positional constraints, given by  b  and  bc  parameters. The  E_{smooth} E_{smooth}  component is an optional objective function, to minimize differences (in the Dirichlet sense) between points, encodes by \"edges\" in parameter  E . Both  E_{close} E_{close}  and  E_{shape} E_{shape}  are also weighted by  wClose  and  wShape  function parameters, respectively.",
            "title": "ShapeUp Projections [shapeup]"
        },
        {
            "location": "/tutorial/chapter-8/",
            "text": "Outlook for continuing development [future]\n\u00b6\n\n\nLibigl is in active development, and we plan to focus on the following features\nin the next months:\n\n\n\n\n\n\nA better and more consistent \ndocumentation\n, plus extending this tutorial\n  to cover more libigl features.\n\n\n\n\n\n\nImplement a \nmixed-integer solver\n which only uses Eigen to remove the\n  dependency on CoMiSo.\n\n\n\n\n\n\nImprove the robustness and performance of the active set QP solver. In\n  particular, handle linearly dependent constraints.\n\n\n\n\n\n\nImplement more mesh analysis functions, including structural analysis for\n  masonry and \n3D-printability\n analysis.\n\n\n\n\n\n\nIncrease support for point clouds and general polygonal meshes.\n\n\n\n\n\n\nWhat would you like to see in libigl? \nContact\n  us!\n or post a \nfeature\n  request\n.\n\n\n\n\n\n\nWe encourage you to contribute to the library and to report problems and bugs.\nThe best way to contribute new feature or bug fixes is to fork the libigl\nrepository and to open a \npull\nrequest\n on \nour github\nrepository\n.",
            "title": "Chapter 8: Outlook for continuing development"
        },
        {
            "location": "/tutorial/chapter-8/#outlook-for-continuing-development-future",
            "text": "Libigl is in active development, and we plan to focus on the following features\nin the next months:    A better and more consistent  documentation , plus extending this tutorial\n  to cover more libigl features.    Implement a  mixed-integer solver  which only uses Eigen to remove the\n  dependency on CoMiSo.    Improve the robustness and performance of the active set QP solver. In\n  particular, handle linearly dependent constraints.    Implement more mesh analysis functions, including structural analysis for\n  masonry and  3D-printability  analysis.    Increase support for point clouds and general polygonal meshes.    What would you like to see in libigl?  Contact\n  us!  or post a  feature\n  request .    We encourage you to contribute to the library and to report problems and bugs.\nThe best way to contribute new feature or bug fixes is to fork the libigl\nrepository and to open a  pull\nrequest  on  our github\nrepository .",
            "title": "Outlook for continuing development [future]"
        },
        {
            "location": "/example-project/",
            "text": "libigl example project\n\u00b6\n\n\nA blank project example showing how to use libigl and cmake. Feel free and\nencouraged to copy or fork this project as a way of starting a new personal\nproject using libigl.\n\n\nSee the tutorial first\n\u00b6\n\n\nThen build, run and understand the \nlibigl\ntutorial\n.\n\n\nCompile\n\u00b6\n\n\nCompile this project using the standard cmake routine:\n\n\nmkdir build\ncd build\ncmake ..\nmake\n\n\n\n\n\nThis should find and build the dependencies and create a \nexample_bin\n binary.\n\n\nRun\n\u00b6\n\n\nFrom within the \nbuild\n directory just issue:\n\n\n./example_bin\n\n\n\n\n\nA glfw app should launch displaying a 3D cube.\n\n\nDependencies\n\u00b6\n\n\nThe only dependencies are stl, eigen, \nlibigl\n and\nthe dependencies of the \nigl::opengl::glfw::Viewer\n.\n\n\nWe recommend you to install libigl using git via:\n\n\ngit clone https://github.com/libigl/libigl.git\ncd libigl/\ngit checkout 6ebc585611d27d8e2038bbbf9cb4910c51713848\ngit submodule update --init --recursive\ncd ..\n\n\n\n\n\nIf you have installed libigl at \n/path/to/libigl/\n then a good place to clone\nthis library is \n/path/to/libigl-example-project/\n.",
            "title": "Example Project"
        },
        {
            "location": "/example-project/#libigl-example-project",
            "text": "A blank project example showing how to use libigl and cmake. Feel free and\nencouraged to copy or fork this project as a way of starting a new personal\nproject using libigl.",
            "title": "libigl example project"
        },
        {
            "location": "/example-project/#see-the-tutorial-first",
            "text": "Then build, run and understand the  libigl\ntutorial .",
            "title": "See the tutorial first"
        },
        {
            "location": "/example-project/#compile",
            "text": "Compile this project using the standard cmake routine:  mkdir build\ncd build\ncmake ..\nmake  This should find and build the dependencies and create a  example_bin  binary.",
            "title": "Compile"
        },
        {
            "location": "/example-project/#run",
            "text": "From within the  build  directory just issue:  ./example_bin  A glfw app should launch displaying a 3D cube.",
            "title": "Run"
        },
        {
            "location": "/example-project/#dependencies",
            "text": "The only dependencies are stl, eigen,  libigl  and\nthe dependencies of the  igl::opengl::glfw::Viewer .  We recommend you to install libigl using git via:  git clone https://github.com/libigl/libigl.git\ncd libigl/\ngit checkout 6ebc585611d27d8e2038bbbf9cb4910c51713848\ngit submodule update --init --recursive\ncd ..  If you have installed libigl at  /path/to/libigl/  then a good place to clone\nthis library is  /path/to/libigl-example-project/ .",
            "title": "Dependencies"
        },
        {
            "location": "/static-library/",
            "text": "Compiling libigl as a static library\n\u00b6\n\n\n\n\nWarning: compiling libigl as a static library is considerably more difficult\nthan using it as a header-only library (see \n../README.md\n instead). Do\nit only if you are experienced with C++, cmake and make, and you want to\nimprove your compilation times.\n\n\n\n\nLibigl is developed most often on Mac OS X, though has current users in Linux\nand Windows.\n\n\nLinux/Mac OS X/Cygwin\n\u00b6\n\n\nLibigl may also be compiled to a static library. This is advantageous when\nbuilding a project with libigl, since when used as an header-only library can\nslow down compile times.\n\n\nTo build the entire libigl library producing at least \nlibigl/lib/libigl.a\n and\npossible other (automatically detected) extras, e.g. \nlibigl/lib/libiglcgal.a\n\nfrom \nthis current directory\n: issue:\n\n\nmkdir -p ../lib\ncd ../lib\ncmake -DCMAKE_BUILD_TYPE=Release ../optional\nmake\n\n\n\n\n\nWarnings\n\u00b6\n\n\nYou should expect to see a few linker warnings of the form:\n\n\n/opt/local/bin/ranlib: file: libigl.a(*.cpp.o) has no symbols\n\n\n\n\n\nThese are (admittedly unpopular) functions that have never been used by us\nstatically so we haven't explicit instantiations (yet).\n\n\nExternal\n\u00b6\n\n\nFinally there are a number of external libraries that we include in\n\n./external/\n because they are either difficult to obtain or they have been\npatched for easier use with libigl. Please see the respective readmes in those\ndirectories or build the tutorial using cmake, which will recursively build all\ndependencies.\n\n\nInstalling Embree 2.0\n\u00b6\n\n\nTo build the embree library and executables on Mac OS X issue:\n\n\ncd external/embree\nmkdir build\ncd build\ncmake ..\n# Or using a different compiler\n#cmake .. -DCMAKE_C_COMPILER=/opt/local/bin/gcc -DCMAKE_CXX_COMPILER=/opt/local/bin/g++\nmake\n# Could also install embree to your root, but libigl examples don't expect\n# this\n#sudo make install\n\n\n\n\n\nExtras\n\u00b6\n\n\nbbw\n\u00b6\n\n\nThis library extra contains functions for computing Bounded Biharmonic Weights, can\nbe used with and without the \nmosek\n extra via the \nIGL_NO_MOSEK\n\nmacro.\n\n\nboolean\n\u00b6\n\n\nThis library extra contains functions for computing mesh-mesh booleans,\ndepending on CGAL and optionally Cork.\n\n\ncgal\n\u00b6\n\n\nThis library extra utilizes CGAL's efficient and exact intersection and\nproximity queries.\n\n\nembree\n\u00b6\n\n\nThis library extra utilizes embree's efficient ray tracing queries.\n\n\nmatlab\n\u00b6\n\n\nThis library extra provides support for reading and writing \n.mat\n workspace\nfiles, interfacing with Matlab at run time and compiling mex functions.\n\n\nmosek\n\u00b6\n\n\nThis library extra utilizes mosek's efficient interior-point solver for\nquadratic programs.\n\n\npng\n\u00b6\n\n\nThis library extra uses \nlibpng\n and \nYImage\n to read and write \n.png\n files.\n\n\ntetgen\n\u00b6\n\n\nThis library extra provides a simplified wrapper to the tetgen 3d tetrahedral\nmeshing library.\n\n\nTriangle\n\u00b6\n\n\nThis library extra provides a simplified wrapper to the triangle 2d triangle\nmeshing library.\n\n\nviewer\n\u00b6\n\n\nThis library extra utilizes glfw and glew to open an opengl context and launch\na simple mesh viewer.\n\n\nxml\n\u00b6\n\n\nThis library extra utilizes tinyxml2 to read and write serialized classes\ncontaining Eigen matrices and other standard simple data-structures.\n\n\nDevelopment\n\u00b6\n\n\nFurther documentation for developers is listed in \n\nstyle_guidelines.html\n.\n\n\nLicense\n\u00b6\n\n\nSee \nLICENSE.txt\n\n\nZipping\n\u00b6\n\n\nZip this directory without .git litter and binaries using:\n\n\ngit archive -prefix=libigl/ -o libigl.zip master\n\n\n\n\n\nExplicit instantiations of templated functions\n\u00b6\n\n\nSpecial care must be taken by the developers of each function and\nclass in the libigl library that uses C++ templates. If this function\nis intended to be compiled into the statically linked libigl library\nthen function is only compiled for each \nexplicitly\n instantiated \ndeclaration. These should be added at the bottom of the corresponding\n.cpp file surrounded by a\n\n\n#ifdef IGL_STATIC_LIBRARY\n\n\n\n\n\n\nOf course, a developer may not know ahead of time which\ninstantiations should be explicitly included in the igl static lib.\nOne way to find out is to add one explicit instantiation for each\ncall in one's own project. This only ever needs to be done once for\neach template.\n\n\nThe process is somewhat mechanical using a linker with reasonable error\noutput.\n\n\nSupposed for example we have compiled the igl static lib, including the\ncat.h and cat.cpp functions, without any explicit instantiation. Say\nusing the makefile in the \nlibigl\n directory:\n\n\ncd $LIBIGL\nmake\n\n\n\n\n\nNow if we try to compile a project and link against it we may get\nan error like:\n\n\nUndefined symbols for architecture x86_64:\n\"Eigen::Matrix<int, -1, -1, 0, -1, -1> igl::cat<Eigen::Matrix<int, -1, -1, 0, -1, -1> >(int, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&)\", referenced from:\nuniform_sample(Eigen::Matrix<double, -1, -1, 0, -1, -1> const&, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&, int, double, Eigen::Matrix<double, -1, -1, 0, -1, -1>&)in Skinning.o\n\"Eigen::SparseMatrix<double, 0, int> igl::cat<Eigen::SparseMatrix<double, 0, int> >(int, Eigen::SparseMatrix<double, 0, int> const&, Eigen::SparseMatrix<double, 0, int> const&)\", referenced from:\ncovariance_scatter_matrix(Eigen::Matrix<double, -1, -1, 0, -1, -1> const&, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&, ArapEnergy, Eigen::SparseMatrix<double, 0, int>&)in arap_dof.o\narap_rhs(Eigen::Matrix<double, -1, -1, 0, -1, -1> const&, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&, ArapEnergy, Eigen::SparseMatrix<double, 0, int>&)in arap_dof.o\n\n\n\n\n\nThis looks like a mess, but luckily we don't really need to read it\nall. Just copy the first part in quotes\n\n\nEigen::Matrix<int, -1, -1, 0, -1, -1> igl::cat<Eigen::Matrix<int, -1, -1, 0, -1, -1> >(int, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&)\n\n\n\n\n\n, then append it\nto the list of explicit template instantiations at the end of\n\ncat.cpp\n after the word\n\ntemplate\n and followed by a semi-colon.\nLike this:\n\n\n#ifdef IGL_STATIC_LIBRARY\n\n\n// Explicit template instantiation\n\n\ntemplate\n \nEigen\n::\nMatrix\n<\nint\n,\n \n-\n1\n,\n \n-\n1\n,\n \n0\n,\n \n-\n1\n,\n \n-\n1\n>\n \nigl\n::\ncat\n<\nEigen\n::\nMatrix\n<\nint\n,\n \n-\n1\n,\n \n-\n1\n,\n \n0\n,\n \n-\n1\n,\n \n-\n1\n>\n \n>\n(\nint\n,\n \nEigen\n::\nMatrix\n<\nint\n,\n \n-\n1\n,\n \n-\n1\n,\n \n0\n,\n \n-\n1\n,\n \n-\n1\n>\n \nconst\n&\n,\n \nEigen\n::\nMatrix\n<\nint\n,\n \n-\n1\n,\n \n-\n1\n,\n \n0\n,\n \n-\n1\n,\n \n-\n1\n>\n \nconst\n&\n);\n\n\n#endif\n\n\n\n\n\n\nThen you must recompile the IGL static library.\n\n\ncd $LIBIGL\nmake\n\n\n\n\n\nAnd try to compile your project again, potentially repeating this\nprocess until no more symbols are undefined.\n\n\nIt may be useful to check that you code compiles withno errors first using the headers-only version to be sure that all errors are from missing templateinstantiations.\n\n\nIf you're using make then the following command will\nreveal each missing symbol on its own line:\n\n\nmake 2>&1 | grep \"referenced from\" | sed -e \"s/, referenced from.*//\"\n\n\n\n\n\nAlternatively you can use the \nautoexplicit.sh\n function\nwhich (for well organized .h/.cpp pairs in libigl) automatically\ncreate explicit instantiations from your compiler's error messages.\nRepeat this process until convergence:\n\n\ncd /to/your/project\nmake 2>$LIBIGL/make.err\ncd $LIBIGL\ncat make.err | ./autoexplicit.sh\nmake clean\nmake\n\n\n\n\n\nBenefits of static library\n\u00b6\n\n\n\n\nFaster compile time\n: Because the libigl library\n    is already compiled, only the new code in ones project must be\n    compiled and then linked to IGL. This means compile times are\n    generally faster.\n\n\nDebug or optimized\n: The IGL static\n    library may be compiled in debug mode or optimized release mode\n    regardless of whether one's project is being optimized or\n    debugged.\n\n\n\n\nDrawbacks of static library\n\u00b6\n\n\n\n\nHard to use templates\n: Special\n    care\n (by the developers of the library) needs to be taken when\n    exposing templated functions.\n\n\n\n\nCompressed .h/.cpp pair\n\u00b6\n\n\nCalling the script:\n\n\nscripts/compress.sh igl.h igl.cpp\n\n\n\n\n\nwill create a single header \nigl.h\n and a single cpp file \nigl.cpp\n.\n\n\nAlternatively, you can also compress everything into a single header file:\n\n\nscripts/compress.sh igl.h\n\n\n\n\n\nBenefits of compressed .h/.cpp pair\n\u00b6\n\n\n\n\nEasy incorporation\n: This can be easily incorporated\n  into external projects.\n\n\n\n\nDrawbacks of compressed .h/.cpp pair\n\u00b6\n\n\n\n\n\n\nHard to debug/edit\n: The compressed files are\n  automatically generated. They're huge and should not be edited. Thus\n  debugging and editing are near impossible.\n\n\n\n\n\n\nCompounded dependencies\n:\n  An immediate disadvantage of this\n  seems to be that even to use a single function (e.g.\n  \ncotmatrix\n), compiling and linking against\n  \nigl.cpp\n will require linking to all of \nlibigl\n's\n  dependencies (\nOpenGL\n, \nGLUT\n,\n  \nAntTweakBar\n, \nBLAS\n). However, because all\n  dependencies other than Eigen should be encapsulated between\n  \n#ifndef\n guards (e.g. \n#ifndef IGL_NO_OPENGL\n, it\n  is possible to ignore certain functions that have such dependencies.\n\n\n\n\n\n\nLong compile\n: \n  Compiling \nigl.cpp\n takes a long time and isn't easily parallelized (no \nmake-j12\n equivalent).\n\n\n\n\n\n\nHere's a tiny test example using \nigl.h\n and \nigl.cpp\n. Save the following in \ntest.cpp\n:\n\n\n#include\n \n<igl.h>\n\n\n#include\n \n<Eigen/Core>\n\n\n\nint\n \nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\n \nargv\n[])\n\n\n{\n\n\nEigen\n::\nMatrixXd\n \nV\n;\n\n\nEigen\n::\nMatrixXi\n \nF\n;\n\n\nreturn\n \n(\nargc\n>=\n2\n \n&&\n \nigl\n::\nread_triangle_mesh\n(\nargv\n[\n1\n],\nV\n,\nF\n)\n?\n0\n:\n1\n);\n\n\n}\n\n\n\n\n\n\nThen compile \nigl.cpp\n with:\n\n\ng++ -o igl.o -c igl.cpp -I/opt/local/include/eigen3 -DIGL_NO_OPENGL -DIGL_NO_ANTTWEAKBAR\n\n\n\n\n\nNotice that we're using \n-DIGL_NO_OPENGL -DIGL_NO_ANTTWEAKBAR\n to disable any libigl dependencies on OpenGL and AntTweakBar.\n\n\nNow compile \ntest.cpp\n with:\n\n\ng++ -g -I/opt/local/include/eigen3/ -I/usr/local/igl/libigl/ -L/usr/local/igl/libigl/ -ligl -DIGL_NO_OPENGL -DIGL_NO_ANTTWEAKBAR -o test\n\n\n\n\n\nTry running it with:\n\n\n./test path/to/mesh.obj\n\n\n\n\n\nThe following bash one-liner will find all source files that contain the string \nOpenGL\n but don't contain and \nIGL_NO_OPENGL\n guard:\n\n\ngrep OpenGL `grep -L IGL_NO_OPENGL include/igl/*`\n\n\n\n\n\nOptional\n\u00b6\n\n\n\n\nOpenGL (disable with \nIGL_NO_OPENGL\n)\n\n\nOpenGL >= 4 (enable with \nIGL_OPENGL_4\n)\n\n\n\n\n\n\nAntTweakBar  (disable with \nIGL_NO_ANTTWEAKBAR\n) Last tested 1.16 (see\n  \nlibigl/external/AntTweakBar\n)\n\n\nGLEW  Windows and Linux\n\n\nOpenMP\n\n\nlibpng  libiglpng extra only\n\n\nMosek  libiglmosek extra only\n\n\nMatlab  libiglmatlab extra only\n\n\nboost  libiglboost, libiglcgal extra only\n\n\nSSE/AVX  libiglsvd3x3 extra only\n\n\nCGAL  libiglcgal extra only\n\n\nboost\n\n\ngmp\n\n\nmpfr\n\n\n\n\n\n\nCoMiSo libcomiso extra only\n\n\n\n\nOptional (included in external/)\n\u00b6\n\n\n\n\nTetGen  libigltetgen extra only\n\n\nEmbree  libiglembree extra only\n\n\ntinyxml2  libiglxml extra only\n\n\nglfw libviewer extra only\n\n\nLIM  liblim extra only",
            "title": "Static Library"
        },
        {
            "location": "/static-library/#compiling-libigl-as-a-static-library",
            "text": "Warning: compiling libigl as a static library is considerably more difficult\nthan using it as a header-only library (see  ../README.md  instead). Do\nit only if you are experienced with C++, cmake and make, and you want to\nimprove your compilation times.   Libigl is developed most often on Mac OS X, though has current users in Linux\nand Windows.",
            "title": "Compiling libigl as a static library"
        },
        {
            "location": "/static-library/#linuxmac-os-xcygwin",
            "text": "Libigl may also be compiled to a static library. This is advantageous when\nbuilding a project with libigl, since when used as an header-only library can\nslow down compile times.  To build the entire libigl library producing at least  libigl/lib/libigl.a  and\npossible other (automatically detected) extras, e.g.  libigl/lib/libiglcgal.a \nfrom  this current directory : issue:  mkdir -p ../lib\ncd ../lib\ncmake -DCMAKE_BUILD_TYPE=Release ../optional\nmake",
            "title": "Linux/Mac OS X/Cygwin"
        },
        {
            "location": "/static-library/#warnings",
            "text": "You should expect to see a few linker warnings of the form:  /opt/local/bin/ranlib: file: libigl.a(*.cpp.o) has no symbols  These are (admittedly unpopular) functions that have never been used by us\nstatically so we haven't explicit instantiations (yet).",
            "title": "Warnings"
        },
        {
            "location": "/static-library/#external",
            "text": "Finally there are a number of external libraries that we include in ./external/  because they are either difficult to obtain or they have been\npatched for easier use with libigl. Please see the respective readmes in those\ndirectories or build the tutorial using cmake, which will recursively build all\ndependencies.",
            "title": "External"
        },
        {
            "location": "/static-library/#installing-embree-20",
            "text": "To build the embree library and executables on Mac OS X issue:  cd external/embree\nmkdir build\ncd build\ncmake ..\n# Or using a different compiler\n#cmake .. -DCMAKE_C_COMPILER=/opt/local/bin/gcc -DCMAKE_CXX_COMPILER=/opt/local/bin/g++\nmake\n# Could also install embree to your root, but libigl examples don't expect\n# this\n#sudo make install",
            "title": "Installing Embree 2.0"
        },
        {
            "location": "/static-library/#extras",
            "text": "",
            "title": "Extras"
        },
        {
            "location": "/static-library/#bbw",
            "text": "This library extra contains functions for computing Bounded Biharmonic Weights, can\nbe used with and without the  mosek  extra via the  IGL_NO_MOSEK \nmacro.",
            "title": "bbw"
        },
        {
            "location": "/static-library/#boolean",
            "text": "This library extra contains functions for computing mesh-mesh booleans,\ndepending on CGAL and optionally Cork.",
            "title": "boolean"
        },
        {
            "location": "/static-library/#cgal",
            "text": "This library extra utilizes CGAL's efficient and exact intersection and\nproximity queries.",
            "title": "cgal"
        },
        {
            "location": "/static-library/#embree",
            "text": "This library extra utilizes embree's efficient ray tracing queries.",
            "title": "embree"
        },
        {
            "location": "/static-library/#matlab",
            "text": "This library extra provides support for reading and writing  .mat  workspace\nfiles, interfacing with Matlab at run time and compiling mex functions.",
            "title": "matlab"
        },
        {
            "location": "/static-library/#mosek",
            "text": "This library extra utilizes mosek's efficient interior-point solver for\nquadratic programs.",
            "title": "mosek"
        },
        {
            "location": "/static-library/#png",
            "text": "This library extra uses  libpng  and  YImage  to read and write  .png  files.",
            "title": "png"
        },
        {
            "location": "/static-library/#tetgen",
            "text": "This library extra provides a simplified wrapper to the tetgen 3d tetrahedral\nmeshing library.",
            "title": "tetgen"
        },
        {
            "location": "/static-library/#triangle",
            "text": "This library extra provides a simplified wrapper to the triangle 2d triangle\nmeshing library.",
            "title": "Triangle"
        },
        {
            "location": "/static-library/#viewer",
            "text": "This library extra utilizes glfw and glew to open an opengl context and launch\na simple mesh viewer.",
            "title": "viewer"
        },
        {
            "location": "/static-library/#xml",
            "text": "This library extra utilizes tinyxml2 to read and write serialized classes\ncontaining Eigen matrices and other standard simple data-structures.",
            "title": "xml"
        },
        {
            "location": "/static-library/#development",
            "text": "Further documentation for developers is listed in  style_guidelines.html .",
            "title": "Development"
        },
        {
            "location": "/static-library/#license",
            "text": "See  LICENSE.txt",
            "title": "License"
        },
        {
            "location": "/static-library/#zipping",
            "text": "Zip this directory without .git litter and binaries using:  git archive -prefix=libigl/ -o libigl.zip master",
            "title": "Zipping"
        },
        {
            "location": "/static-library/#explicit-instantiations-of-templated-functions",
            "text": "Special care must be taken by the developers of each function and\nclass in the libigl library that uses C++ templates. If this function\nis intended to be compiled into the statically linked libigl library\nthen function is only compiled for each  explicitly  instantiated \ndeclaration. These should be added at the bottom of the corresponding\n.cpp file surrounded by a  #ifdef IGL_STATIC_LIBRARY   Of course, a developer may not know ahead of time which\ninstantiations should be explicitly included in the igl static lib.\nOne way to find out is to add one explicit instantiation for each\ncall in one's own project. This only ever needs to be done once for\neach template.  The process is somewhat mechanical using a linker with reasonable error\noutput.  Supposed for example we have compiled the igl static lib, including the\ncat.h and cat.cpp functions, without any explicit instantiation. Say\nusing the makefile in the  libigl  directory:  cd $LIBIGL\nmake  Now if we try to compile a project and link against it we may get\nan error like:  Undefined symbols for architecture x86_64:\n\"Eigen::Matrix<int, -1, -1, 0, -1, -1> igl::cat<Eigen::Matrix<int, -1, -1, 0, -1, -1> >(int, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&)\", referenced from:\nuniform_sample(Eigen::Matrix<double, -1, -1, 0, -1, -1> const&, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&, int, double, Eigen::Matrix<double, -1, -1, 0, -1, -1>&)in Skinning.o\n\"Eigen::SparseMatrix<double, 0, int> igl::cat<Eigen::SparseMatrix<double, 0, int> >(int, Eigen::SparseMatrix<double, 0, int> const&, Eigen::SparseMatrix<double, 0, int> const&)\", referenced from:\ncovariance_scatter_matrix(Eigen::Matrix<double, -1, -1, 0, -1, -1> const&, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&, ArapEnergy, Eigen::SparseMatrix<double, 0, int>&)in arap_dof.o\narap_rhs(Eigen::Matrix<double, -1, -1, 0, -1, -1> const&, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&, ArapEnergy, Eigen::SparseMatrix<double, 0, int>&)in arap_dof.o  This looks like a mess, but luckily we don't really need to read it\nall. Just copy the first part in quotes  Eigen::Matrix<int, -1, -1, 0, -1, -1> igl::cat<Eigen::Matrix<int, -1, -1, 0, -1, -1> >(int, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&, Eigen::Matrix<int, -1, -1, 0, -1, -1> const&)  , then append it\nto the list of explicit template instantiations at the end of cat.cpp  after the word template  and followed by a semi-colon.\nLike this:  #ifdef IGL_STATIC_LIBRARY  // Explicit template instantiation  template   Eigen :: Matrix < int ,   - 1 ,   - 1 ,   0 ,   - 1 ,   - 1 >   igl :: cat < Eigen :: Matrix < int ,   - 1 ,   - 1 ,   0 ,   - 1 ,   - 1 >   > ( int ,   Eigen :: Matrix < int ,   - 1 ,   - 1 ,   0 ,   - 1 ,   - 1 >   const & ,   Eigen :: Matrix < int ,   - 1 ,   - 1 ,   0 ,   - 1 ,   - 1 >   const & );  #endif   Then you must recompile the IGL static library.  cd $LIBIGL\nmake  And try to compile your project again, potentially repeating this\nprocess until no more symbols are undefined.  It may be useful to check that you code compiles withno errors first using the headers-only version to be sure that all errors are from missing templateinstantiations.  If you're using make then the following command will\nreveal each missing symbol on its own line:  make 2>&1 | grep \"referenced from\" | sed -e \"s/, referenced from.*//\"  Alternatively you can use the  autoexplicit.sh  function\nwhich (for well organized .h/.cpp pairs in libigl) automatically\ncreate explicit instantiations from your compiler's error messages.\nRepeat this process until convergence:  cd /to/your/project\nmake 2>$LIBIGL/make.err\ncd $LIBIGL\ncat make.err | ./autoexplicit.sh\nmake clean\nmake",
            "title": "Explicit instantiations of templated functions"
        },
        {
            "location": "/static-library/#benefits-of-static-library",
            "text": "Faster compile time : Because the libigl library\n    is already compiled, only the new code in ones project must be\n    compiled and then linked to IGL. This means compile times are\n    generally faster.  Debug or optimized : The IGL static\n    library may be compiled in debug mode or optimized release mode\n    regardless of whether one's project is being optimized or\n    debugged.",
            "title": "Benefits of static library"
        },
        {
            "location": "/static-library/#drawbacks-of-static-library",
            "text": "Hard to use templates : Special\n    care  (by the developers of the library) needs to be taken when\n    exposing templated functions.",
            "title": "Drawbacks of static library"
        },
        {
            "location": "/static-library/#compressed-hcpp-pair",
            "text": "Calling the script:  scripts/compress.sh igl.h igl.cpp  will create a single header  igl.h  and a single cpp file  igl.cpp .  Alternatively, you can also compress everything into a single header file:  scripts/compress.sh igl.h",
            "title": "Compressed .h/.cpp pair"
        },
        {
            "location": "/static-library/#benefits-of-compressed-hcpp-pair",
            "text": "Easy incorporation : This can be easily incorporated\n  into external projects.",
            "title": "Benefits of compressed .h/.cpp pair"
        },
        {
            "location": "/static-library/#drawbacks-of-compressed-hcpp-pair",
            "text": "Hard to debug/edit : The compressed files are\n  automatically generated. They're huge and should not be edited. Thus\n  debugging and editing are near impossible.    Compounded dependencies :\n  An immediate disadvantage of this\n  seems to be that even to use a single function (e.g.\n   cotmatrix ), compiling and linking against\n   igl.cpp  will require linking to all of  libigl 's\n  dependencies ( OpenGL ,  GLUT ,\n   AntTweakBar ,  BLAS ). However, because all\n  dependencies other than Eigen should be encapsulated between\n   #ifndef  guards (e.g.  #ifndef IGL_NO_OPENGL , it\n  is possible to ignore certain functions that have such dependencies.    Long compile : \n  Compiling  igl.cpp  takes a long time and isn't easily parallelized (no  make-j12  equivalent).    Here's a tiny test example using  igl.h  and  igl.cpp . Save the following in  test.cpp :  #include   <igl.h>  #include   <Eigen/Core>  int   main ( int   argc ,   char   *   argv [])  {  Eigen :: MatrixXd   V ;  Eigen :: MatrixXi   F ;  return   ( argc >= 2   &&   igl :: read_triangle_mesh ( argv [ 1 ], V , F ) ? 0 : 1 );  }   Then compile  igl.cpp  with:  g++ -o igl.o -c igl.cpp -I/opt/local/include/eigen3 -DIGL_NO_OPENGL -DIGL_NO_ANTTWEAKBAR  Notice that we're using  -DIGL_NO_OPENGL -DIGL_NO_ANTTWEAKBAR  to disable any libigl dependencies on OpenGL and AntTweakBar.  Now compile  test.cpp  with:  g++ -g -I/opt/local/include/eigen3/ -I/usr/local/igl/libigl/ -L/usr/local/igl/libigl/ -ligl -DIGL_NO_OPENGL -DIGL_NO_ANTTWEAKBAR -o test  Try running it with:  ./test path/to/mesh.obj  The following bash one-liner will find all source files that contain the string  OpenGL  but don't contain and  IGL_NO_OPENGL  guard:  grep OpenGL `grep -L IGL_NO_OPENGL include/igl/*`",
            "title": "Drawbacks of compressed .h/.cpp pair"
        },
        {
            "location": "/static-library/#optional",
            "text": "OpenGL (disable with  IGL_NO_OPENGL )  OpenGL >= 4 (enable with  IGL_OPENGL_4 )    AntTweakBar  (disable with  IGL_NO_ANTTWEAKBAR ) Last tested 1.16 (see\n   libigl/external/AntTweakBar )  GLEW  Windows and Linux  OpenMP  libpng  libiglpng extra only  Mosek  libiglmosek extra only  Matlab  libiglmatlab extra only  boost  libiglboost, libiglcgal extra only  SSE/AVX  libiglsvd3x3 extra only  CGAL  libiglcgal extra only  boost  gmp  mpfr    CoMiSo libcomiso extra only",
            "title": "Optional"
        },
        {
            "location": "/static-library/#optional-included-in-external",
            "text": "TetGen  libigltetgen extra only  Embree  libiglembree extra only  tinyxml2  libiglxml extra only  glfw libviewer extra only  LIM  liblim extra only",
            "title": "Optional (included in external/)"
        },
        {
            "location": "/third-party/",
            "text": "This directory contains external libraries which are either difficult to\nobtain, difficult to compile or patched for libigl.\n\n\nAntTweakBar\n\u00b6\n\n\nPatched to support copying and pasting from text fields (see\n\nhttp://www.alecjacobson.com/weblog/?p=2378\n)\n\n\nAdded makefiles for Mac OS X with modern GCC (AntTweakBar/src/Makefile.osx.igl)\nand for building with Mesa (AntTweakBar/src/Makefile.mesa.igl)\n\n\nEmbree\n\u00b6\n\n\nInstall \nispc\n  and \ntbb\n for example (\nbrew install ispc tbb\n),\nthen\n\n\nmkdir build\ncd build\ncmake -DCMAKE_C_COMPILER=/usr/bin/gcc -DCMAKE_CXX_COMPILER=/usr/bin/g++ -DCMAKE_BUILD_TYPE=Release ..\nmake\n\n\n\n\n\nTinyXML2\n\u00b6\n\n\ndouble precision bug fixes:\n\n\ntinyxml2.h line 1286 add function:\n\n\nvoid SetAttribute( const char* name, float value ) {\n    XMLAttribute* a = FindOrCreateAttribute( name );\n    a->SetAttribute( value );\n}\n\n\ntinyxml2.cpp line 434 replace with:\n\n\nTIXML_SNPRINTF( buffer, bufferSize, \"%.15e\", v );\n\n\nCGAL\n\u00b6\n\n\nCGAL can be built as a CMake external project thanks to the \nCMakeLists.txt\n provided in this folder. While this is mainly intended as a convenience for Windows users, and CI builds on AppVeyor, this should work on Linux/macOS as well. To build CGAL and Boost with the provided CMake script, build this folder as you would compile any CMake project (use CMake GUI and MSVC on Windows):\n\n\nmkdir build\ncd build\ncmake ..\nmake -j4\n\n\n\n\nOnce this is done, just build the libigl tutorials, and it should properly detect CGAL and Boost.",
            "title": "External Dependencies"
        },
        {
            "location": "/third-party/#anttweakbar",
            "text": "Patched to support copying and pasting from text fields (see http://www.alecjacobson.com/weblog/?p=2378 )  Added makefiles for Mac OS X with modern GCC (AntTweakBar/src/Makefile.osx.igl)\nand for building with Mesa (AntTweakBar/src/Makefile.mesa.igl)",
            "title": "AntTweakBar"
        },
        {
            "location": "/third-party/#embree",
            "text": "Install  ispc   and  tbb  for example ( brew install ispc tbb ),\nthen  mkdir build\ncd build\ncmake -DCMAKE_C_COMPILER=/usr/bin/gcc -DCMAKE_CXX_COMPILER=/usr/bin/g++ -DCMAKE_BUILD_TYPE=Release ..\nmake",
            "title": "Embree"
        },
        {
            "location": "/third-party/#tinyxml2",
            "text": "double precision bug fixes:  tinyxml2.h line 1286 add function:  void SetAttribute( const char* name, float value ) {\n    XMLAttribute* a = FindOrCreateAttribute( name );\n    a->SetAttribute( value );\n}  tinyxml2.cpp line 434 replace with:  TIXML_SNPRINTF( buffer, bufferSize, \"%.15e\", v );",
            "title": "TinyXML2"
        },
        {
            "location": "/third-party/#cgal",
            "text": "CGAL can be built as a CMake external project thanks to the  CMakeLists.txt  provided in this folder. While this is mainly intended as a convenience for Windows users, and CI builds on AppVeyor, this should work on Linux/macOS as well. To build CGAL and Boost with the provided CMake script, build this folder as you would compile any CMake project (use CMake GUI and MSVC on Windows):  mkdir build\ncd build\ncmake ..\nmake -j4  Once this is done, just build the libigl tutorials, and it should properly detect CGAL and Boost.",
            "title": "CGAL"
        },
        {
            "location": "/style-guidelines/",
            "text": "Libigl Style Guidelines\n\u00b6\n\n\nLibigl is used and developed by many people. This document highlights some\nstyle guidelines for \ndevelopers\n of the library, but also acts as\nbest-practices for users.\n\n\nOne function, one .h/.cpp pair\n\u00b6\n\n\nThe structure of libigl is very flat and function-based. For every\nfunction/sub-routine, create a single .h and .cpp file. For example, if you have\na function that determines connected components from a face list \nF\n you would\ncreate the header \nconnected_components.h\n and \nconnected_components.cpp\n and the only\nfunction defined should be \nvoid connected_components(const ... F, ... C)\n. If the\nimplementation of \nconnected_components\n requires a subroutine to compute an\nadjacency matrix then \ncreate another pair\n \nadjacency_matrix.h\n and\n\nadjacency_matrix.cpp\n with a single function \nvoid adjacency_matrix(const ... F, ... A)\n.\n\n\nExample\n\u00b6\n\n\nHere is an example function that would be defined in\n\ninclude/igl/example_fun.h\n and implemented in \ninclude/igl/example_fun.cpp\n.\n\n\nexample_fun.h\n\u00b6\n\n\n// This file is part of libigl, a simple c++ geometry processing library.\n\n\n// \n\n\n// Copyright (C) 2015 [Your Name] [your email address]\n\n\n// \n\n\n// This Source Code Form is subject to the terms of the Mozilla Public License \n\n\n// v. 2.0. If a copy of the MPL was not distributed with this file, You can \n\n\n// obtain one at http://mozilla.org/MPL/2.0/\n\n\n#ifndef IGL_EXAMPLE_FUN_H\n\n\n#define IGL_EXAMPLE_FUN_H\n\n\n\n#include\n \n\"igl_inline.h\"\n\n\n\nnamespace\n \nigl\n\n\n{\n\n  \n// This is an example of a function, it takes a templated parameter and\n\n  \n// shovels it into cout\n\n  \n//\n\n  \n// Input:\n\n  \n//   input  some input of a Printable type\n\n  \n// Returns true for the sake of returning something\n\n  \ntemplate\n \n<\ntypename\n \nPrintable\n>\n\n  \nIGL_INLINE\n \nbool\n \nexample_fun\n(\nconst\n \nPrintable\n \n&\n \ninput\n);\n\n\n}\n\n\n\n#ifndef IGL_STATIC_LIBRARY\n\n\n#  include \"example_fun.cpp\"\n\n\n#endif\n\n\n\n#endif\n\n\n\n\n\nexample_fun.cpp\n\u00b6\n\n\n// This file is part of libigl, a simple c++ geometry processing library.\n\n\n// \n\n\n// Copyright (C) 2015 [Your Name] [your email address]\n\n\n// \n\n\n// This Source Code Form is subject to the terms of the Mozilla Public License \n\n\n// v. 2.0. If a copy of the MPL was not distributed with this file, You can \n\n\n// obtain one at http://mozilla.org/MPL/2.0/\n\n\n#include\n \n\"igl/example_fun.h\"\n\n\n#include\n \n<iostream>\n\n\n\ntemplate\n \n<\ntypename\n \nPrintable\n>\n\n\nIGL_INLINE\n \nbool\n \nigl\n::\nexample_fun\n(\nconst\n \nPrintable\n \n&\n \ninput\n)\n\n\n{\n\n  \nusing\n \nnamespace\n \nstd\n;\n\n  \ncout\n<<\n\"example_fun: \"\n<<\ninput\n<<\nendl\n;\n\n  \nreturn\n \ntrue\n;\n\n\n}\n\n\n\n#ifdef IGL_STATIC_LIBRARY\n\n\ntemplate\n \nbool\n \nigl\n::\nexample_fun\n<\ndouble\n>\n(\nconst\n \ndouble\n&\n \ninput\n);\n\n\ntemplate\n \nbool\n \nigl\n::\nexample_fun\n<\nint\n>\n(\nconst\n \nint\n&\n \ninput\n);\n\n\n#endif\n\n\n\n\n\nAvoid static \"helper\" functions\n\u00b6\n\n\nStrive to encapsulate sub-functions that could possibly be useful outside of\nthe implementation of your current function. This might mean abstracting the\ninterface a bit. If it doesn't dramatically effect performance then create a\nnew pair of .h/.cpp files with this sub-function.\n\n\nLambda functions\n\u00b6\n\n\nIf encapsulation in a separate file is not possible or does not make sense,\nthen avoid crowding the namespace by creating lambda functions within the\nfunction implementation.\n\n\nThese lambda functions must still be documented with clear \ninput and output\narguments\n. Avoid using full capturing of all automatic\nvariables: do not use \n[&]\n or \n[=]\n. Rather specify each captured variable\nindividually.\n\n\nAvoid \"helper\" classes\n\u00b6\n\n\nLibigl is built around the high-performance paradigm of \"struct of arrays\"\nrather than \"array of structs\". The way we achieve this is to avoid classes and\npass \"basic types\" directly. The price we pay is long function interfaces, but\nthis increases code reuse dramatically. A \"basic type\" in our context is a\nEigen type, stl type, or basic C type.\n\n\nHeader Documentation\n\u00b6\n\n\nEach function prototype should be well documented in its corresponding .h\nheader file. A typical documentation consists of four parts:\n\n\n// [A human readable description of what the function does.]\n\n\n//\n\n\n// Inputs:\n\n\n//   [variable name of first (const) input]   [dimensions and description of\n\n\n//     this input variable]\n\n\n//   [variable name of second (const) input]   [dimensions and description of\n\n\n//     this input variable]\n\n\n//   ...\n\n\n// Outputs:\n\n\n//   [variable name of first output ]   [dimensions and description of this\n\n\n//     output variable]\n\n\n//   [variable name of second output ]   [dimensions and description of this\n\n\n//     output variable]\n\n\n//   ...\n\n\n// Returns [description of return value]\n\n\n\n\n\nExample\n\u00b6\n\n\nFor example the header \nbarycenter.h\n\n\n// Computes the barycenter of every simplex\n//\n// Inputs:\n//   V  #V by dim matrix of vertex coordinates\n//   F  #F by simplex_size  matrix of indices of simplex corners into V\n// Output:\n//   BC  #F by dim matrix of 3d vertices\n//\n\n\n\n\nConst inputs\n\u00b6\n\n\nAll input parameters should be demarcated \nconst\n. If an input is also an\noutput than consider exposing two parameters (one \nconst\n) or be sure to list\nthe variable under both \n// Inputs:\n and \n// Outputs:\n in the header comments.\n\n\nReference parameters\n\u00b6\n\n\nAll but simple types should be passed by reference (e.g. \nMatrix & mat\n) rather\nthan pointers (e.g. \nMatrix * mat\n) or value (e.g. \nMatrix mat\n).\n\n\nReturns vs output parameters\n\u00b6\n\n\nAll functions should be implemented with at least one overload that has a\n\nvoid\n or simple return type (e.g. \nbool\n on success/failure). With this\nimplementation its then possible to write an overload that returns a single\noutput. Please see \nTemplating with Eigen\n.\n\n\nFor example:\n\n\ntemplate\n \n<\ntypename\n \nAtype\n>\n\n\nvoid\n \nadjacency_matrix\n(\nconst\n \n...\n \n&\n \nF\n,\n \nEigen\n::\nSparseMatrix\n<\nAType\n>\n \n&\n \nA\n);\n\n\n\ntemplate\n \n<\ntypename\n \nAtype\n>\n\n\nEigen\n::\nSparseMatrix\n<\nAtype\n>\n \nadjacency_matrix\n(\nconst\n \n...\n \n&\n \nF\n);\n\n\n\n\n\nTemplating with Eigen\n\u00b6\n\n\nFunctions taking Eigen dense matrices/arrays as inputs and outputs (but \nnot\n\nreturn arguments), should template on top of \nEigen::MatrixBase\n. \nEach\nparameter\n should be derived using its own template.\n\n\nFor example,\n\n\ntemplate\n \n<\ntypename\n \nDerivedV\n,\n \ntypename\n \nDerivedF\n,\n \ntypename\n \nDerivedBC\n>\n\n\nvoid\n \nbarycenter\n(\n\n  \nconst\n \nEigen\n::\nMatrixBase\n<\nDerivedV\n>\n \n&\n \nV\n,\n\n  \nconst\n \nEigen\n::\nMatrixBase\n<\nDerivedF\n>\n \n&\n \nF\n,\n\n  \nconst\n \nEigen\n::\nMatrixBase\n<\nDerivedBC\n>\n \n&\n \nBC\n);\n\n\n\n\n\nThe \nDerived*\n template encodes the scalar type (e.g. \ndouble\n, \nint\n), the\nnumber of rows and cols at compile time, and the data storage (Row-major vs.\ncolumn-major). \n\n\nReturning Eigen types is discouraged. In cases where the size and scalar type\nare a fixed \nand matching\n function of an input \nDerived*\n template, then\nreturn that \nDerived*\n type. \nDo not\n return\n\nEigen::PlainObjectBase<...>\n types. For example, this function scales fits a\ngiven set of points to the unit cube. The return is a new set of vertex\npositions so its type should \nmatch\n that of the input points:\n\n\ntemplate\n \n<\ntypename\n \nDerivedV\n>\n\n\nvoid\n \nDerivedV\n \nfit_to_unit_cube\n(\nconst\n \nEigen\n::\nPlainObjectBase\n<\nDerivedV\n>\n \n&\n \nV\n);\n\n\n\n\n\nTo implement this function, it is \nrequired\n to implement a more generic\noutput-argument version and call that. So a full implementation looks like:\n\n\nIn \nigl/fit_in_unit_cube.h\n:\n\n\ntemplate\n \n<\ntypename\n \nDerivedV\n,\n \ntypename\n \nDerivedW\n>\n\n\nvoid\n \nfit_to_unit_cube\n(\n\n  \nconst\n \nEigen\n::\nMatrixBase\n<\nDerivedV\n>\n \n&\n \nV\n,\n\n  \nEigen\n::\nPlainObjectBase\n<\nDerivedW\n>\n \n&\n \nW\n);\n\n\ntemplate\n \n<\ntypename\n \nDerivedV\n>\n\n\nvoid\n \nDerivedV\n \nfit_to_unit_cube\n(\nconst\n \nEigen\n::\nPlainObjectBase\n<\nDerivedV\n>\n \n&\n \nV\n);\n\n\n\n\n\nIn \nigl/fit_in_unit_cube.cpp\n:\n\n\ntemplate <typename DerivedV, typename DerivedW>\nvoid fit_to_unit_cube(\n  const Eigen::MatrixBase<DerivedV> & V,\n  Eigen::PlainObjectBase<DerivedW> & W)\n{\n  W = (V.rowwise()-V.colwise().minCoeff()).array() /\n    (V.maxCoeff()-V.minCoeff());\n}\n\ntemplate <typename DerivedV>\nvoid DerivedV fit_to_unit_cube(const Eigen::MatrixBase<DerivedV> & V)\n{\n  DerivedV W;\n  fit_to_unit_cube(V,W);\n  return W;\n}\n\n\n\n\nNotice that \nW\n is declared as a \nDerivedV\n type and \nnot\n\n\nEigen::PlainObjectBase<DerivedV>\n type.\n\n\nNote:\n Not all functions are suitable for returning Eigen types. For example\n\nigl::barycenter\n above outputs a #F by dim list of barycenters. Returning a\n\nDerivedV\n type would be inappropriate since the number of rows in \nDerivedV\n\nwill be #V and may not match the number of rows in \nDerivedF\n (#F).\n\n\nFunction naming conventions\n\u00b6\n\n\nFunctions (and \nthus also files\n) should have simple,\ndescriptive names using lowercase letters and underscores between words. Avoid\nunnecessary prefaces. For example, instead of \ncompute_adjacency_matrix\n,\n\nconstruct_adjacency_matrix\n, \nextract_adjacency_matrix\n,\n\nget_adjacency_matrix\n, or \nset_adjacency_matrix\n just call the function\n\nadjacency_matrix\n.\n\n\nVariable naming conventions\n\u00b6\n\n\nLibigl prefers short (even single character) variable names \nwith heavy\ndocumentation\n in the comments in the header file or above the declaration of\nthe function. When possible use \nV\n to mean a list of vertex positions and \nF\n\nto mean a list of faces/triangles.\n\n\nClass naming conventions\n\u00b6\n\n\nClasses should be avoided. When naming a class use CamelCase (e.g.\nSortableRow.h).\n\n\nEnum naming conversion\n\u00b6\n\n\nEnums types should be placed in the appropriate \nigl::\n namespace and should be\nnamed in CamelCase (e.g. \nigl::SolverStatus\n) and instances should be named in\nALL_CAPS with underscores between words and prefaced with the name of the enum.\nFor example:\n\n\nnamespace\n \nigl\n\n\n{\n\n  \nenum\n \nSolverStatus\n\n  \n{\n\n    \n// Good\n\n    \nSOLVER_STATUS_CONVERGED\n \n=\n \n0\n,\n\n    \n// OK\n\n    \nSOLVER_STATUS_MAX_ITER\n \n=\n \n1\n,\n\n    \n// Bad\n\n    \nSOLVER_STATUS_ERROR\n \n=\n \n2\n,\n\n    \nNUM_SOLVER_STATUSES\n \n=\n \n3\n,\n\n  \n};\n\n\n};\n\n\n\n\n\nException for file IO\n\u00b6\n\n\nFor legacy reasons, file reading and writing functions use a different naming\nconvention. A functions reading a \n.xyz\n file should be named \nreadXYZ\n and a\nfunction writing \n.xyz\n files should be names \nwriteXYZ\n.\n\n\nusing\n \nnamespace\n \n...\n in global scope\n\u00b6\n\n\nWriting \nusing\n \nnamespace\n \nstd\n;\n, \nusing\n \nnamespace\n \nEigen\n;\n etc. outside of a\nglobal scope is strictly forbidden. Place these lines at the top of each\nfunction instead.\n\n\nNamespaces and external dependencies\n\u00b6\n\n\nFunctions in the main library (directly in \ninclude/igl\n) should only depend on\nEigen and stl. These functions should have the \nigl::\n namespace.\n\n\nFunctions with other dependencies should be placed into\nappropriate sub-directories (e.g. if \nmyfunction\n depends on tetgen then create\n\nigl/copyleft/tetgen/myfunction.h\n and \nigl/copyleft/tetgen/myfunction.cpp\n and give the function\nthe namespace \nigl::copyleft::tetgen::myfunction\n.\n\n\ncopyleft subdirectory/namespace\n\u00b6\n\n\nDependencies that require users of libigl to release their projects open source\n(e.g. GPL) are considered aggressively \"copyleft\" and should be placed in the\n\ninclude/igl/copyleft/\n sub-directory and \nigl::copyleft::\n namespace.\n\n\nAssertions\n\u00b6\n\n\nBe generous with assertions and always identify the assertion with strings:\n\n\nassert\n(\nm\n \n<\n \nn\n \n&&\n \n\"m must be less than n\"\n);\n\n\n\n\n\nifndef include guard\n\u00b6\n\n\nEvery header file should be wrapped in an \n#ifndef\n compiler directive. The\nname of the guard should be in direct correspondence with the path of the .h\nfile. For example, \ninclude/igl/copyleft/tetgen/tetrahedralize.h\n should be\n\n\n#ifndef IGL_COPYLEFT_TETGEN_TETRAHEDRALIZE_H\n\n\n#define IGL_COPYLEFT_TETGEN_TETRAHEDRALIZE_H\n\n\n...\n\n\n#endif\n\n\n\n\n\nSpaces vs. tabs indentation\n\u00b6\n\n\nDo not use tabs. Use 2 spaces for each indentation level.\n\n\nMax line length\n\u00b6\n\n\nLimit lines to 80 characters. Break up long lines into many operations (this\nalso helps performance).\n\n\nInclude order\n\u00b6\n\n\n#include\n directives at the top of a .h or .cpp file should be sorted\naccording to a simple principle: place headers of files most likely to be\nedited by you first. This means for\n\ninclude/igl/copyleft/tetgen/tetrahedralize.cpp\n you might see\n\n\n// [Includes of headers in this directory]\n\n\n#include\n \n\"tetrahedralize.h\"\n\n\n#include\n \n\"mesh_to_tetgenio.h\"\n\n\n#include\n \n\"tetgenio_to_tetmesh.h\"\n\n\n// [Includes of headers in this project]\n\n\n#include\n \n\"../../matrix_to_list.h\"\n\n\n#include\n \n\"../../list_to_matrix.h\"\n\n\n#include\n \n\"../../boundary_facets.h\"\n\n\n// [Includes of headers of related projects]\n\n\n#include\n \n<Eigen/Core>\n\n\n// [Includes of headers of standard libraries]\n\n\n#include\n \n<cassert>\n\n\n#include\n \n<iostream>\n\n\n\n\n\nPlacement of includes\n\u00b6\n\n\nWhenever possible \n#include\n directives should be placed in the \n.cpp\n\nimplementation file rather than the \n.h\n header file.\n\n\nWarnings\n\u00b6\n\n\nCode should compile without firing any warnings.\n\n\nAn Exception\n\u00b6\n\n\nThe only exception is for the use of the deprecated\n\nEigen::DynamicSparseMatrix\n in core sub-routines (e.g. \nigl::cat\n). This class\nis still supported and faster than the standard, non-deprecated Eigen\nimplementation so we're keeping it as long as possible and profitable.",
            "title": "Style Guidelines"
        },
        {
            "location": "/style-guidelines/#libigl-style-guidelines",
            "text": "Libigl is used and developed by many people. This document highlights some\nstyle guidelines for  developers  of the library, but also acts as\nbest-practices for users.",
            "title": "Libigl Style Guidelines"
        },
        {
            "location": "/style-guidelines/#one-function-one-hcpp-pair",
            "text": "The structure of libigl is very flat and function-based. For every\nfunction/sub-routine, create a single .h and .cpp file. For example, if you have\na function that determines connected components from a face list  F  you would\ncreate the header  connected_components.h  and  connected_components.cpp  and the only\nfunction defined should be  void connected_components(const ... F, ... C) . If the\nimplementation of  connected_components  requires a subroutine to compute an\nadjacency matrix then  create another pair   adjacency_matrix.h  and adjacency_matrix.cpp  with a single function  void adjacency_matrix(const ... F, ... A) .",
            "title": "One function, one .h/.cpp pair"
        },
        {
            "location": "/style-guidelines/#example",
            "text": "Here is an example function that would be defined in include/igl/example_fun.h  and implemented in  include/igl/example_fun.cpp .",
            "title": "Example"
        },
        {
            "location": "/style-guidelines/#example_funh",
            "text": "// This file is part of libigl, a simple c++ geometry processing library.  //   // Copyright (C) 2015 [Your Name] [your email address]  //   // This Source Code Form is subject to the terms of the Mozilla Public License   // v. 2.0. If a copy of the MPL was not distributed with this file, You can   // obtain one at http://mozilla.org/MPL/2.0/  #ifndef IGL_EXAMPLE_FUN_H  #define IGL_EXAMPLE_FUN_H  #include   \"igl_inline.h\"  namespace   igl  { \n   // This is an example of a function, it takes a templated parameter and \n   // shovels it into cout \n   // \n   // Input: \n   //   input  some input of a Printable type \n   // Returns true for the sake of returning something \n   template   < typename   Printable > \n   IGL_INLINE   bool   example_fun ( const   Printable   &   input );  }  #ifndef IGL_STATIC_LIBRARY  #  include \"example_fun.cpp\"  #endif  #endif",
            "title": "example_fun.h"
        },
        {
            "location": "/style-guidelines/#example_funcpp",
            "text": "// This file is part of libigl, a simple c++ geometry processing library.  //   // Copyright (C) 2015 [Your Name] [your email address]  //   // This Source Code Form is subject to the terms of the Mozilla Public License   // v. 2.0. If a copy of the MPL was not distributed with this file, You can   // obtain one at http://mozilla.org/MPL/2.0/  #include   \"igl/example_fun.h\"  #include   <iostream>  template   < typename   Printable >  IGL_INLINE   bool   igl :: example_fun ( const   Printable   &   input )  { \n   using   namespace   std ; \n   cout << \"example_fun: \" << input << endl ; \n   return   true ;  }  #ifdef IGL_STATIC_LIBRARY  template   bool   igl :: example_fun < double > ( const   double &   input );  template   bool   igl :: example_fun < int > ( const   int &   input );  #endif",
            "title": "example_fun.cpp"
        },
        {
            "location": "/style-guidelines/#avoid-static-helper-functions",
            "text": "Strive to encapsulate sub-functions that could possibly be useful outside of\nthe implementation of your current function. This might mean abstracting the\ninterface a bit. If it doesn't dramatically effect performance then create a\nnew pair of .h/.cpp files with this sub-function.",
            "title": "Avoid static \"helper\" functions"
        },
        {
            "location": "/style-guidelines/#lambda-functions",
            "text": "If encapsulation in a separate file is not possible or does not make sense,\nthen avoid crowding the namespace by creating lambda functions within the\nfunction implementation.  These lambda functions must still be documented with clear  input and output\narguments . Avoid using full capturing of all automatic\nvariables: do not use  [&]  or  [=] . Rather specify each captured variable\nindividually.",
            "title": "Lambda functions"
        },
        {
            "location": "/style-guidelines/#avoid-helper-classes",
            "text": "Libigl is built around the high-performance paradigm of \"struct of arrays\"\nrather than \"array of structs\". The way we achieve this is to avoid classes and\npass \"basic types\" directly. The price we pay is long function interfaces, but\nthis increases code reuse dramatically. A \"basic type\" in our context is a\nEigen type, stl type, or basic C type.",
            "title": "Avoid \"helper\" classes"
        },
        {
            "location": "/style-guidelines/#header-documentation",
            "text": "Each function prototype should be well documented in its corresponding .h\nheader file. A typical documentation consists of four parts:  // [A human readable description of what the function does.]  //  // Inputs:  //   [variable name of first (const) input]   [dimensions and description of  //     this input variable]  //   [variable name of second (const) input]   [dimensions and description of  //     this input variable]  //   ...  // Outputs:  //   [variable name of first output ]   [dimensions and description of this  //     output variable]  //   [variable name of second output ]   [dimensions and description of this  //     output variable]  //   ...  // Returns [description of return value]",
            "title": "Header Documentation"
        },
        {
            "location": "/style-guidelines/#example_1",
            "text": "For example the header  barycenter.h  // Computes the barycenter of every simplex\n//\n// Inputs:\n//   V  #V by dim matrix of vertex coordinates\n//   F  #F by simplex_size  matrix of indices of simplex corners into V\n// Output:\n//   BC  #F by dim matrix of 3d vertices\n//",
            "title": "Example"
        },
        {
            "location": "/style-guidelines/#const-inputs",
            "text": "All input parameters should be demarcated  const . If an input is also an\noutput than consider exposing two parameters (one  const ) or be sure to list\nthe variable under both  // Inputs:  and  // Outputs:  in the header comments.",
            "title": "Const inputs"
        },
        {
            "location": "/style-guidelines/#reference-parameters",
            "text": "All but simple types should be passed by reference (e.g.  Matrix & mat ) rather\nthan pointers (e.g.  Matrix * mat ) or value (e.g.  Matrix mat ).",
            "title": "Reference parameters"
        },
        {
            "location": "/style-guidelines/#returns-vs-output-parameters",
            "text": "All functions should be implemented with at least one overload that has a void  or simple return type (e.g.  bool  on success/failure). With this\nimplementation its then possible to write an overload that returns a single\noutput. Please see  Templating with Eigen .  For example:  template   < typename   Atype >  void   adjacency_matrix ( const   ...   &   F ,   Eigen :: SparseMatrix < AType >   &   A );  template   < typename   Atype >  Eigen :: SparseMatrix < Atype >   adjacency_matrix ( const   ...   &   F );",
            "title": "Returns vs output parameters"
        },
        {
            "location": "/style-guidelines/#templating-with-eigen",
            "text": "Functions taking Eigen dense matrices/arrays as inputs and outputs (but  not \nreturn arguments), should template on top of  Eigen::MatrixBase .  Each\nparameter  should be derived using its own template.  For example,  template   < typename   DerivedV ,   typename   DerivedF ,   typename   DerivedBC >  void   barycenter ( \n   const   Eigen :: MatrixBase < DerivedV >   &   V , \n   const   Eigen :: MatrixBase < DerivedF >   &   F , \n   const   Eigen :: MatrixBase < DerivedBC >   &   BC );   The  Derived*  template encodes the scalar type (e.g.  double ,  int ), the\nnumber of rows and cols at compile time, and the data storage (Row-major vs.\ncolumn-major).   Returning Eigen types is discouraged. In cases where the size and scalar type\nare a fixed  and matching  function of an input  Derived*  template, then\nreturn that  Derived*  type.  Do not  return Eigen::PlainObjectBase<...>  types. For example, this function scales fits a\ngiven set of points to the unit cube. The return is a new set of vertex\npositions so its type should  match  that of the input points:  template   < typename   DerivedV >  void   DerivedV   fit_to_unit_cube ( const   Eigen :: PlainObjectBase < DerivedV >   &   V );   To implement this function, it is  required  to implement a more generic\noutput-argument version and call that. So a full implementation looks like:  In  igl/fit_in_unit_cube.h :  template   < typename   DerivedV ,   typename   DerivedW >  void   fit_to_unit_cube ( \n   const   Eigen :: MatrixBase < DerivedV >   &   V , \n   Eigen :: PlainObjectBase < DerivedW >   &   W );  template   < typename   DerivedV >  void   DerivedV   fit_to_unit_cube ( const   Eigen :: PlainObjectBase < DerivedV >   &   V );   In  igl/fit_in_unit_cube.cpp :  template <typename DerivedV, typename DerivedW>\nvoid fit_to_unit_cube(\n  const Eigen::MatrixBase<DerivedV> & V,\n  Eigen::PlainObjectBase<DerivedW> & W)\n{\n  W = (V.rowwise()-V.colwise().minCoeff()).array() /\n    (V.maxCoeff()-V.minCoeff());\n}\n\ntemplate <typename DerivedV>\nvoid DerivedV fit_to_unit_cube(const Eigen::MatrixBase<DerivedV> & V)\n{\n  DerivedV W;\n  fit_to_unit_cube(V,W);\n  return W;\n}  Notice that  W  is declared as a  DerivedV  type and  not  Eigen::PlainObjectBase<DerivedV>  type.  Note:  Not all functions are suitable for returning Eigen types. For example igl::barycenter  above outputs a #F by dim list of barycenters. Returning a DerivedV  type would be inappropriate since the number of rows in  DerivedV \nwill be #V and may not match the number of rows in  DerivedF  (#F).",
            "title": "Templating with Eigen"
        },
        {
            "location": "/style-guidelines/#function-naming-conventions",
            "text": "Functions (and  thus also files ) should have simple,\ndescriptive names using lowercase letters and underscores between words. Avoid\nunnecessary prefaces. For example, instead of  compute_adjacency_matrix , construct_adjacency_matrix ,  extract_adjacency_matrix , get_adjacency_matrix , or  set_adjacency_matrix  just call the function adjacency_matrix .",
            "title": "Function naming conventions"
        },
        {
            "location": "/style-guidelines/#variable-naming-conventions",
            "text": "Libigl prefers short (even single character) variable names  with heavy\ndocumentation  in the comments in the header file or above the declaration of\nthe function. When possible use  V  to mean a list of vertex positions and  F \nto mean a list of faces/triangles.",
            "title": "Variable naming conventions"
        },
        {
            "location": "/style-guidelines/#class-naming-conventions",
            "text": "Classes should be avoided. When naming a class use CamelCase (e.g.\nSortableRow.h).",
            "title": "Class naming conventions"
        },
        {
            "location": "/style-guidelines/#enum-naming-conversion",
            "text": "Enums types should be placed in the appropriate  igl::  namespace and should be\nnamed in CamelCase (e.g.  igl::SolverStatus ) and instances should be named in\nALL_CAPS with underscores between words and prefaced with the name of the enum.\nFor example:  namespace   igl  { \n   enum   SolverStatus \n   { \n     // Good \n     SOLVER_STATUS_CONVERGED   =   0 , \n     // OK \n     SOLVER_STATUS_MAX_ITER   =   1 , \n     // Bad \n     SOLVER_STATUS_ERROR   =   2 , \n     NUM_SOLVER_STATUSES   =   3 , \n   };  };",
            "title": "Enum naming conversion"
        },
        {
            "location": "/style-guidelines/#exception-for-file-io",
            "text": "For legacy reasons, file reading and writing functions use a different naming\nconvention. A functions reading a  .xyz  file should be named  readXYZ  and a\nfunction writing  .xyz  files should be names  writeXYZ .",
            "title": "Exception for file IO"
        },
        {
            "location": "/style-guidelines/#using-namespace-in-global-scope",
            "text": "Writing  using   namespace   std ; ,  using   namespace   Eigen ;  etc. outside of a\nglobal scope is strictly forbidden. Place these lines at the top of each\nfunction instead.",
            "title": "using namespace ... in global scope"
        },
        {
            "location": "/style-guidelines/#namespaces-and-external-dependencies",
            "text": "Functions in the main library (directly in  include/igl ) should only depend on\nEigen and stl. These functions should have the  igl::  namespace.  Functions with other dependencies should be placed into\nappropriate sub-directories (e.g. if  myfunction  depends on tetgen then create igl/copyleft/tetgen/myfunction.h  and  igl/copyleft/tetgen/myfunction.cpp  and give the function\nthe namespace  igl::copyleft::tetgen::myfunction .",
            "title": "Namespaces and external dependencies"
        },
        {
            "location": "/style-guidelines/#copyleft-subdirectorynamespace",
            "text": "Dependencies that require users of libigl to release their projects open source\n(e.g. GPL) are considered aggressively \"copyleft\" and should be placed in the include/igl/copyleft/  sub-directory and  igl::copyleft::  namespace.",
            "title": "copyleft subdirectory/namespace"
        },
        {
            "location": "/style-guidelines/#assertions",
            "text": "Be generous with assertions and always identify the assertion with strings:  assert ( m   <   n   &&   \"m must be less than n\" );",
            "title": "Assertions"
        },
        {
            "location": "/style-guidelines/#ifndef-include-guard",
            "text": "Every header file should be wrapped in an  #ifndef  compiler directive. The\nname of the guard should be in direct correspondence with the path of the .h\nfile. For example,  include/igl/copyleft/tetgen/tetrahedralize.h  should be  #ifndef IGL_COPYLEFT_TETGEN_TETRAHEDRALIZE_H  #define IGL_COPYLEFT_TETGEN_TETRAHEDRALIZE_H  ...  #endif",
            "title": "ifndef include guard"
        },
        {
            "location": "/style-guidelines/#spaces-vs-tabs-indentation",
            "text": "Do not use tabs. Use 2 spaces for each indentation level.",
            "title": "Spaces vs. tabs indentation"
        },
        {
            "location": "/style-guidelines/#max-line-length",
            "text": "Limit lines to 80 characters. Break up long lines into many operations (this\nalso helps performance).",
            "title": "Max line length"
        },
        {
            "location": "/style-guidelines/#include-order",
            "text": "#include  directives at the top of a .h or .cpp file should be sorted\naccording to a simple principle: place headers of files most likely to be\nedited by you first. This means for include/igl/copyleft/tetgen/tetrahedralize.cpp  you might see  // [Includes of headers in this directory]  #include   \"tetrahedralize.h\"  #include   \"mesh_to_tetgenio.h\"  #include   \"tetgenio_to_tetmesh.h\"  // [Includes of headers in this project]  #include   \"../../matrix_to_list.h\"  #include   \"../../list_to_matrix.h\"  #include   \"../../boundary_facets.h\"  // [Includes of headers of related projects]  #include   <Eigen/Core>  // [Includes of headers of standard libraries]  #include   <cassert>  #include   <iostream>",
            "title": "Include order"
        },
        {
            "location": "/style-guidelines/#placement-of-includes",
            "text": "Whenever possible  #include  directives should be placed in the  .cpp \nimplementation file rather than the  .h  header file.",
            "title": "Placement of includes"
        },
        {
            "location": "/style-guidelines/#warnings",
            "text": "Code should compile without firing any warnings.",
            "title": "Warnings"
        },
        {
            "location": "/style-guidelines/#an-exception",
            "text": "The only exception is for the use of the deprecated Eigen::DynamicSparseMatrix  in core sub-routines (e.g.  igl::cat ). This class\nis still supported and faster than the standard, non-deprecated Eigen\nimplementation so we're keeping it as long as possible and profitable.",
            "title": "An Exception"
        },
        {
            "location": "/CONTRIBUTING/",
            "text": "Before opening an issue on creating a pull request, please check the following:\n\n\nCompilation Issues\n\u00b6\n\n\n\n\n\n\nIf you are on Windows, did you select the \nx64\n version of the Visual Studio compiler?\n\n\n\n\n\n\nIf you have a \nCMake issue\n, make sure you follow the same approach as the  \nlibigl-example-project\n to build libigl with your project, and make sure that you can compile the example project.\n\n\n\n\n\n\nIf you have an issue with a \nsubmodule\n, check if your submodules are up to date. If you have a doubt about a submodule, delete its folder and run \ngit submodule update --init --recursive\n in the libigl directory.\n\n\n\n\n\n\nIf you have an issue with a missing \ntemplate issue\n, check if your code compile with the \nheader-only\n option of libigl activated. Turn \nOFF\n the CMake option \nLIBIGL_USE_STATIC_LIBRARY\n: either modify your \nCMakeCache.txt\n via CMake GUI or ccmake, or delete your \nCMakeCache.txt\n and re-run \ncmake -DLIBIGL_USE_STATIC_LIBRARY=OFF ..\n in your build folder.\n\n\n\n\n\n\nMake sure your read the \nFAQ\n before asking a new question, and search \nexisting issues\n for a problem similar to yours.\n\n\n\n\n\n\nMake sure you read the informations contained in the libigl \nhomepage\n as well as the \ntutorials\n.\n\n\n\n\n\n\nIf none of these solve your problem, then please report your issue in the bug tracker!",
            "title": "Bug Report"
        },
        {
            "location": "/CONTRIBUTING/#compilation-issues",
            "text": "If you are on Windows, did you select the  x64  version of the Visual Studio compiler?    If you have a  CMake issue , make sure you follow the same approach as the   libigl-example-project  to build libigl with your project, and make sure that you can compile the example project.    If you have an issue with a  submodule , check if your submodules are up to date. If you have a doubt about a submodule, delete its folder and run  git submodule update --init --recursive  in the libigl directory.    If you have an issue with a missing  template issue , check if your code compile with the  header-only  option of libigl activated. Turn  OFF  the CMake option  LIBIGL_USE_STATIC_LIBRARY : either modify your  CMakeCache.txt  via CMake GUI or ccmake, or delete your  CMakeCache.txt  and re-run  cmake -DLIBIGL_USE_STATIC_LIBRARY=OFF ..  in your build folder.    Make sure your read the  FAQ  before asking a new question, and search  existing issues  for a problem similar to yours.    Make sure you read the informations contained in the libigl  homepage  as well as the  tutorials .    If none of these solve your problem, then please report your issue in the bug tracker!",
            "title": "Compilation Issues"
        },
        {
            "location": "/before-submitting-pull-request/",
            "text": "Before submitting a pull request\n\u00b6\n\n\nThere are a variety of things you can do before submitting a pull request that\nwill reduce the effort on the libigl team to merge your code and increase the\nlikelihood that the merge ever happens.\n\n\n\n\nTest your code and submit a unit test as part of the pull request\n\n\nVerify that your code matches the \nlibigl style\n  guidelines\n\n\nRun the \nexhaustive build test\n below\n\n\n\n\nExhaustive build test\n\u00b6\n\n\nThis script will \ngit clone\n libigl to a temporary directory and build \n\n\n\n\nthe static libigl library, \n\n\nthe tutorial using the default header only libigl, and \n\n\nthe tutorial using the static library libigl.\n\n\n\n\nEventually this script should also run the unit tests.\n\n\n# In scripts/clone_and_build.sh add your email address to the line:\n\n\n# `recipients=\"alecjacobson@gmail.com,youremail@domain.com\"`\n\n\n# In your email client (e.g. gmail) create a filter to prevent emails \n\n\n# from your local machine from going to spam\n\nscripts/clone_and_build.sh\n\n\n\n\nDirect test of tutorial using static library\n\u00b6\n\n\nThis part of the \nclone_and_build.sh\n script catches 99% of the compilation\nissues that \ndon't\n show up when testing:\n\n\ncd\n tutorial/\nmkdir build-use-static\n\ncd\n build-use-static\ncmake -DCMAKE_BUILD_TYPE\n=\nRelease -DLIBIGL_USE_STATIC_LIBRARY\n=\nON ..\nmake\n\n\n\n\nA typical issue is a missing template instantiation (symbol not found):\n\n\n\"void igl::cgal::points_inside_component<Eigen::Matrix<double, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 3, 0, -1, 3>, Eigen::Matrix<double, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 1, 0, -1, 1> >(Eigen::PlainObjectBase<Eigen::Matrix<double, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<double, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 1, 0, -1, 1> >&)\", referenced from:\n    void igl::cgal::outer_hull<Eigen::Matrix<double, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 3, 0, -1, 3>, Eigen::Matrix<long, -1, 1, 0, -1, 1>, Eigen::Matrix<int, -1, 1, 0, -1, 1> >(Eigen::PlainObjectBase<Eigen::Matrix<double, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 3, 0, -1, 3> >&, Eigen::PlainObjectBase<Eigen::Matrix<long, -1, 1, 0, -1, 1> >&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 1, 0, -1, 1> >&) in libiglboolean.a(mesh_boolean.cpp.o)\n    void igl::cgal::outer_hull<Eigen::Matrix<double, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 3, 0, -1, 3>, Eigen::Matrix<long, -1, 1, 0, -1, 1>, Eigen::Matrix<bool, -1, 1, 0, -1, 1> >(Eigen::PlainObjectBase<Eigen::Matrix<double, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 3, 0, -1, 3> >&, Eigen::PlainObjectBase<Eigen::Matrix<long, -1, 1, 0, -1, 1> >&, Eigen::PlainObjectBase<Eigen::Matrix<bool, -1, 1, 0, -1, 1> >&) in libiglboolean.a(mesh_boolean.cpp.o)\n\n\n\n\n\nThis looks like a mess, but the solution is very simple. Copy the chunk inside of the quotes, in this case:\n\n\n\"void igl::cgal::points_inside_component<Eigen::Matrix<double, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 3, 0, -1, 3>, Eigen::Matrix<double, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 1, 0, -1, 1> >(Eigen::PlainObjectBase<Eigen::Matrix<double, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<double, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 1, 0, -1, 1> >&)\"\n\n\n\n\n\nand paste it at the bottom of the relevant .cpp file with the word template in front of it and a semicolon at then. In this case, in include/igl/cgal/points_inside_component.cpp:\n\n\n#ifdef IGL_STATIC_LIBRARY\n\n\n// Explicit template instantiation\n\n\ntemplate\n \nvoid\n \nigl\n::\ncgal\n::\npoints_inside_component\n<\nEigen\n::\nMatrix\n<\nCGAL\n::\nLazy_exact_nt\n<\nCGAL\n::\nGmpq\n>\n,\n \n-\n1\n,\n \n3\n,\n \n0\n,\n \n-\n1\n,\n \n3\n>\n,\n \nEigen\n::\nMatrix\n<\nint\n,\n \n-\n1\n,\n \n3\n,\n \n0\n,\n \n-\n1\n,\n \n3\n>\n,\n \nEigen\n::\nMatrix\n<\nCGAL\n::\nLazy_exact_nt\n<\nCGAL\n::\nGmpq\n>\n,\n \n-\n1\n,\n \n3\n,\n \n0\n,\n \n-\n1\n,\n \n3\n>\n,\n \nEigen\n::\nMatrix\n<\nint\n,\n \n-\n1\n,\n \n1\n,\n \n0\n,\n \n-\n1\n,\n \n1\n>\n \n>\n(\nEigen\n::\nPlainObjectBase\n<\nEigen\n::\nMatrix\n<\nCGAL\n::\nLazy_exact_nt\n<\nCGAL\n::\nGmpq\n>\n,\n \n-\n1\n,\n \n3\n,\n \n0\n,\n \n-\n1\n,\n \n3\n>\n \n>\n \nconst\n&\n,\n \nEigen\n::\nPlainObjectBase\n<\nEigen\n::\nMatrix\n<\nint\n,\n \n-\n1\n,\n \n3\n,\n \n0\n,\n \n-\n1\n,\n \n3\n>\n \n>\n \nconst\n&\n,\n \nEigen\n::\nPlainObjectBase\n<\nEigen\n::\nMatrix\n<\nCGAL\n::\nLazy_exact_nt\n<\nCGAL\n::\nGmpq\n>\n,\n \n-\n1\n,\n \n3\n,\n \n0\n,\n \n-\n1\n,\n \n3\n>\n \n>\n \nconst\n&\n,\n \nEigen\n::\nPlainObjectBase\n<\nEigen\n::\nMatrix\n<\nint\n,\n \n-\n1\n,\n \n1\n,\n \n0\n,\n \n-\n1\n,\n \n1\n>\n \n>&\n);\n\n\n#endif\n\n\n\n\n\nThen \"rinse and repeat\".",
            "title": "Creating a Pull Request"
        },
        {
            "location": "/before-submitting-pull-request/#before-submitting-a-pull-request",
            "text": "There are a variety of things you can do before submitting a pull request that\nwill reduce the effort on the libigl team to merge your code and increase the\nlikelihood that the merge ever happens.   Test your code and submit a unit test as part of the pull request  Verify that your code matches the  libigl style\n  guidelines  Run the  exhaustive build test  below",
            "title": "Before submitting a pull request"
        },
        {
            "location": "/before-submitting-pull-request/#exhaustive-build-test",
            "text": "This script will  git clone  libigl to a temporary directory and build    the static libigl library,   the tutorial using the default header only libigl, and   the tutorial using the static library libigl.   Eventually this script should also run the unit tests.  # In scripts/clone_and_build.sh add your email address to the line:  # `recipients=\"alecjacobson@gmail.com,youremail@domain.com\"`  # In your email client (e.g. gmail) create a filter to prevent emails   # from your local machine from going to spam \nscripts/clone_and_build.sh",
            "title": "Exhaustive build test"
        },
        {
            "location": "/before-submitting-pull-request/#direct-test-of-tutorial-using-static-library",
            "text": "This part of the  clone_and_build.sh  script catches 99% of the compilation\nissues that  don't  show up when testing:  cd  tutorial/\nmkdir build-use-static cd  build-use-static\ncmake -DCMAKE_BUILD_TYPE = Release -DLIBIGL_USE_STATIC_LIBRARY = ON ..\nmake  A typical issue is a missing template instantiation (symbol not found):  \"void igl::cgal::points_inside_component<Eigen::Matrix<double, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 3, 0, -1, 3>, Eigen::Matrix<double, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 1, 0, -1, 1> >(Eigen::PlainObjectBase<Eigen::Matrix<double, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<double, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 1, 0, -1, 1> >&)\", referenced from:\n    void igl::cgal::outer_hull<Eigen::Matrix<double, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 3, 0, -1, 3>, Eigen::Matrix<long, -1, 1, 0, -1, 1>, Eigen::Matrix<int, -1, 1, 0, -1, 1> >(Eigen::PlainObjectBase<Eigen::Matrix<double, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 3, 0, -1, 3> >&, Eigen::PlainObjectBase<Eigen::Matrix<long, -1, 1, 0, -1, 1> >&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 1, 0, -1, 1> >&) in libiglboolean.a(mesh_boolean.cpp.o)\n    void igl::cgal::outer_hull<Eigen::Matrix<double, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 3, 0, -1, 3>, Eigen::Matrix<long, -1, 1, 0, -1, 1>, Eigen::Matrix<bool, -1, 1, 0, -1, 1> >(Eigen::PlainObjectBase<Eigen::Matrix<double, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 3, 0, -1, 3> >&, Eigen::PlainObjectBase<Eigen::Matrix<long, -1, 1, 0, -1, 1> >&, Eigen::PlainObjectBase<Eigen::Matrix<bool, -1, 1, 0, -1, 1> >&) in libiglboolean.a(mesh_boolean.cpp.o)  This looks like a mess, but the solution is very simple. Copy the chunk inside of the quotes, in this case:  \"void igl::cgal::points_inside_component<Eigen::Matrix<double, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 3, 0, -1, 3>, Eigen::Matrix<double, -1, 3, 0, -1, 3>, Eigen::Matrix<int, -1, 1, 0, -1, 1> >(Eigen::PlainObjectBase<Eigen::Matrix<double, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<double, -1, 3, 0, -1, 3> > const&, Eigen::PlainObjectBase<Eigen::Matrix<int, -1, 1, 0, -1, 1> >&)\"  and paste it at the bottom of the relevant .cpp file with the word template in front of it and a semicolon at then. In this case, in include/igl/cgal/points_inside_component.cpp:  #ifdef IGL_STATIC_LIBRARY  // Explicit template instantiation  template   void   igl :: cgal :: points_inside_component < Eigen :: Matrix < CGAL :: Lazy_exact_nt < CGAL :: Gmpq > ,   - 1 ,   3 ,   0 ,   - 1 ,   3 > ,   Eigen :: Matrix < int ,   - 1 ,   3 ,   0 ,   - 1 ,   3 > ,   Eigen :: Matrix < CGAL :: Lazy_exact_nt < CGAL :: Gmpq > ,   - 1 ,   3 ,   0 ,   - 1 ,   3 > ,   Eigen :: Matrix < int ,   - 1 ,   1 ,   0 ,   - 1 ,   1 >   > ( Eigen :: PlainObjectBase < Eigen :: Matrix < CGAL :: Lazy_exact_nt < CGAL :: Gmpq > ,   - 1 ,   3 ,   0 ,   - 1 ,   3 >   >   const & ,   Eigen :: PlainObjectBase < Eigen :: Matrix < int ,   - 1 ,   3 ,   0 ,   - 1 ,   3 >   >   const & ,   Eigen :: PlainObjectBase < Eigen :: Matrix < CGAL :: Lazy_exact_nt < CGAL :: Gmpq > ,   - 1 ,   3 ,   0 ,   - 1 ,   3 >   >   const & ,   Eigen :: PlainObjectBase < Eigen :: Matrix < int ,   - 1 ,   1 ,   0 ,   - 1 ,   1 >   >& );  #endif   Then \"rinse and repeat\".",
            "title": "Direct test of tutorial using static library"
        },
        {
            "location": "/unit-tests/",
            "text": "Unit Tests for \nlibigl\n\u00b6\n\n\n\n\nGet started with\n\n\ngit clone --recursive git@github.com:libigl/libigl-unit-tests.git\n\n\n\n\nDependencies\n\u00b6\n\n\ngoogletest\n is a submodule\n\n\nBuild and test\n\u00b6\n\n\nUse \ncmake\n to generate a \nMakefile\n that will build \nand test\n upon issuing\n\nmake\n:\n\n\nmkdir build\ncd build\ncmake ..\n\n\n\n\nThen build and test with\n\n\nmake test\n\n\n\n\nThis will first compile the tests and then immediately run the tests. If tests\nare succeeding you should see output similar to:\n\n\nTest project /usr/local/libigl-unit-tests/build\n    Start 1: run_igl_mosek_tests\n1/4 Test #1: run_igl_mosek_tests ..............***Exception: Other  0.00 sec\n    Start 2: run_igl_boolean_tests\n2/4 Test #2: run_igl_boolean_tests ............   Passed    1.12 sec\n    Start 3: run_igl_cgal_tests\n3/4 Test #3: run_igl_cgal_tests ...............   Passed    2.46 sec\n    Start 4: run_igl_tests\n\n\n\n\nAlternatively, to get more detailed output you can call ctest directly with the\nverbose flag:\n\n\nGTEST_COLOR=1 ctest --verbose\n\n\n\n\nYou'll see outputs for each individual test:\n\n\nUpdateCTestConfiguration  from :/usr/local/libigl-unit-tests/build/DartConfiguration.tcl\nUpdateCTestConfiguration  from :/usr/local/libigl-unit-tests/build/DartConfiguration.tcl\nTest project /usr/local/libigl-unit-tests/build\nConstructing a list of tests\nDone constructing a list of tests\nUpdating test list for fixtures\nAdded 0 tests to meet fixture requirements\nChecking test dependency graph...\nChecking test dependency graph end\ntest 1\n    Start 1: run_igl_mosek_tests\n\n1: Test command: /usr/local/libigl-unit-tests/build/include/igl/mosek/igl_mosek_tests\n1: Test timeout computed to be: 9.99988e+06\n1: [==========] Running 1 test from 1 test case.\n1: [----------] Global test environment set-up.\n1: [----------] 1 test from mosek_bbw\n1: [ RUN      ] mosek_bbw.decimated_knight\n1: /usr/local/libigl-unit-tests/include/igl/mosek/bbw.cpp:25: Failure\n1: Expected: ((Wmo-W_groundtruth).array().abs().maxCoeff()) < (1e-3), actual: 0.00287895 vs 0.001\n1: [  FAILED  ] mosek_bbw.decimated_knight (2126 ms)\n1: [----------] 1 test from mosek_bbw (2126 ms total)\n1: \n1: [----------] Global test environment tear-down\n1: [==========] 1 test from 1 test case ran. (2126 ms total)\n1: [  PASSED  ] 0 tests.\n1: [  FAILED  ] 1 test, listed below:\n1: [  FAILED  ] mosek_bbw.decimated_knight\n1: \n1:  1 FAILED TEST\n1/4 Test #1: run_igl_mosek_tests ..............***Failed    2.14 sec\ntest 2\n    Start 2: run_igl_boolean_tests\n\n2: Test command: /usr/local/libigl-unit-tests/build/include/igl/copyleft/boolean/igl_boolean_tests\n2: Test timeout computed to be: 9.99988e+06\n2: [==========] Running 3 tests from 1 test case.\n2: [----------] Global test environment set-up.\n2: [----------] 3 tests from MeshBoolean\n2: [ RUN      ] MeshBoolean.TwoCubes\n...\n\n\n\n\nGenerating new tests\n\u00b6\n\n\nMany libigl functions act on triangle meshes. To make it easy to add a new test\nfor a libigl function, we have a script that will output some boilerplate\ntesting code. So if you issue:\n\n\ncd include/igl/\n../../scripts/new.sh myfun\n\n\n\n\nThis will create a test file \nmyfun.cpp\n containing:\n\n\n#\ninclude\n \n<\ntest_common\n.\nh\n>\n\n\n#\ninclude\n \n<\nigl\n/\nmyfun\n.\nh\n>\n\n\n\nclass\n \nmyfun\n : \npublic\n \n::\ntesting\n::\nTestWithParam\n<\nstd\n::\nstring\n>\n \n{};\n\n\n\nTEST_P\n(\nmyfun\n,\n \nchange_to_meaningful_name\n)\n\n\n{\n\n  \nEigen\n::\nMatrixXd\n \nV\n;\n\n  \nEigen\n::\nMatrixXi\n \nF\n;\n\n  \nEigen\n::\nSparseMatrix\n<\ndouble\n>\n \nL\n;\n\n  \n// Load example mesh: GetParam() will be name of mesh file\n\n  \ntest_common\n::\nload_mesh\n(\nGetParam\n(),\n \nV\n,\n \nF\n);\n\n  \n// ASSERT_EQ(a,b);\n\n  \n// ASSERT_TRUE(a==b);\n\n  \n// ASSERT_NEAR(a,b,1e-15)\n\n  \n// ASSERT_LT(a,1e-12);\n\n\n}\n\n\n\nINSTANTIATE_TEST_CASE_P\n\n\n(\n\n \nall_meshes\n,\n\n \nmyfun\n,\n\n \n::\ntesting\n::\nValuesIn\n(\ntest_common\n::\nall_meshes\n()),\n\n \ntest_common\n::\nstring_test_name\n\n\n);\n\n\n\n\n\nAdd a call to \nigl::myfun\n and an assertion (e.g., \nASSERT_EQ\n) and this will\nadd a test for \nall\n meshes in the \ndata/\n folder. (Should also change\n\nchange_to_meaningful_name\n to a meaningful name based on what you're testing).\n\n\nConventions\n\u00b6\n\n\nWhen naming a test for a function \nigl::extra::function_name\n use:\n\n\nTEST\n(\nextra_function_name\n,\n \nmeaning_test_name\n)\n\n\n{\n\n  \n...\n\n\n}\n\n\n\n\n\nwhere \nmeaning_test_name\n could identify the type of test or the type of data\nbeing used.\n\n\nExample\n\u00b6\n\n\nThe test for \nigl::copyleft::cgal::order_facets_around_edges\n in\n\ninclude/igl/copyleft/cgal/order_facets_around_edges.cpp\n is:\n\n\nTEST\n(\ncopyleft_cgal_order_facets_around_edges\n,\n \nTripletFaces\n)\n\n\n{\n\n  \n...\n\n\n}\n\n\n\n\n\nwhich tests this function on example data containing a triplet of faces.\n\n\nGuarantees\n\u00b6\n\n\nNone.\n\n\n(Obviously?) The presence of a unit test here for some function (e.g.,\n\nigl::cotmatrix\n) is not a guarantee or even an endorsement of the notion that\nthe libigl function \nigl::cotmatrix\n is bug free or \"fully tested\" or \"heavily\ntested\" or even \"adequately tested\".\n\n\nNeed work?\n\u00b6\n\n\nSome of the most used libigl functions\n\n\ngrep -hr \n\"^#include \\\"\"\n ../libigl/include/igl \n|\n sed -e \n's/\\(\\.\\.\\/\\)//g'\n \n|\n sort \n|\n uniq -c \n|\n sort\n\n\n\n\nstill don't have unit tests.",
            "title": "Unit Tests"
        },
        {
            "location": "/unit-tests/#unit-tests-for-libigl",
            "text": "Get started with  git clone --recursive git@github.com:libigl/libigl-unit-tests.git",
            "title": "Unit Tests for libigl"
        },
        {
            "location": "/unit-tests/#dependencies",
            "text": "googletest  is a submodule",
            "title": "Dependencies"
        },
        {
            "location": "/unit-tests/#build-and-test",
            "text": "Use  cmake  to generate a  Makefile  that will build  and test  upon issuing make :  mkdir build\ncd build\ncmake ..  Then build and test with  make test  This will first compile the tests and then immediately run the tests. If tests\nare succeeding you should see output similar to:  Test project /usr/local/libigl-unit-tests/build\n    Start 1: run_igl_mosek_tests\n1/4 Test #1: run_igl_mosek_tests ..............***Exception: Other  0.00 sec\n    Start 2: run_igl_boolean_tests\n2/4 Test #2: run_igl_boolean_tests ............   Passed    1.12 sec\n    Start 3: run_igl_cgal_tests\n3/4 Test #3: run_igl_cgal_tests ...............   Passed    2.46 sec\n    Start 4: run_igl_tests  Alternatively, to get more detailed output you can call ctest directly with the\nverbose flag:  GTEST_COLOR=1 ctest --verbose  You'll see outputs for each individual test:  UpdateCTestConfiguration  from :/usr/local/libigl-unit-tests/build/DartConfiguration.tcl\nUpdateCTestConfiguration  from :/usr/local/libigl-unit-tests/build/DartConfiguration.tcl\nTest project /usr/local/libigl-unit-tests/build\nConstructing a list of tests\nDone constructing a list of tests\nUpdating test list for fixtures\nAdded 0 tests to meet fixture requirements\nChecking test dependency graph...\nChecking test dependency graph end\ntest 1\n    Start 1: run_igl_mosek_tests\n\n1: Test command: /usr/local/libigl-unit-tests/build/include/igl/mosek/igl_mosek_tests\n1: Test timeout computed to be: 9.99988e+06\n1: [==========] Running 1 test from 1 test case.\n1: [----------] Global test environment set-up.\n1: [----------] 1 test from mosek_bbw\n1: [ RUN      ] mosek_bbw.decimated_knight\n1: /usr/local/libigl-unit-tests/include/igl/mosek/bbw.cpp:25: Failure\n1: Expected: ((Wmo-W_groundtruth).array().abs().maxCoeff()) < (1e-3), actual: 0.00287895 vs 0.001\n1: [  FAILED  ] mosek_bbw.decimated_knight (2126 ms)\n1: [----------] 1 test from mosek_bbw (2126 ms total)\n1: \n1: [----------] Global test environment tear-down\n1: [==========] 1 test from 1 test case ran. (2126 ms total)\n1: [  PASSED  ] 0 tests.\n1: [  FAILED  ] 1 test, listed below:\n1: [  FAILED  ] mosek_bbw.decimated_knight\n1: \n1:  1 FAILED TEST\n1/4 Test #1: run_igl_mosek_tests ..............***Failed    2.14 sec\ntest 2\n    Start 2: run_igl_boolean_tests\n\n2: Test command: /usr/local/libigl-unit-tests/build/include/igl/copyleft/boolean/igl_boolean_tests\n2: Test timeout computed to be: 9.99988e+06\n2: [==========] Running 3 tests from 1 test case.\n2: [----------] Global test environment set-up.\n2: [----------] 3 tests from MeshBoolean\n2: [ RUN      ] MeshBoolean.TwoCubes\n...",
            "title": "Build and test"
        },
        {
            "location": "/unit-tests/#generating-new-tests",
            "text": "Many libigl functions act on triangle meshes. To make it easy to add a new test\nfor a libigl function, we have a script that will output some boilerplate\ntesting code. So if you issue:  cd include/igl/\n../../scripts/new.sh myfun  This will create a test file  myfun.cpp  containing:  # include   < test_common . h >  # include   < igl / myfun . h >  class   myfun  :  public   :: testing :: TestWithParam < std :: string >   {};  TEST_P ( myfun ,   change_to_meaningful_name )  { \n   Eigen :: MatrixXd   V ; \n   Eigen :: MatrixXi   F ; \n   Eigen :: SparseMatrix < double >   L ; \n   // Load example mesh: GetParam() will be name of mesh file \n   test_common :: load_mesh ( GetParam (),   V ,   F ); \n   // ASSERT_EQ(a,b); \n   // ASSERT_TRUE(a==b); \n   // ASSERT_NEAR(a,b,1e-15) \n   // ASSERT_LT(a,1e-12);  }  INSTANTIATE_TEST_CASE_P  ( \n  all_meshes , \n  myfun , \n  :: testing :: ValuesIn ( test_common :: all_meshes ()), \n  test_common :: string_test_name  );   Add a call to  igl::myfun  and an assertion (e.g.,  ASSERT_EQ ) and this will\nadd a test for  all  meshes in the  data/  folder. (Should also change change_to_meaningful_name  to a meaningful name based on what you're testing).",
            "title": "Generating new tests"
        },
        {
            "location": "/unit-tests/#conventions",
            "text": "When naming a test for a function  igl::extra::function_name  use:  TEST ( extra_function_name ,   meaning_test_name )  { \n   ...  }   where  meaning_test_name  could identify the type of test or the type of data\nbeing used.",
            "title": "Conventions"
        },
        {
            "location": "/unit-tests/#example",
            "text": "The test for  igl::copyleft::cgal::order_facets_around_edges  in include/igl/copyleft/cgal/order_facets_around_edges.cpp  is:  TEST ( copyleft_cgal_order_facets_around_edges ,   TripletFaces )  { \n   ...  }   which tests this function on example data containing a triplet of faces.",
            "title": "Example"
        },
        {
            "location": "/unit-tests/#guarantees",
            "text": "None.  (Obviously?) The presence of a unit test here for some function (e.g., igl::cotmatrix ) is not a guarantee or even an endorsement of the notion that\nthe libigl function  igl::cotmatrix  is bug free or \"fully tested\" or \"heavily\ntested\" or even \"adequately tested\".",
            "title": "Guarantees"
        },
        {
            "location": "/unit-tests/#need-work",
            "text": "Some of the most used libigl functions  grep -hr  \"^#include \\\"\"  ../libigl/include/igl  |  sed -e  's/\\(\\.\\.\\/\\)//g'   |  sort  |  uniq -c  |  sort  still don't have unit tests.",
            "title": "Need work?"
        },
        {
            "location": "/coding-guidelines/",
            "text": "Libigl Coding Tips (aka \"How to code a SIGGRAPH project\")\n\u00b6\n\n\nThis is a short list of coding tips that will greatly reduce your pain and suffering before (and after) the SIGGRAPH deadline.\n\n\n1. Serialize it all\n\u00b6\n\n\nThe entire state of your application should be serializable, i.e. It should be possible to save it into a binary file and reload it at any point. This drastically simplifies debugging, since you can serialize just before a crash happens and debug from that point without running your complete algorithm again. Serializing all results shown in the paper's figures enables quicker editing iterations before (and after) the deadline. It also allows you to share your results with others that wish to compare with your method. An additional tip is to serialize the state of the application on the window close event and automatically reload it when you launch it again.\n\n\n2. Always assert\n\u00b6\n\n\nEven if you know what you are doing, always assert, you will be surprised. Assertion is a powerful but underused feature available in all programming languages. It is essential for writing research code since often you will have to implement algorithms that turns out to not be doing what you expect: in these cases it is important to know if the algorithm is flawed or if there is a bug in your implementation. Discarding a good idea  because of a coding bug is frustrating and unfortunately common. Assertion is an ideal way to reduce the chances of introducing bugs in your code and, differently from unit testing, requires a very minor programming effort. You should use them extensively.\n\n\n3. Plot everything\n\u00b6\n\n\nIf you can visually plot the results or some intermediate steps of your algorithm, do it, even if you think your implementation is correct! It is a lot easier to find bugs or to get an intuition on an algorithm by looking at a plot than by looking at the code.\n\n\n4. If the compilation time after a code change is more than five seconds, you are doing it wrong\n\u00b6\n\n\nYou will change your code hundreds of times every day for months. Let's say that you will change it a hundred times a day (which is a  very conservative estimate): if the compilation takes one minute, you will waste almost two hours every day, just waiting! What is even worse, is that since it is only 1-2 minutes at a time, it will not even be sufficient to prepare a coffee. Spend the hour or two that is needed to get your code to compile in a few seconds, you will benefit from it in the same day already, and the time saved over an entire project will be gigantic.\n\n\n5. Commit often (and with a meaningful description)\n\u00b6\n\n\nUse a distributed version control system (git,hg), and keep the repository on a remote host. Commit often and put meaningful comments. This will serve you as an emergency backup and it will always allow you to have a running version of your code whenever your advisor is passing by and asking to see some results. She will be impressed and you will not have to quickly fix your build with your boss breathing down your neck.\n\n\n6. Dependencies are evil, avoid them\n\u00b6\n\n\nKeep your code simple and with minimal external dependencies. Spending a day or two to code something from scratch while avoiding to use third party code is usually an investment that pays off. The more code you have in your algorithm that is not written by you, the harder debugging becomes. In particular, refrain from building your entire project on code that you do not understand to avoid bad surprises just before the deadline. If you must use code written by others, spend the time that is needed to fully understand what it does, and link it statically so that it will be easy to place breakpoints inside it.\n\n\n7. Global variables are not evil, use them\n\u00b6\n\n\nGlobal variables are often extremely useful --- if you think you need one, use it. They are indeed dangerous for large projects, but you are not coding one of those, you are coding a prototype to test a research idea. I suggest to keep one single copy of your entire application state in a global variable (or a singleton class) that can be serialized (see tip 1). This variable should include everything rendered on screen and all the temporary data produced by your algorithm. This will allow you to easily access all the data in your project for plotting or debugging purposes.\n\n\n8. Prototype first\n\u00b6\n\n\nDon\u2019t preemptively optimize and try to quickly write code that is clean and correct. It is common to try multiple different approaches to solve a new problem before finding the right one. This means that the majority of the code that you will write will not be used at the end of the project. While you should still write high-quality and bug-free code to make sure that your results is correct, you definitely do not want to spend time optimizing it before you are sure that is the right approach. In particular, it is helpful to learn a good prototyping language (Python, matlab) and use it for the early stages of the project and switch to (or mix it with) c++ only after finding a promising direction.\n\n\n9. Avoid explicit pointers\n\u00b6\n\n\nDo yourself a favor, do not use explicit pointers. If you use a language that supports explicit pointers, use them only if you really have to. And even in that case, keep them isolated in a single file and be very careful with them. Writing data inside another variable by accident might not trigger a crash, and simply produce strange artifacts that might convince you that a promising research direction does not work, while the problem lies in a nasty bug in your code. There is no reason to take that risk during prototyping, just avoid them and leave them for the end of the project in case they become necessary to optimize your code.\n\n\n10. If your program crashes, fix it now!\n\u00b6\n\n\nIf your program crashes, don't close your eyes and move on. Try to make it happen again, debug it and fix it immediately. These bugs are a nightmare to find, and the more code you add on top of a bug will just make it harder to find. If you don't fix it, due to Murphy's law, it will start to be problematic only a few days before the deadline and you will have no time to fix it at that point.\n\n\nDaniele Panozzo",
            "title": "Coding Tips"
        },
        {
            "location": "/coding-guidelines/#libigl-coding-tips-aka-how-to-code-a-siggraph-project",
            "text": "This is a short list of coding tips that will greatly reduce your pain and suffering before (and after) the SIGGRAPH deadline.",
            "title": "Libigl Coding Tips (aka \"How to code a SIGGRAPH project\")"
        },
        {
            "location": "/coding-guidelines/#1-serialize-it-all",
            "text": "The entire state of your application should be serializable, i.e. It should be possible to save it into a binary file and reload it at any point. This drastically simplifies debugging, since you can serialize just before a crash happens and debug from that point without running your complete algorithm again. Serializing all results shown in the paper's figures enables quicker editing iterations before (and after) the deadline. It also allows you to share your results with others that wish to compare with your method. An additional tip is to serialize the state of the application on the window close event and automatically reload it when you launch it again.",
            "title": "1. Serialize it all"
        },
        {
            "location": "/coding-guidelines/#2-always-assert",
            "text": "Even if you know what you are doing, always assert, you will be surprised. Assertion is a powerful but underused feature available in all programming languages. It is essential for writing research code since often you will have to implement algorithms that turns out to not be doing what you expect: in these cases it is important to know if the algorithm is flawed or if there is a bug in your implementation. Discarding a good idea  because of a coding bug is frustrating and unfortunately common. Assertion is an ideal way to reduce the chances of introducing bugs in your code and, differently from unit testing, requires a very minor programming effort. You should use them extensively.",
            "title": "2. Always assert"
        },
        {
            "location": "/coding-guidelines/#3-plot-everything",
            "text": "If you can visually plot the results or some intermediate steps of your algorithm, do it, even if you think your implementation is correct! It is a lot easier to find bugs or to get an intuition on an algorithm by looking at a plot than by looking at the code.",
            "title": "3. Plot everything"
        },
        {
            "location": "/coding-guidelines/#4-if-the-compilation-time-after-a-code-change-is-more-than-five-seconds-you-are-doing-it-wrong",
            "text": "You will change your code hundreds of times every day for months. Let's say that you will change it a hundred times a day (which is a  very conservative estimate): if the compilation takes one minute, you will waste almost two hours every day, just waiting! What is even worse, is that since it is only 1-2 minutes at a time, it will not even be sufficient to prepare a coffee. Spend the hour or two that is needed to get your code to compile in a few seconds, you will benefit from it in the same day already, and the time saved over an entire project will be gigantic.",
            "title": "4. If the compilation time after a code change is more than five seconds, you are doing it wrong"
        },
        {
            "location": "/coding-guidelines/#5-commit-often-and-with-a-meaningful-description",
            "text": "Use a distributed version control system (git,hg), and keep the repository on a remote host. Commit often and put meaningful comments. This will serve you as an emergency backup and it will always allow you to have a running version of your code whenever your advisor is passing by and asking to see some results. She will be impressed and you will not have to quickly fix your build with your boss breathing down your neck.",
            "title": "5. Commit often (and with a meaningful description)"
        },
        {
            "location": "/coding-guidelines/#6-dependencies-are-evil-avoid-them",
            "text": "Keep your code simple and with minimal external dependencies. Spending a day or two to code something from scratch while avoiding to use third party code is usually an investment that pays off. The more code you have in your algorithm that is not written by you, the harder debugging becomes. In particular, refrain from building your entire project on code that you do not understand to avoid bad surprises just before the deadline. If you must use code written by others, spend the time that is needed to fully understand what it does, and link it statically so that it will be easy to place breakpoints inside it.",
            "title": "6. Dependencies are evil, avoid them"
        },
        {
            "location": "/coding-guidelines/#7-global-variables-are-not-evil-use-them",
            "text": "Global variables are often extremely useful --- if you think you need one, use it. They are indeed dangerous for large projects, but you are not coding one of those, you are coding a prototype to test a research idea. I suggest to keep one single copy of your entire application state in a global variable (or a singleton class) that can be serialized (see tip 1). This variable should include everything rendered on screen and all the temporary data produced by your algorithm. This will allow you to easily access all the data in your project for plotting or debugging purposes.",
            "title": "7. Global variables are not evil, use them"
        },
        {
            "location": "/coding-guidelines/#8-prototype-first",
            "text": "Don\u2019t preemptively optimize and try to quickly write code that is clean and correct. It is common to try multiple different approaches to solve a new problem before finding the right one. This means that the majority of the code that you will write will not be used at the end of the project. While you should still write high-quality and bug-free code to make sure that your results is correct, you definitely do not want to spend time optimizing it before you are sure that is the right approach. In particular, it is helpful to learn a good prototyping language (Python, matlab) and use it for the early stages of the project and switch to (or mix it with) c++ only after finding a promising direction.",
            "title": "8. Prototype first"
        },
        {
            "location": "/coding-guidelines/#9-avoid-explicit-pointers",
            "text": "Do yourself a favor, do not use explicit pointers. If you use a language that supports explicit pointers, use them only if you really have to. And even in that case, keep them isolated in a single file and be very careful with them. Writing data inside another variable by accident might not trigger a crash, and simply produce strange artifacts that might convince you that a promising research direction does not work, while the problem lies in a nasty bug in your code. There is no reason to take that risk during prototyping, just avoid them and leave them for the end of the project in case they become necessary to optimize your code.",
            "title": "9. Avoid explicit pointers"
        },
        {
            "location": "/coding-guidelines/#10-if-your-program-crashes-fix-it-now",
            "text": "If your program crashes, don't close your eyes and move on. Try to make it happen again, debug it and fix it immediately. These bugs are a nightmare to find, and the more code you add on top of a bug will just make it harder to find. If you don't fix it, due to Murphy's law, it will start to be problematic only a few days before the deadline and you will have no time to fix it at that point.  Daniele Panozzo",
            "title": "10. If your program crashes, fix it now!"
        },
        {
            "location": "/faq/",
            "text": "FAQ\n\u00b6\n\n\n\n\nQ:\n I'd like to merge two 3D meshes into one. How to do it with igl?\n\n\n\n\nIt sounds like you're trying to compute a union. Are your two meshes closed, watertight manifolds? Then you could call \nigl/boolean/mesh_boolean\n with the union option. If not, then there's still hope with something else. \n[Alec]\n\n\n\n\nQ:\n In other apps I have seen the the user is asked to specify singularities , and the then the rosy field is generated. But in libigl it seems like you have to specify faces and direction vectors to design a field. Is it possible to specify singularities?\n\n\n\n\nIt is not possible to specify singularities right now. To specify the directions, the vectors should be in global coordinates (the vectors are 3D vectors, the libigl function takes care of projecting them onto the corresponding face), you can take a look here for a basic example that fixes only one face: \nhttp://libigl.github.io/libigl/tutorial/tutorial.html#505\n \n[Daniele]\n\n\n\n\nQ:\n Does Libigl use the same 2D Triangle code (my search in the Libigl source code indicates NO, but a confirmation would be reassuring)?\n\n\n\n\nNo, it uses CGAL for triangulation. \n[Alec]\n\n\n\n\nQ:\n Libigl's Boolean depends on some GPL-licensed header files from CGAL. Is it possible to remove this dependency?\n\n\n\n\nNo, the dependency on CGAL would require severely rewriting a core function. It is possible to do, but I will not do it. \n[Alec]\n\n\n\n\nQ:\n Do you have a ready to run command line program so that I can run a test with a few of my sample data sets?\n\n\n\n\nNo, but it would be very easy to alter the \nboolean tutorial example\n to do that. Basically drop the viewer and change the hardcoded paths to command line arguments and write out the result to an obj. \n[Alec]\n\n\n\n\nQ:\n I see that it can generate N-rosy fields, but is it possible to remesh based on the rosy field?\n\n\n\n\nHere is an example that uses libigl to produce a seamless parametrization:\n\nhttp://libigl.github.io/libigl/tutorial/tutorial.html#505\n\n\nIf you want a mesh, you can pass this parametrization to libQEX (\nhttps://github.com/hcebke/libQEx\n) to extract it. We do not have it built in in the tutorial due to a more restrictive licence used by libQEx. \n[Daniele]\n\n\n\n\nQ:\n I am having issues with parameterization (igl::miq). Even at 100 iterations, there are still distortions. What is the cause?\n\n\n\n\nThis is unfortunately the expected behaviour, the MIQ parametrization tends to concentrate the distortion around singularities. \n[Daniele]\n\n\n\n\nQ:\n I am receiving compilation errors along the lines of \"ISO C++ forbids declaration of ... with no type\" when compiling under Windows using gcc.\n\n\n\n\nWe never tried to compile libigl on Windows with gcc, but we did test our library on:\n\n\n\n\nwindows using visual studio\n\n\nlinux with gcc\n\n\nmacosx with clang\n\n\n\n\nYou might have a version of gcc that doesn't support (enough of) c++11. Try using Cygwin and g++ 4.9.2. \n[Alec, Daniele]",
            "title": "FAQ"
        },
        {
            "location": "/faq/#faq",
            "text": "Q:  I'd like to merge two 3D meshes into one. How to do it with igl?   It sounds like you're trying to compute a union. Are your two meshes closed, watertight manifolds? Then you could call  igl/boolean/mesh_boolean  with the union option. If not, then there's still hope with something else.  [Alec]   Q:  In other apps I have seen the the user is asked to specify singularities , and the then the rosy field is generated. But in libigl it seems like you have to specify faces and direction vectors to design a field. Is it possible to specify singularities?   It is not possible to specify singularities right now. To specify the directions, the vectors should be in global coordinates (the vectors are 3D vectors, the libigl function takes care of projecting them onto the corresponding face), you can take a look here for a basic example that fixes only one face:  http://libigl.github.io/libigl/tutorial/tutorial.html#505   [Daniele]   Q:  Does Libigl use the same 2D Triangle code (my search in the Libigl source code indicates NO, but a confirmation would be reassuring)?   No, it uses CGAL for triangulation.  [Alec]   Q:  Libigl's Boolean depends on some GPL-licensed header files from CGAL. Is it possible to remove this dependency?   No, the dependency on CGAL would require severely rewriting a core function. It is possible to do, but I will not do it.  [Alec]   Q:  Do you have a ready to run command line program so that I can run a test with a few of my sample data sets?   No, but it would be very easy to alter the  boolean tutorial example  to do that. Basically drop the viewer and change the hardcoded paths to command line arguments and write out the result to an obj.  [Alec]   Q:  I see that it can generate N-rosy fields, but is it possible to remesh based on the rosy field?   Here is an example that uses libigl to produce a seamless parametrization: http://libigl.github.io/libigl/tutorial/tutorial.html#505  If you want a mesh, you can pass this parametrization to libQEX ( https://github.com/hcebke/libQEx ) to extract it. We do not have it built in in the tutorial due to a more restrictive licence used by libQEx.  [Daniele]   Q:  I am having issues with parameterization (igl::miq). Even at 100 iterations, there are still distortions. What is the cause?   This is unfortunately the expected behaviour, the MIQ parametrization tends to concentrate the distortion around singularities.  [Daniele]   Q:  I am receiving compilation errors along the lines of \"ISO C++ forbids declaration of ... with no type\" when compiling under Windows using gcc.   We never tried to compile libigl on Windows with gcc, but we did test our library on:   windows using visual studio  linux with gcc  macosx with clang   You might have a version of gcc that doesn't support (enough of) c++11. Try using Cygwin and g++ 4.9.2.  [Alec, Daniele]",
            "title": "FAQ"
        },
        {
            "location": "/RELEASE_HISTORY/",
            "text": "html header:   \n\n\n\n\n\n\nhljs.initHighlightingOnLoad();\n\n\nLibigl version tracking\n\u00b6\n\n\n\n\n\n\n\n\nVersion\n\n\nShort description\n\n\n\n\n\n\n\n\n\n\n1.2.1\n\n\nReorganization opengl-dependent functions: opengl and opengl2 extras\n\n\n\n\n\n\n1.2.0\n\n\nReorganization of \"extras\", rm deprecated funcs, absorb boost & svd3x3\n\n\n\n\n\n\n1.1.7\n\n\nSwitch build for static library to cmake.\n\n\n\n\n\n\n1.1.6\n\n\nMajor boolean robustness fix, drop CGAL dependency for AABB/distances\n\n\n\n\n\n\n1.1.5\n\n\nBug fix in booleans\n\n\n\n\n\n\n1.1.4\n\n\nEdge collapsing and linear program solving\n\n\n\n\n\n\n1.1.3\n\n\nBug fixes in active set and boundary_conditions\n\n\n\n\n\n\n1.1.1\n\n\nPLY file format support\n\n\n\n\n\n\n1.1.0\n\n\nMesh boolean operations using CGAL and cork, implementing [Attene 14]\n\n\n\n\n\n\n1.0.3\n\n\nBone heat method\n\n\n\n\n\n\n1.0.2\n\n\nBug fix in winding number code\n\n\n\n\n\n\n1.0.1\n\n\nBug fixes and more CGAL support\n\n\n\n\n\n\n1.0.0\n\n\nMajor beta release: many renames, tutorial, triangle, org. build\n\n\n\n\n\n\n0.4.6\n\n\nGeneralized Winding Numbers\n\n\n\n\n\n\n0.4.5\n\n\nCGAL extra: mesh selfintersection\n\n\n\n\n\n\n0.4.4\n\n\nSTL file format support\n\n\n\n\n\n\n0.4.3\n\n\nARAP implementation\n\n\n\n\n\n\n0.4.1\n\n\nMigrated much of the FAST code including extra for Sifakis' 3x3 svd\n\n\n\n\n\n\n0.4.0\n\n\nRelease under MPL2 license\n\n\n\n\n\n\n0.3.7\n\n\nEmbree2.0 support\n\n\n\n\n\n\n0.3.6\n\n\nboost extra, patches, mosek 7 support, libiglbbw (mosek optional)\n\n\n\n\n\n\n0.3.5\n\n\nMore examples, naive primitive sorting\n\n\n\n\n\n\n0.3.3\n\n\nMany more examples, ambient occlusion with Embree.\n\n\n\n\n\n\n0.3.1\n\n\nLinearly dependent constraints in min_quad_with_fixed, SparseQR buggy\n\n\n\n\n\n\n0.3.0\n\n\nBetter active set method support\n\n\n\n\n\n\n0.2.3\n\n\nMore explicits, active set method, opengl/anttweakbar guards\n\n\n\n\n\n\n0.2.2\n\n\nMore explicit instantiations, faster sorts and uniques\n\n\n\n\n\n\n0.2.1\n\n\nBug fixes in barycenter and doublearea found by Martin Bisson\n\n\n\n\n\n\n0.2.0\n\n\nXML serializer more stable and fixed bug in remove_duplicate_vertices\n\n\n\n\n\n\n0.1.8\n\n\nEmbree and xml (windows only) extras\n\n\n\n\n\n\n0.1.5\n\n\nCompilation on windows, bug fix for compilation with cygwin\n\n\n\n\n\n\n0.1.1\n\n\nAlpha release with core functions, extras, examples\n\n\n\n\n\n\n\n\nVersion 1.2 Changes\n\u00b6\n\n\nThis change introduces better organization of dependencies and removes some\ndeprecated/repeated functions. The 3x3 svd code and dependent functions\n(including ARAP) were absorbed into the main library. Similarly, the boost\ndependency extra was absorbed.\n\n\nExternal libraries as git subrepos\n\u00b6\n\n\nThe core functionality of libigl (still) just depends on stl, c++11 and Eigen.\nThere are additional \noptional\n dependencies (e.g. CGAL, embree, glfw, tetgen,\ntriangle). Libigl functions using these are located (still) in sub-folders of\nthe include directory (e.g.  \ninclude/igl/cgal/\n, \ninclude/igl/embree/\n). Prior\nto version 1.2 we included copies of the code for some of these dependencies in the\n\nexternal/\n directory. As of\nversion 1.2, these have been replaced with git sub-repos. If you have cloned\nlibigl \nbefore version 1.2\n then you should issue \n\n\ngit submodule update --init --recursive\n\n\n\n\n\nDeprecated/repeated functions\n\u00b6\n\n\n\n\n\n\n\n\nOld\n\n\nNew\n\n\n\n\n\n\n\n\n\n\nigl::angles\n\n\nigl::internal_angles\n\n\n\n\n\n\nigl::get_modifiers\n\n\n[deleted]\n\n\n\n\n\n\nigl::nchoosek(offset,K,N,std::vector)\n\n\nigl::nchoosek(Eigen,K,Eigen)\n\n\n\n\n\n\n#include\n \n<igl/boost/components.h>\n\n\n#include\n \n<igl/components.h>\n\n\n\n\n\n\n#include\n \n<igl/boost/bfs_orient.h>\n\n\n#include\n \n<igl/bfs_orient.h>\n\n\n\n\n\n\n#include\n \n<igl/boost/orientable_patches.h>\n\n\n#include\n \n<igl/orientable_patches.h>\n\n\n\n\n\n\n#include\n \n<igl/svd3x3/arap.h>\n\n\n#include\n \n<igl/arap.h>\n\n\n\n\n\n\n#include\n \n<igl/svd3x3/arap_dof.h>\n\n\n#include\n \n<igl/arap_dof.h>\n\n\n\n\n\n\n#include\n \n<igl/svd3x3/fit_rotations.h>\n\n\n#include\n \n<igl/fit_rotations.h>\n\n\n\n\n\n\n#include\n \n<igl/svd3x3/polar_svd3x3.h>\n\n\n#include\n \n<igl/polar_svd3x3.h>\n\n\n\n\n\n\n#include\n \n<igl/svd3x3/svd3x3.h>\n\n\n#include\n \n<igl/svd3x3.h>\n\n\n\n\n\n\n#include\n \n<igl/svd3x3/svd3x3_avx.h>\n\n\n#include\n \n<igl/svd3x3_avx.h>\n\n\n\n\n\n\n#include\n \n<igl/svd3x3/svd3x3_sse.h>\n\n\n#include\n \n<igl/svd3x3_sse.h>\n\n\n\n\n\n\n\n\nVersion 1.0 Changes\n\u00b6\n\n\nOur beta release marks our confidence that this library can be used outside of\ncasual experimenting. To maintain order, we have made a few changes which\ncurrent users should read and adapt their code accordingly.\n\n\nRenamed functions\n\u00b6\n\n\nThe following table lists functions which have changed name as of version\n1.0.0:\n\n\n\n\n\n\n\n\nOld\n\n\nNew\n\n\n\n\n\n\n\n\n\n\nigl::add_barycenter\n\n\nigl::false_barycentric_subdivision\n\n\n\n\n\n\nigl::areamatrix\n\n\nigl::vector_area_matrix\n\n\n\n\n\n\nigl::barycentric2global\n\n\nigl::barycentric_to_global\n\n\n\n\n\n\nigl::boundary_faces\n\n\nigl::boundary_facets\n\n\n\n\n\n\nigl::boundary_vertices_sorted\n\n\nigl::boundary_loop\n\n\n\n\n\n\nigl::cotangent\n\n\nigl::cotmatrix_entries\n\n\n\n\n\n\nigl::edgetopology\n\n\nigl::edge_topology\n\n\n\n\n\n\nigl::gradMat\n\n\nigl::grad\n\n\n\n\n\n\nigl::is_manifold\n\n\nigl::is_edge_manifold\n\n\n\n\n\n\nigl::mexStream\n\n\nigl::MexStream\n\n\n\n\n\n\nigl::moveFV\n\n\nigl::average_onto_vertices\n\n\n\n\n\n\nigl::moveVF\n\n\nigl::average_onto_faces\n\n\n\n\n\n\nigl::plot_vector\n\n\nigl::print_vector\n\n\n\n\n\n\nigl::pos\n\n\nigl::HalfEdgeIterator\n\n\n\n\n\n\nigl::plane_project\n\n\nigl::project_isometrically_to_plane\n\n\n\n\n\n\nigl::project_points_mesh\n\n\nigl::line_mesh_intersection\n\n\n\n\n\n\nigl::read\n\n\nigl::read_triangle_mesh\n\n\n\n\n\n\nigl::removeDuplicates.cpp\n\n\nigl::remove_duplicates\n\n\n\n\n\n\nigl::removeUnreferenced\n\n\nigl::remove_unreferenced\n\n\n\n\n\n\nigl::tt\n\n\nigl::triangle_triangle_adjacency\n\n\n\n\n\n\nigl::vf\n\n\nigl::vertex_triangle_adjacency\n\n\n\n\n\n\nigl::write\n\n\nigl::write_triangle_mesh\n\n\n\n\n\n\nigl::manifold_patches\n\n\nigl::orientable_patches\n\n\n\n\n\n\nigl::selfintersect\n\n\nigl::remesh_self_intersections\n\n\n\n\n\n\nigl::project_mesh\n\n\nigl::line_mesh_intersection\n\n\n\n\n\n\nigl::triangulate\n\n\nigl::polygon_mesh_to_triangle_mesh\n\n\n\n\n\n\nigl::is_manifold\n\n\nigl::is_edge_manifold\n\n\n\n\n\n\nigl::triangle_wrapper\n\n\nigl::triangulate\n\n\n\n\n\n\n\n\nMiscellaneous\n\u00b6\n\n\n\n\nTo match interfaces provided by (all) other quadratic optimization\n   libraries, \nigl::min_quad_with_fixed\n and \nigl::active_set\n now expect as\n   input twice the quadratic coefficients matrix, i.e. the Hessian. For\n   example, \nigl::min_quad_with_fixed(H,B,...)\n minimizes \n\\frac{1}{2}x^T H\n   x+x^T B\n\\frac{1}{2}x^T H\n   x+x^T B\n.\n\n\nWe have inverted the \nIGL_HEADER_ONLY\n macro to \nIGL_STATIC_LIBRARY\n. To\n   compile using libigl as a header-only library, simply include headers and\n   libigl in the header search path. To link to libigl, you must define the\n   \nIGL_STATIC_LIBRARY\n macro at compile time and link to the \nlibigl*.a\n\n   libraries.\n\n\nBuilding libigl as a static library is now more organized. There is a\n   \nbuild/\n directory with Makefiles for the main library (\nMakefile\n) and each\n   dependency (e.g. \nMakefile_mosek\n for \nlibiglmosek.a\n)\n\n\nigl::polar_svd\n now always returns a rotation in \nR\n, never a reflection.\n   This mirrors the behavior of \nigl::polar_svd3x3\n.  Consequently the \nT\n\n   part may have negative skews.\n\n\nWe have organized the static library build\n\n\nThe previous \nigl::grad\n function, which computed the per-triangle gradient\n   of a per-vertex scalar function has been replaced. Now \nigl::grad\n computes\n   the linear operator (previous computed using \nigl::gradMat\n). The gradient\n   values can still be recovered by multiplying the operator against the scalar\n   field as a vector and reshaping to have gradients per row.\n\n\nMASSMATRIX_*\n has become \nMASSMATRIX_TYPE_*\n\n\nThe function \nigl::project_normals\n, which cast a line for each vertex of\n   mesh \nA\n in the normal direction and found the closest intersection along\n   these lines with mesh \nB\n, has been removed.",
            "title": "Release History"
        },
        {
            "location": "/RELEASE_HISTORY/#libigl-version-tracking",
            "text": "Version  Short description      1.2.1  Reorganization opengl-dependent functions: opengl and opengl2 extras    1.2.0  Reorganization of \"extras\", rm deprecated funcs, absorb boost & svd3x3    1.1.7  Switch build for static library to cmake.    1.1.6  Major boolean robustness fix, drop CGAL dependency for AABB/distances    1.1.5  Bug fix in booleans    1.1.4  Edge collapsing and linear program solving    1.1.3  Bug fixes in active set and boundary_conditions    1.1.1  PLY file format support    1.1.0  Mesh boolean operations using CGAL and cork, implementing [Attene 14]    1.0.3  Bone heat method    1.0.2  Bug fix in winding number code    1.0.1  Bug fixes and more CGAL support    1.0.0  Major beta release: many renames, tutorial, triangle, org. build    0.4.6  Generalized Winding Numbers    0.4.5  CGAL extra: mesh selfintersection    0.4.4  STL file format support    0.4.3  ARAP implementation    0.4.1  Migrated much of the FAST code including extra for Sifakis' 3x3 svd    0.4.0  Release under MPL2 license    0.3.7  Embree2.0 support    0.3.6  boost extra, patches, mosek 7 support, libiglbbw (mosek optional)    0.3.5  More examples, naive primitive sorting    0.3.3  Many more examples, ambient occlusion with Embree.    0.3.1  Linearly dependent constraints in min_quad_with_fixed, SparseQR buggy    0.3.0  Better active set method support    0.2.3  More explicits, active set method, opengl/anttweakbar guards    0.2.2  More explicit instantiations, faster sorts and uniques    0.2.1  Bug fixes in barycenter and doublearea found by Martin Bisson    0.2.0  XML serializer more stable and fixed bug in remove_duplicate_vertices    0.1.8  Embree and xml (windows only) extras    0.1.5  Compilation on windows, bug fix for compilation with cygwin    0.1.1  Alpha release with core functions, extras, examples",
            "title": "Libigl version tracking"
        },
        {
            "location": "/RELEASE_HISTORY/#version-12-changes",
            "text": "This change introduces better organization of dependencies and removes some\ndeprecated/repeated functions. The 3x3 svd code and dependent functions\n(including ARAP) were absorbed into the main library. Similarly, the boost\ndependency extra was absorbed.",
            "title": "Version 1.2 Changes"
        },
        {
            "location": "/RELEASE_HISTORY/#external-libraries-as-git-subrepos",
            "text": "The core functionality of libigl (still) just depends on stl, c++11 and Eigen.\nThere are additional  optional  dependencies (e.g. CGAL, embree, glfw, tetgen,\ntriangle). Libigl functions using these are located (still) in sub-folders of\nthe include directory (e.g.   include/igl/cgal/ ,  include/igl/embree/ ). Prior\nto version 1.2 we included copies of the code for some of these dependencies in the external/  directory. As of\nversion 1.2, these have been replaced with git sub-repos. If you have cloned\nlibigl  before version 1.2  then you should issue   git submodule update --init --recursive",
            "title": "External libraries as git subrepos"
        },
        {
            "location": "/RELEASE_HISTORY/#deprecatedrepeated-functions",
            "text": "Old  New      igl::angles  igl::internal_angles    igl::get_modifiers  [deleted]    igl::nchoosek(offset,K,N,std::vector)  igl::nchoosek(Eigen,K,Eigen)    #include   <igl/boost/components.h>  #include   <igl/components.h>    #include   <igl/boost/bfs_orient.h>  #include   <igl/bfs_orient.h>    #include   <igl/boost/orientable_patches.h>  #include   <igl/orientable_patches.h>    #include   <igl/svd3x3/arap.h>  #include   <igl/arap.h>    #include   <igl/svd3x3/arap_dof.h>  #include   <igl/arap_dof.h>    #include   <igl/svd3x3/fit_rotations.h>  #include   <igl/fit_rotations.h>    #include   <igl/svd3x3/polar_svd3x3.h>  #include   <igl/polar_svd3x3.h>    #include   <igl/svd3x3/svd3x3.h>  #include   <igl/svd3x3.h>    #include   <igl/svd3x3/svd3x3_avx.h>  #include   <igl/svd3x3_avx.h>    #include   <igl/svd3x3/svd3x3_sse.h>  #include   <igl/svd3x3_sse.h>",
            "title": "Deprecated/repeated functions"
        },
        {
            "location": "/RELEASE_HISTORY/#version-10-changes",
            "text": "Our beta release marks our confidence that this library can be used outside of\ncasual experimenting. To maintain order, we have made a few changes which\ncurrent users should read and adapt their code accordingly.",
            "title": "Version 1.0 Changes"
        },
        {
            "location": "/RELEASE_HISTORY/#renamed-functions",
            "text": "The following table lists functions which have changed name as of version\n1.0.0:     Old  New      igl::add_barycenter  igl::false_barycentric_subdivision    igl::areamatrix  igl::vector_area_matrix    igl::barycentric2global  igl::barycentric_to_global    igl::boundary_faces  igl::boundary_facets    igl::boundary_vertices_sorted  igl::boundary_loop    igl::cotangent  igl::cotmatrix_entries    igl::edgetopology  igl::edge_topology    igl::gradMat  igl::grad    igl::is_manifold  igl::is_edge_manifold    igl::mexStream  igl::MexStream    igl::moveFV  igl::average_onto_vertices    igl::moveVF  igl::average_onto_faces    igl::plot_vector  igl::print_vector    igl::pos  igl::HalfEdgeIterator    igl::plane_project  igl::project_isometrically_to_plane    igl::project_points_mesh  igl::line_mesh_intersection    igl::read  igl::read_triangle_mesh    igl::removeDuplicates.cpp  igl::remove_duplicates    igl::removeUnreferenced  igl::remove_unreferenced    igl::tt  igl::triangle_triangle_adjacency    igl::vf  igl::vertex_triangle_adjacency    igl::write  igl::write_triangle_mesh    igl::manifold_patches  igl::orientable_patches    igl::selfintersect  igl::remesh_self_intersections    igl::project_mesh  igl::line_mesh_intersection    igl::triangulate  igl::polygon_mesh_to_triangle_mesh    igl::is_manifold  igl::is_edge_manifold    igl::triangle_wrapper  igl::triangulate",
            "title": "Renamed functions"
        },
        {
            "location": "/RELEASE_HISTORY/#miscellaneous",
            "text": "To match interfaces provided by (all) other quadratic optimization\n   libraries,  igl::min_quad_with_fixed  and  igl::active_set  now expect as\n   input twice the quadratic coefficients matrix, i.e. the Hessian. For\n   example,  igl::min_quad_with_fixed(H,B,...)  minimizes  \\frac{1}{2}x^T H\n   x+x^T B \\frac{1}{2}x^T H\n   x+x^T B .  We have inverted the  IGL_HEADER_ONLY  macro to  IGL_STATIC_LIBRARY . To\n   compile using libigl as a header-only library, simply include headers and\n   libigl in the header search path. To link to libigl, you must define the\n    IGL_STATIC_LIBRARY  macro at compile time and link to the  libigl*.a \n   libraries.  Building libigl as a static library is now more organized. There is a\n    build/  directory with Makefiles for the main library ( Makefile ) and each\n   dependency (e.g.  Makefile_mosek  for  libiglmosek.a )  igl::polar_svd  now always returns a rotation in  R , never a reflection.\n   This mirrors the behavior of  igl::polar_svd3x3 .  Consequently the  T \n   part may have negative skews.  We have organized the static library build  The previous  igl::grad  function, which computed the per-triangle gradient\n   of a per-vertex scalar function has been replaced. Now  igl::grad  computes\n   the linear operator (previous computed using  igl::gradMat ). The gradient\n   values can still be recovered by multiplying the operator against the scalar\n   field as a vector and reshaping to have gradients per row.  MASSMATRIX_*  has become  MASSMATRIX_TYPE_*  The function  igl::project_normals , which cast a line for each vertex of\n   mesh  A  in the normal direction and found the closest intersection along\n   these lines with mesh  B , has been removed.",
            "title": "Miscellaneous"
        },
        {
            "location": "/LICENSE/",
            "text": "License\n\u00b6\n\n\nLibigl is primarily licensed under MPL2\n  - \nhttp://www.mozilla.org/MPL/2.0/\n\n  - \nhttp://www.mozilla.org/MPL/2.0/FAQ.html\n\n\nAll \n.h\n and \n.cpp\n \nfiles\n directly in \ninclude/igl\n (but not necessarily in\nsub-directories) are subject only to the terms of the MPL2; they should not\ninclude any code that is covered by other/less-permissive licenses.\n\n\nThe \n.h\n and \n.cpp\n \nfiles\n in sub-directories of \ninclude/igl\n allow libigl to\nintegrate with external third-party libraries (e.g., those in \nexternal/\n) and\nare subject to the MPL2, \nand\n also the terms of licenses of the\ncorresponding external library.  The licenses used by these libraries fall under\nthree categories:\n\n\n\n\ncommon \"free, non-copyleft licenses\" (such as zlib, BSD, MIT, and public\n  domain)\n\n\ninclude/igl/anttweakbar\n\n\ninclude/igl/embree\n\n\ninclude/igl/opengl\n\n\ninclude/igl/opengl/glfw\n\n\ninclude/igl/opengl2\n\n\ninclude/igl/png\n\n\ninclude/igl/viewer\n\n\ninclude/igl/xml\n\n\ncommon \"copyleft\" licences (such as GPL, LGPL, and AGPL)\n\n\ninclude/igl/copyleft\n\n\ninclude/igl/copyleft/cgal\n\n\ninclude/igl/copyleft/comiso\n\n\ninclude/igl/copyleft/cork\n\n\ninclude/igl/copyleft/tetgen\n\n\nother \"uncommon\" licenses or commercial software\n\n\ninclude/igl/lim\n\n\ninclude/igl/matlab\n\n\ninclude/igl/mosek\n\n\ninclude/igl/triangle\n\n\n\n\nThe Libigl code that interfaces with \"copyleft\" libraries is in\n\ninclude/igl/copyleft\n.  Only include these headers if you are accept the\nlicensing terms of the corresponding external library.  For example, using\n\ninclude/igl/copyleft/tetgen\n requires that you accept the terms of the AGPLv3.",
            "title": "License"
        },
        {
            "location": "/LICENSE/#license",
            "text": "Libigl is primarily licensed under MPL2\n  -  http://www.mozilla.org/MPL/2.0/ \n  -  http://www.mozilla.org/MPL/2.0/FAQ.html  All  .h  and  .cpp   files  directly in  include/igl  (but not necessarily in\nsub-directories) are subject only to the terms of the MPL2; they should not\ninclude any code that is covered by other/less-permissive licenses.  The  .h  and  .cpp   files  in sub-directories of  include/igl  allow libigl to\nintegrate with external third-party libraries (e.g., those in  external/ ) and\nare subject to the MPL2,  and  also the terms of licenses of the\ncorresponding external library.  The licenses used by these libraries fall under\nthree categories:   common \"free, non-copyleft licenses\" (such as zlib, BSD, MIT, and public\n  domain)  include/igl/anttweakbar  include/igl/embree  include/igl/opengl  include/igl/opengl/glfw  include/igl/opengl2  include/igl/png  include/igl/viewer  include/igl/xml  common \"copyleft\" licences (such as GPL, LGPL, and AGPL)  include/igl/copyleft  include/igl/copyleft/cgal  include/igl/copyleft/comiso  include/igl/copyleft/cork  include/igl/copyleft/tetgen  other \"uncommon\" licenses or commercial software  include/igl/lim  include/igl/matlab  include/igl/mosek  include/igl/triangle   The Libigl code that interfaces with \"copyleft\" libraries is in include/igl/copyleft .  Only include these headers if you are accept the\nlicensing terms of the corresponding external library.  For example, using include/igl/copyleft/tetgen  requires that you accept the terms of the AGPLv3.",
            "title": "License"
        }
    ]
}